Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.010870
Epoch 1
Validation rmse = 3.010870
Epoch 2
Validation rmse = 3.010870
Epoch 3
Validation rmse = 3.010870
Epoch 4
Validation rmse = 3.010870
Epoch 5
Validation rmse = 3.010870
Epoch 6
Validation rmse = 3.010870
Epoch 7
Validation rmse = 3.010870
Epoch 8
Validation rmse = 3.010870
Epoch 9
Validation rmse = 3.010870
Epoch 10
Validation rmse = 3.010870
Epoch 11
Validation rmse = 3.010870
Epoch 12
Validation rmse = 3.010870
Epoch 13
Validation rmse = 3.010870
Epoch 14
Validation rmse = 3.010870
Epoch 15
Validation rmse = 3.010870
Epoch 16
Validation rmse = 3.010870
Epoch 17
Validation rmse = 3.010870
Epoch 18
Validation rmse = 3.010870
Epoch 19
Validation rmse = 3.010870
Epoch 20
Validation rmse = 3.010870
Epoch 21
Validation rmse = 3.010870
Epoch 22
Validation rmse = 3.010870
Epoch 23
Validation rmse = 3.010870
Epoch 24
Validation rmse = 3.010870
Epoch 25
Validation rmse = 3.010870
Epoch 26
Validation rmse = 3.010870
Epoch 27
Validation rmse = 3.010870
Epoch 28
Validation rmse = 3.010870
Epoch 29
Validation rmse = 3.010870
Model 0 best validation rmse = 3.010870 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.637835
Ensemble test rmse = 2.637835
1-fold cross validation
Seed 0 ==> test rmse = 2.637835
Overall test rmse = 2.637835 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.597879
Epoch 1
Validation rmse = 3.597879
Epoch 2
Validation rmse = 3.597879
Epoch 3
Validation rmse = 3.597879
Epoch 4
Validation rmse = 3.597879
Epoch 5
Validation rmse = 3.597879
Epoch 6
Validation rmse = 3.597879
Epoch 7
Validation rmse = 3.597879
Epoch 8
Validation rmse = 3.597879
Epoch 9
Validation rmse = 3.597879
Epoch 10
Validation rmse = 3.597879
Epoch 11
Validation rmse = 3.597879
Epoch 12
Validation rmse = 3.597879
Epoch 13
Validation rmse = 3.597879
Epoch 14
Validation rmse = 3.597879
Epoch 15
Validation rmse = 3.597879
Epoch 16
Validation rmse = 3.597879
Epoch 17
Validation rmse = 3.597879
Epoch 18
Validation rmse = 3.597879
Epoch 19
Validation rmse = 3.597879
Epoch 20
Validation rmse = 3.597879
Epoch 21
Validation rmse = 3.597879
Epoch 22
Validation rmse = 3.597879
Epoch 23
Validation rmse = 3.597879
Epoch 24
Validation rmse = 3.597879
Epoch 25
Validation rmse = 3.597879
Epoch 26
Validation rmse = 3.597879
Epoch 27
Validation rmse = 3.597879
Epoch 28
Validation rmse = 3.597879
Epoch 29
Validation rmse = 3.597879
Model 0 best validation rmse = 3.597879 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.041888
Ensemble test rmse = 2.041888
1-fold cross validation
Seed 0 ==> test rmse = 2.041888
Overall test rmse = 2.041888 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.438543
Epoch 1
Validation rmse = 2.438543
Epoch 2
Validation rmse = 2.438543
Epoch 3
Validation rmse = 2.438543
Epoch 4
Validation rmse = 2.438543
Epoch 5
Validation rmse = 2.438543
Epoch 6
Validation rmse = 2.438543
Epoch 7
Validation rmse = 2.438543
Epoch 8
Validation rmse = 2.438543
Epoch 9
Validation rmse = 2.438543
Epoch 10
Validation rmse = 2.438543
Epoch 11
Validation rmse = 2.438543
Epoch 12
Validation rmse = 2.438543
Epoch 13
Validation rmse = 2.438543
Epoch 14
Validation rmse = 2.438543
Epoch 15
Validation rmse = 2.438543
Epoch 16
Validation rmse = 2.438543
Epoch 17
Validation rmse = 2.438543
Epoch 18
Validation rmse = 2.438543
Epoch 19
Validation rmse = 2.438543
Epoch 20
Validation rmse = 2.438543
Epoch 21
Validation rmse = 2.438543
Epoch 22
Validation rmse = 2.438543
Epoch 23
Validation rmse = 2.438543
Epoch 24
Validation rmse = 2.438543
Epoch 25
Validation rmse = 2.438543
Epoch 26
Validation rmse = 2.438543
Epoch 27
Validation rmse = 2.438543
Epoch 28
Validation rmse = 2.438543
Epoch 29
Validation rmse = 2.438543
Model 0 best validation rmse = 2.438543 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.042391
Ensemble test rmse = 3.042391
1-fold cross validation
Seed 0 ==> test rmse = 3.042391
Overall test rmse = 3.042391 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.702417
Epoch 1
Validation rmse = 2.702417
Epoch 2
Validation rmse = 2.702417
Epoch 3
Validation rmse = 2.702417
Epoch 4
Validation rmse = 2.702417
Epoch 5
Validation rmse = 2.702417
Epoch 6
Validation rmse = 2.702417
Epoch 7
Validation rmse = 2.702417
Epoch 8
Validation rmse = 2.702417
Epoch 9
Validation rmse = 2.702417
Epoch 10
Validation rmse = 2.702417
Epoch 11
Validation rmse = 2.702417
Epoch 12
Validation rmse = 2.702417
Epoch 13
Validation rmse = 2.702417
Epoch 14
Validation rmse = 2.702417
Epoch 15
Validation rmse = 2.702417
Epoch 16
Validation rmse = 2.702417
Epoch 17
Validation rmse = 2.702417
Epoch 18
Validation rmse = 2.702417
Epoch 19
Validation rmse = 2.702417
Epoch 20
Validation rmse = 2.702417
Epoch 21
Validation rmse = 2.702417
Epoch 22
Validation rmse = 2.702417
Epoch 23
Validation rmse = 2.702417
Epoch 24
Validation rmse = 2.702417
Epoch 25
Validation rmse = 2.702417
Epoch 26
Validation rmse = 2.702417
Epoch 27
Validation rmse = 2.702417
Epoch 28
Validation rmse = 2.702417
Epoch 29
Validation rmse = 2.702417
Model 0 best validation rmse = 2.702417 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.822858
Ensemble test rmse = 2.822858
1-fold cross validation
Seed 0 ==> test rmse = 2.822858
Overall test rmse = 2.822858 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.951837
Epoch 1
Validation rmse = 3.951837
Epoch 2
Validation rmse = 3.951837
Epoch 3
Validation rmse = 3.951837
Epoch 4
Validation rmse = 3.951837
Epoch 5
Validation rmse = 3.951837
Epoch 6
Validation rmse = 3.951837
Epoch 7
Validation rmse = 3.951837
Epoch 8
Validation rmse = 3.951837
Epoch 9
Validation rmse = 3.951837
Epoch 10
Validation rmse = 3.951837
Epoch 11
Validation rmse = 3.951837
Epoch 12
Validation rmse = 3.951837
Epoch 13
Validation rmse = 3.951837
Epoch 14
Validation rmse = 3.951837
Epoch 15
Validation rmse = 3.951837
Epoch 16
Validation rmse = 3.951837
Epoch 17
Validation rmse = 3.951837
Epoch 18
Validation rmse = 3.951837
Epoch 19
Validation rmse = 3.951837
Epoch 20
Validation rmse = 3.951837
Epoch 21
Validation rmse = 3.951837
Epoch 22
Validation rmse = 3.951837
Epoch 23
Validation rmse = 3.951837
Epoch 24
Validation rmse = 3.951837
Epoch 25
Validation rmse = 3.951837
Epoch 26
Validation rmse = 3.951837
Epoch 27
Validation rmse = 3.951837
Epoch 28
Validation rmse = 3.951837
Epoch 29
Validation rmse = 3.951837
Model 0 best validation rmse = 3.951837 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.876617
Ensemble test rmse = 1.876617
1-fold cross validation
Seed 0 ==> test rmse = 1.876617
Overall test rmse = 1.876617 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.978996
Epoch 1
Validation rmse = 2.978996
Epoch 2
Validation rmse = 2.978996
Epoch 3
Validation rmse = 2.978996
Epoch 4
Validation rmse = 2.978996
Epoch 5
Validation rmse = 2.978996
Epoch 6
Validation rmse = 2.978996
Epoch 7
Validation rmse = 2.978996
Epoch 8
Validation rmse = 2.978996
Epoch 9
Validation rmse = 2.978996
Epoch 10
Validation rmse = 2.978996
Epoch 11
Validation rmse = 2.978996
Epoch 12
Validation rmse = 2.978996
Epoch 13
Validation rmse = 2.978996
Epoch 14
Validation rmse = 2.978996
Epoch 15
Validation rmse = 2.978996
Epoch 16
Validation rmse = 2.978996
Epoch 17
Validation rmse = 2.978996
Epoch 18
Validation rmse = 2.978996
Epoch 19
Validation rmse = 2.978996
Epoch 20
Validation rmse = 2.978996
Epoch 21
Validation rmse = 2.978996
Epoch 22
Validation rmse = 2.978996
Epoch 23
Validation rmse = 2.978996
Epoch 24
Validation rmse = 2.978996
Epoch 25
Validation rmse = 2.978996
Epoch 26
Validation rmse = 2.978996
Epoch 27
Validation rmse = 2.978996
Epoch 28
Validation rmse = 2.978996
Epoch 29
Validation rmse = 2.978996
Model 0 best validation rmse = 2.978996 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.241398
Ensemble test rmse = 2.241398
1-fold cross validation
Seed 0 ==> test rmse = 2.241398
Overall test rmse = 2.241398 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.208484
Epoch 1
Validation rmse = 3.208484
Epoch 2
Validation rmse = 3.208484
Epoch 3
Validation rmse = 3.208484
Epoch 4
Validation rmse = 3.208484
Epoch 5
Validation rmse = 3.208484
Epoch 6
Validation rmse = 3.208484
Epoch 7
Validation rmse = 3.208484
Epoch 8
Validation rmse = 3.208484
Epoch 9
Validation rmse = 3.208484
Epoch 10
Validation rmse = 3.208484
Epoch 11
Validation rmse = 3.208484
Epoch 12
Validation rmse = 3.208484
Epoch 13
Validation rmse = 3.208484
Epoch 14
Validation rmse = 3.208484
Epoch 15
Validation rmse = 3.208484
Epoch 16
Validation rmse = 3.208484
Epoch 17
Validation rmse = 3.208484
Epoch 18
Validation rmse = 3.208484
Epoch 19
Validation rmse = 3.208484
Epoch 20
Validation rmse = 3.208484
Epoch 21
Validation rmse = 3.208484
Epoch 22
Validation rmse = 3.208484
Epoch 23
Validation rmse = 3.208484
Epoch 24
Validation rmse = 3.208484
Epoch 25
Validation rmse = 3.208484
Epoch 26
Validation rmse = 3.208484
Epoch 27
Validation rmse = 3.208484
Epoch 28
Validation rmse = 3.208484
Epoch 29
Validation rmse = 3.208484
Model 0 best validation rmse = 3.208484 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.413307
Ensemble test rmse = 2.413307
1-fold cross validation
Seed 0 ==> test rmse = 2.413307
Overall test rmse = 2.413307 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.828393
Epoch 1
Validation rmse = 2.828393
Epoch 2
Validation rmse = 2.828393
Epoch 3
Validation rmse = 2.828393
Epoch 4
Validation rmse = 2.828393
Epoch 5
Validation rmse = 2.828393
Epoch 6
Validation rmse = 2.828393
Epoch 7
Validation rmse = 2.828393
Epoch 8
Validation rmse = 2.828393
Epoch 9
Validation rmse = 2.828393
Epoch 10
Validation rmse = 2.828393
Epoch 11
Validation rmse = 2.828393
Epoch 12
Validation rmse = 2.828393
Epoch 13
Validation rmse = 2.828393
Epoch 14
Validation rmse = 2.828393
Epoch 15
Validation rmse = 2.828393
Epoch 16
Validation rmse = 2.828393
Epoch 17
Validation rmse = 2.828393
Epoch 18
Validation rmse = 2.828393
Epoch 19
Validation rmse = 2.828393
Epoch 20
Validation rmse = 2.828393
Epoch 21
Validation rmse = 2.828393
Epoch 22
Validation rmse = 2.828393
Epoch 23
Validation rmse = 2.828393
Epoch 24
Validation rmse = 2.828393
Epoch 25
Validation rmse = 2.828393
Epoch 26
Validation rmse = 2.828393
Epoch 27
Validation rmse = 2.828393
Epoch 28
Validation rmse = 2.828393
Epoch 29
Validation rmse = 2.828393
Model 0 best validation rmse = 2.828393 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.418472
Ensemble test rmse = 2.418472
1-fold cross validation
Seed 0 ==> test rmse = 2.418472
Overall test rmse = 2.418472 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.680624
Epoch 1
Validation rmse = 2.680624
Epoch 2
Validation rmse = 2.680624
Epoch 3
Validation rmse = 2.680624
Epoch 4
Validation rmse = 2.680624
Epoch 5
Validation rmse = 2.680624
Epoch 6
Validation rmse = 2.680624
Epoch 7
Validation rmse = 2.680624
Epoch 8
Validation rmse = 2.680624
Epoch 9
Validation rmse = 2.680624
Epoch 10
Validation rmse = 2.680624
Epoch 11
Validation rmse = 2.680624
Epoch 12
Validation rmse = 2.680624
Epoch 13
Validation rmse = 2.680624
Epoch 14
Validation rmse = 2.680624
Epoch 15
Validation rmse = 2.680624
Epoch 16
Validation rmse = 2.680624
Epoch 17
Validation rmse = 2.680624
Epoch 18
Validation rmse = 2.680624
Epoch 19
Validation rmse = 2.680624
Epoch 20
Validation rmse = 2.680624
Epoch 21
Validation rmse = 2.680624
Epoch 22
Validation rmse = 2.680624
Epoch 23
Validation rmse = 2.680624
Epoch 24
Validation rmse = 2.680624
Epoch 25
Validation rmse = 2.680624
Epoch 26
Validation rmse = 2.680624
Epoch 27
Validation rmse = 2.680624
Epoch 28
Validation rmse = 2.680624
Epoch 29
Validation rmse = 2.680624
Model 0 best validation rmse = 2.680624 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.594328
Ensemble test rmse = 2.594328
1-fold cross validation
Seed 0 ==> test rmse = 2.594328
Overall test rmse = 2.594328 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.112161
Epoch 1
Validation rmse = 3.112161
Epoch 2
Validation rmse = 3.112161
Epoch 3
Validation rmse = 3.112161
Epoch 4
Validation rmse = 3.112161
Epoch 5
Validation rmse = 3.112161
Epoch 6
Validation rmse = 3.112161
Epoch 7
Validation rmse = 3.112161
Epoch 8
Validation rmse = 3.112161
Epoch 9
Validation rmse = 3.112161
Epoch 10
Validation rmse = 3.112161
Epoch 11
Validation rmse = 3.112161
Epoch 12
Validation rmse = 3.112161
Epoch 13
Validation rmse = 3.112161
Epoch 14
Validation rmse = 3.112161
Epoch 15
Validation rmse = 3.112161
Epoch 16
Validation rmse = 3.112161
Epoch 17
Validation rmse = 3.112161
Epoch 18
Validation rmse = 3.112161
Epoch 19
Validation rmse = 3.112161
Epoch 20
Validation rmse = 3.112161
Epoch 21
Validation rmse = 3.112161
Epoch 22
Validation rmse = 3.112161
Epoch 23
Validation rmse = 3.112161
Epoch 24
Validation rmse = 3.112161
Epoch 25
Validation rmse = 3.112161
Epoch 26
Validation rmse = 3.112161
Epoch 27
Validation rmse = 3.112161
Epoch 28
Validation rmse = 3.112161
Epoch 29
Validation rmse = 3.112161
Model 0 best validation rmse = 3.112161 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.867011
Ensemble test rmse = 2.867011
1-fold cross validation
Seed 0 ==> test rmse = 2.867011
Overall test rmse = 2.867011 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.522661
Epoch 1
Validation rmse = 2.522661
Epoch 2
Validation rmse = 2.522661
Epoch 3
Validation rmse = 2.522661
Epoch 4
Validation rmse = 2.522661
Epoch 5
Validation rmse = 2.522661
Epoch 6
Validation rmse = 2.522661
Epoch 7
Validation rmse = 2.522661
Epoch 8
Validation rmse = 2.522661
Epoch 9
Validation rmse = 2.522661
Epoch 10
Validation rmse = 2.522661
Epoch 11
Validation rmse = 2.522661
Epoch 12
Validation rmse = 2.522661
Epoch 13
Validation rmse = 2.522661
Epoch 14
Validation rmse = 2.522661
Epoch 15
Validation rmse = 2.522661
Epoch 16
Validation rmse = 2.522661
Epoch 17
Validation rmse = 2.522661
Epoch 18
Validation rmse = 2.522661
Epoch 19
Validation rmse = 2.522661
Epoch 20
Validation rmse = 2.522661
Epoch 21
Validation rmse = 2.522661
Epoch 22
Validation rmse = 2.522661
Epoch 23
Validation rmse = 2.522661
Epoch 24
Validation rmse = 2.522661
Epoch 25
Validation rmse = 2.522661
Epoch 26
Validation rmse = 2.522661
Epoch 27
Validation rmse = 2.522661
Epoch 28
Validation rmse = 2.522661
Epoch 29
Validation rmse = 2.522661
Model 0 best validation rmse = 2.522661 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.887460
Ensemble test rmse = 3.887460
1-fold cross validation
Seed 0 ==> test rmse = 3.887460
Overall test rmse = 3.887460 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.484906
Epoch 1
Validation rmse = 3.484906
Epoch 2
Validation rmse = 3.484906
Epoch 3
Validation rmse = 3.484906
Epoch 4
Validation rmse = 3.484906
Epoch 5
Validation rmse = 3.484906
Epoch 6
Validation rmse = 3.484906
Epoch 7
Validation rmse = 3.484906
Epoch 8
Validation rmse = 3.484906
Epoch 9
Validation rmse = 3.484906
Epoch 10
Validation rmse = 3.484906
Epoch 11
Validation rmse = 3.484906
Epoch 12
Validation rmse = 3.484906
Epoch 13
Validation rmse = 3.484906
Epoch 14
Validation rmse = 3.484906
Epoch 15
Validation rmse = 3.484906
Epoch 16
Validation rmse = 3.484906
Epoch 17
Validation rmse = 3.484906
Epoch 18
Validation rmse = 3.484906
Epoch 19
Validation rmse = 3.484906
Epoch 20
Validation rmse = 3.484906
Epoch 21
Validation rmse = 3.484906
Epoch 22
Validation rmse = 3.484906
Epoch 23
Validation rmse = 3.484906
Epoch 24
Validation rmse = 3.484906
Epoch 25
Validation rmse = 3.484906
Epoch 26
Validation rmse = 3.484906
Epoch 27
Validation rmse = 3.484906
Epoch 28
Validation rmse = 3.484906
Epoch 29
Validation rmse = 3.484906
Model 0 best validation rmse = 3.484906 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.322090
Ensemble test rmse = 2.322090
1-fold cross validation
Seed 0 ==> test rmse = 2.322090
Overall test rmse = 2.322090 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.581397
Epoch 1
Validation rmse = 3.581397
Epoch 2
Validation rmse = 3.581397
Epoch 3
Validation rmse = 3.581397
Epoch 4
Validation rmse = 3.581397
Epoch 5
Validation rmse = 3.581397
Epoch 6
Validation rmse = 3.581397
Epoch 7
Validation rmse = 3.581397
Epoch 8
Validation rmse = 3.581397
Epoch 9
Validation rmse = 3.581397
Epoch 10
Validation rmse = 3.581397
Epoch 11
Validation rmse = 3.581397
Epoch 12
Validation rmse = 3.581397
Epoch 13
Validation rmse = 3.581397
Epoch 14
Validation rmse = 3.581397
Epoch 15
Validation rmse = 3.581397
Epoch 16
Validation rmse = 3.581397
Epoch 17
Validation rmse = 3.581397
Epoch 18
Validation rmse = 3.581397
Epoch 19
Validation rmse = 3.581397
Epoch 20
Validation rmse = 3.581397
Epoch 21
Validation rmse = 3.581397
Epoch 22
Validation rmse = 3.581397
Epoch 23
Validation rmse = 3.581397
Epoch 24
Validation rmse = 3.581397
Epoch 25
Validation rmse = 3.581397
Epoch 26
Validation rmse = 3.581397
Epoch 27
Validation rmse = 3.581397
Epoch 28
Validation rmse = 3.581397
Epoch 29
Validation rmse = 3.581397
Model 0 best validation rmse = 3.581397 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.966085
Ensemble test rmse = 1.966085
1-fold cross validation
Seed 0 ==> test rmse = 1.966085
Overall test rmse = 1.966085 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 4.374728
Epoch 1
Validation rmse = 4.374728
Epoch 2
Validation rmse = 4.374728
Epoch 3
Validation rmse = 4.374728
Epoch 4
Validation rmse = 4.374728
Epoch 5
Validation rmse = 4.374728
Epoch 6
Validation rmse = 4.374728
Epoch 7
Validation rmse = 4.374728
Epoch 8
Validation rmse = 4.374728
Epoch 9
Validation rmse = 4.374728
Epoch 10
Validation rmse = 4.374728
Epoch 11
Validation rmse = 4.374728
Epoch 12
Validation rmse = 4.374728
Epoch 13
Validation rmse = 4.374728
Epoch 14
Validation rmse = 4.374728
Epoch 15
Validation rmse = 4.374728
Epoch 16
Validation rmse = 4.374728
Epoch 17
Validation rmse = 4.374728
Epoch 18
Validation rmse = 4.374728
Epoch 19
Validation rmse = 4.374728
Epoch 20
Validation rmse = 4.374728
Epoch 21
Validation rmse = 4.374728
Epoch 22
Validation rmse = 4.374728
Epoch 23
Validation rmse = 4.374728
Epoch 24
Validation rmse = 4.374728
Epoch 25
Validation rmse = 4.374728
Epoch 26
Validation rmse = 4.374728
Epoch 27
Validation rmse = 4.374728
Epoch 28
Validation rmse = 4.374728
Epoch 29
Validation rmse = 4.374728
Model 0 best validation rmse = 4.374728 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.500063
Ensemble test rmse = 1.500063
1-fold cross validation
Seed 0 ==> test rmse = 1.500063
Overall test rmse = 1.500063 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.115959
Epoch 1
Validation rmse = 3.115959
Epoch 2
Validation rmse = 3.115959
Epoch 3
Validation rmse = 3.115959
Epoch 4
Validation rmse = 3.115959
Epoch 5
Validation rmse = 3.115959
Epoch 6
Validation rmse = 3.115959
Epoch 7
Validation rmse = 3.115959
Epoch 8
Validation rmse = 3.115959
Epoch 9
Validation rmse = 3.115959
Epoch 10
Validation rmse = 3.115959
Epoch 11
Validation rmse = 3.115959
Epoch 12
Validation rmse = 3.115959
Epoch 13
Validation rmse = 3.115959
Epoch 14
Validation rmse = 3.115959
Epoch 15
Validation rmse = 3.115959
Epoch 16
Validation rmse = 3.115959
Epoch 17
Validation rmse = 3.115959
Epoch 18
Validation rmse = 3.115959
Epoch 19
Validation rmse = 3.115959
Epoch 20
Validation rmse = 3.115959
Epoch 21
Validation rmse = 3.115959
Epoch 22
Validation rmse = 3.115959
Epoch 23
Validation rmse = 3.115959
Epoch 24
Validation rmse = 3.115959
Epoch 25
Validation rmse = 3.115959
Epoch 26
Validation rmse = 3.115959
Epoch 27
Validation rmse = 3.115959
Epoch 28
Validation rmse = 3.115959
Epoch 29
Validation rmse = 3.115959
Model 0 best validation rmse = 3.115959 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.333065
Ensemble test rmse = 2.333065
1-fold cross validation
Seed 0 ==> test rmse = 2.333065
Overall test rmse = 2.333065 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.413080
Epoch 1
Validation rmse = 3.413080
Epoch 2
Validation rmse = 3.413080
Epoch 3
Validation rmse = 3.413080
Epoch 4
Validation rmse = 3.413080
Epoch 5
Validation rmse = 3.413080
Epoch 6
Validation rmse = 3.413080
Epoch 7
Validation rmse = 3.413080
Epoch 8
Validation rmse = 3.413080
Epoch 9
Validation rmse = 3.413080
Epoch 10
Validation rmse = 3.413080
Epoch 11
Validation rmse = 3.413080
Epoch 12
Validation rmse = 3.413080
Epoch 13
Validation rmse = 3.413080
Epoch 14
Validation rmse = 3.413080
Epoch 15
Validation rmse = 3.413080
Epoch 16
Validation rmse = 3.413080
Epoch 17
Validation rmse = 3.413080
Epoch 18
Validation rmse = 3.413080
Epoch 19
Validation rmse = 3.413080
Epoch 20
Validation rmse = 3.413080
Epoch 21
Validation rmse = 3.413080
Epoch 22
Validation rmse = 3.413080
Epoch 23
Validation rmse = 3.413080
Epoch 24
Validation rmse = 3.413080
Epoch 25
Validation rmse = 3.413080
Epoch 26
Validation rmse = 3.413080
Epoch 27
Validation rmse = 3.413080
Epoch 28
Validation rmse = 3.413080
Epoch 29
Validation rmse = 3.413080
Model 0 best validation rmse = 3.413080 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.611864
Ensemble test rmse = 2.611864
1-fold cross validation
Seed 0 ==> test rmse = 2.611864
Overall test rmse = 2.611864 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.936614
Epoch 1
Validation rmse = 3.936614
Epoch 2
Validation rmse = 3.936614
Epoch 3
Validation rmse = 3.936614
Epoch 4
Validation rmse = 3.936614
Epoch 5
Validation rmse = 3.936614
Epoch 6
Validation rmse = 3.936614
Epoch 7
Validation rmse = 3.936614
Epoch 8
Validation rmse = 3.936614
Epoch 9
Validation rmse = 3.936614
Epoch 10
Validation rmse = 3.936614
Epoch 11
Validation rmse = 3.936614
Epoch 12
Validation rmse = 3.936614
Epoch 13
Validation rmse = 3.936614
Epoch 14
Validation rmse = 3.936614
Epoch 15
Validation rmse = 3.936614
Epoch 16
Validation rmse = 3.936614
Epoch 17
Validation rmse = 3.936614
Epoch 18
Validation rmse = 3.936614
Epoch 19
Validation rmse = 3.936614
Epoch 20
Validation rmse = 3.936614
Epoch 21
Validation rmse = 3.936614
Epoch 22
Validation rmse = 3.936614
Epoch 23
Validation rmse = 3.936614
Epoch 24
Validation rmse = 3.936614
Epoch 25
Validation rmse = 3.936614
Epoch 26
Validation rmse = 3.936614
Epoch 27
Validation rmse = 3.936614
Epoch 28
Validation rmse = 3.936614
Epoch 29
Validation rmse = 3.936614
Model 0 best validation rmse = 3.936614 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.688712
Ensemble test rmse = 1.688712
1-fold cross validation
Seed 0 ==> test rmse = 1.688712
Overall test rmse = 1.688712 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.735872
Epoch 1
Validation rmse = 2.735872
Epoch 2
Validation rmse = 2.735872
Epoch 3
Validation rmse = 2.735872
Epoch 4
Validation rmse = 2.735872
Epoch 5
Validation rmse = 2.735872
Epoch 6
Validation rmse = 2.735872
Epoch 7
Validation rmse = 2.735872
Epoch 8
Validation rmse = 2.735872
Epoch 9
Validation rmse = 2.735872
Epoch 10
Validation rmse = 2.735872
Epoch 11
Validation rmse = 2.735872
Epoch 12
Validation rmse = 2.735872
Epoch 13
Validation rmse = 2.735872
Epoch 14
Validation rmse = 2.735872
Epoch 15
Validation rmse = 2.735872
Epoch 16
Validation rmse = 2.735872
Epoch 17
Validation rmse = 2.735872
Epoch 18
Validation rmse = 2.735872
Epoch 19
Validation rmse = 2.735872
Epoch 20
Validation rmse = 2.735872
Epoch 21
Validation rmse = 2.735872
Epoch 22
Validation rmse = 2.735872
Epoch 23
Validation rmse = 2.735872
Epoch 24
Validation rmse = 2.735872
Epoch 25
Validation rmse = 2.735872
Epoch 26
Validation rmse = 2.735872
Epoch 27
Validation rmse = 2.735872
Epoch 28
Validation rmse = 2.735872
Epoch 29
Validation rmse = 2.735872
Model 0 best validation rmse = 2.735872 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.711764
Ensemble test rmse = 2.711764
1-fold cross validation
Seed 0 ==> test rmse = 2.711764
Overall test rmse = 2.711764 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.758073
Epoch 1
Validation rmse = 3.758073
Epoch 2
Validation rmse = 3.758073
Epoch 3
Validation rmse = 3.758073
Epoch 4
Validation rmse = 3.758073
Epoch 5
Validation rmse = 3.758073
Epoch 6
Validation rmse = 3.758073
Epoch 7
Validation rmse = 3.758073
Epoch 8
Validation rmse = 3.758073
Epoch 9
Validation rmse = 3.758073
Epoch 10
Validation rmse = 3.758073
Epoch 11
Validation rmse = 3.758073
Epoch 12
Validation rmse = 3.758073
Epoch 13
Validation rmse = 3.758073
Epoch 14
Validation rmse = 3.758073
Epoch 15
Validation rmse = 3.758073
Epoch 16
Validation rmse = 3.758073
Epoch 17
Validation rmse = 3.758073
Epoch 18
Validation rmse = 3.758073
Epoch 19
Validation rmse = 3.758073
Epoch 20
Validation rmse = 3.758073
Epoch 21
Validation rmse = 3.758073
Epoch 22
Validation rmse = 3.758073
Epoch 23
Validation rmse = 3.758073
Epoch 24
Validation rmse = 3.758073
Epoch 25
Validation rmse = 3.758073
Epoch 26
Validation rmse = 3.758073
Epoch 27
Validation rmse = 3.758073
Epoch 28
Validation rmse = 3.758073
Epoch 29
Validation rmse = 3.758073
Model 0 best validation rmse = 3.758073 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.854200
Ensemble test rmse = 1.854200
1-fold cross validation
Seed 0 ==> test rmse = 1.854200
Overall test rmse = 1.854200 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.279929
Epoch 1
Validation rmse = 2.279929
Epoch 2
Validation rmse = 2.279929
Epoch 3
Validation rmse = 2.279929
Epoch 4
Validation rmse = 2.279929
Epoch 5
Validation rmse = 2.279929
Epoch 6
Validation rmse = 2.279929
Epoch 7
Validation rmse = 2.279929
Epoch 8
Validation rmse = 2.279929
Epoch 9
Validation rmse = 2.279929
Epoch 10
Validation rmse = 2.279929
Epoch 11
Validation rmse = 2.279929
Epoch 12
Validation rmse = 2.279929
Epoch 13
Validation rmse = 2.279929
Epoch 14
Validation rmse = 2.279929
Epoch 15
Validation rmse = 2.279929
Epoch 16
Validation rmse = 2.279929
Epoch 17
Validation rmse = 2.279929
Epoch 18
Validation rmse = 2.279929
Epoch 19
Validation rmse = 2.279929
Epoch 20
Validation rmse = 2.279929
Epoch 21
Validation rmse = 2.279929
Epoch 22
Validation rmse = 2.279929
Epoch 23
Validation rmse = 2.279929
Epoch 24
Validation rmse = 2.279929
Epoch 25
Validation rmse = 2.279929
Epoch 26
Validation rmse = 2.279929
Epoch 27
Validation rmse = 2.279929
Epoch 28
Validation rmse = 2.279929
Epoch 29
Validation rmse = 2.279929
Model 0 best validation rmse = 2.279929 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.151335
Ensemble test rmse = 3.151335
1-fold cross validation
Seed 0 ==> test rmse = 3.151335
Overall test rmse = 3.151335 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.360381
Epoch 1
Validation rmse = 2.360381
Epoch 2
Validation rmse = 2.360381
Epoch 3
Validation rmse = 2.360381
Epoch 4
Validation rmse = 2.360381
Epoch 5
Validation rmse = 2.360381
Epoch 6
Validation rmse = 2.360381
Epoch 7
Validation rmse = 2.360381
Epoch 8
Validation rmse = 2.360381
Epoch 9
Validation rmse = 2.360381
Epoch 10
Validation rmse = 2.360381
Epoch 11
Validation rmse = 2.360381
Epoch 12
Validation rmse = 2.360381
Epoch 13
Validation rmse = 2.360381
Epoch 14
Validation rmse = 2.360381
Epoch 15
Validation rmse = 2.360381
Epoch 16
Validation rmse = 2.360381
Epoch 17
Validation rmse = 2.360381
Epoch 18
Validation rmse = 2.360381
Epoch 19
Validation rmse = 2.360381
Epoch 20
Validation rmse = 2.360381
Epoch 21
Validation rmse = 2.360381
Epoch 22
Validation rmse = 2.360381
Epoch 23
Validation rmse = 2.360381
Epoch 24
Validation rmse = 2.360381
Epoch 25
Validation rmse = 2.360381
Epoch 26
Validation rmse = 2.360381
Epoch 27
Validation rmse = 2.360381
Epoch 28
Validation rmse = 2.360381
Epoch 29
Validation rmse = 2.360381
Model 0 best validation rmse = 2.360381 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.057382
Ensemble test rmse = 3.057382
1-fold cross validation
Seed 0 ==> test rmse = 3.057382
Overall test rmse = 3.057382 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.687539
Epoch 1
Validation rmse = 2.687539
Epoch 2
Validation rmse = 2.687539
Epoch 3
Validation rmse = 2.687539
Epoch 4
Validation rmse = 2.687539
Epoch 5
Validation rmse = 2.687539
Epoch 6
Validation rmse = 2.687539
Epoch 7
Validation rmse = 2.687539
Epoch 8
Validation rmse = 2.687539
Epoch 9
Validation rmse = 2.687539
Epoch 10
Validation rmse = 2.687539
Epoch 11
Validation rmse = 2.687539
Epoch 12
Validation rmse = 2.687539
Epoch 13
Validation rmse = 2.687539
Epoch 14
Validation rmse = 2.687539
Epoch 15
Validation rmse = 2.687539
Epoch 16
Validation rmse = 2.687539
Epoch 17
Validation rmse = 2.687539
Epoch 18
Validation rmse = 2.687539
Epoch 19
Validation rmse = 2.687539
Epoch 20
Validation rmse = 2.687539
Epoch 21
Validation rmse = 2.687539
Epoch 22
Validation rmse = 2.687539
Epoch 23
Validation rmse = 2.687539
Epoch 24
Validation rmse = 2.687539
Epoch 25
Validation rmse = 2.687539
Epoch 26
Validation rmse = 2.687539
Epoch 27
Validation rmse = 2.687539
Epoch 28
Validation rmse = 2.687539
Epoch 29
Validation rmse = 2.687539
Model 0 best validation rmse = 2.687539 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.736598
Ensemble test rmse = 2.736598
1-fold cross validation
Seed 0 ==> test rmse = 2.736598
Overall test rmse = 2.736598 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.570640
Epoch 1
Validation rmse = 2.570640
Epoch 2
Validation rmse = 2.570640
Epoch 3
Validation rmse = 2.570640
Epoch 4
Validation rmse = 2.570640
Epoch 5
Validation rmse = 2.570640
Epoch 6
Validation rmse = 2.570640
Epoch 7
Validation rmse = 2.570640
Epoch 8
Validation rmse = 2.570640
Epoch 9
Validation rmse = 2.570640
Epoch 10
Validation rmse = 2.570640
Epoch 11
Validation rmse = 2.570640
Epoch 12
Validation rmse = 2.570640
Epoch 13
Validation rmse = 2.570640
Epoch 14
Validation rmse = 2.570640
Epoch 15
Validation rmse = 2.570640
Epoch 16
Validation rmse = 2.570640
Epoch 17
Validation rmse = 2.570640
Epoch 18
Validation rmse = 2.570640
Epoch 19
Validation rmse = 2.570640
Epoch 20
Validation rmse = 2.570640
Epoch 21
Validation rmse = 2.570640
Epoch 22
Validation rmse = 2.570640
Epoch 23
Validation rmse = 2.570640
Epoch 24
Validation rmse = 2.570640
Epoch 25
Validation rmse = 2.570640
Epoch 26
Validation rmse = 2.570640
Epoch 27
Validation rmse = 2.570640
Epoch 28
Validation rmse = 2.570640
Epoch 29
Validation rmse = 2.570640
Model 0 best validation rmse = 2.570640 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.034106
Ensemble test rmse = 3.034106
1-fold cross validation
Seed 0 ==> test rmse = 3.034106
Overall test rmse = 3.034106 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.345020
Epoch 1
Validation rmse = 3.345020
Epoch 2
Validation rmse = 3.345020
Epoch 3
Validation rmse = 3.345020
Epoch 4
Validation rmse = 3.345020
Epoch 5
Validation rmse = 3.345020
Epoch 6
Validation rmse = 3.345020
Epoch 7
Validation rmse = 3.345020
Epoch 8
Validation rmse = 3.345020
Epoch 9
Validation rmse = 3.345020
Epoch 10
Validation rmse = 3.345020
Epoch 11
Validation rmse = 3.345020
Epoch 12
Validation rmse = 3.345020
Epoch 13
Validation rmse = 3.345020
Epoch 14
Validation rmse = 3.345020
Epoch 15
Validation rmse = 3.345020
Epoch 16
Validation rmse = 3.345020
Epoch 17
Validation rmse = 3.345020
Epoch 18
Validation rmse = 3.345020
Epoch 19
Validation rmse = 3.345020
Epoch 20
Validation rmse = 3.345020
Epoch 21
Validation rmse = 3.345020
Epoch 22
Validation rmse = 3.345020
Epoch 23
Validation rmse = 3.345020
Epoch 24
Validation rmse = 3.345020
Epoch 25
Validation rmse = 3.345020
Epoch 26
Validation rmse = 3.345020
Epoch 27
Validation rmse = 3.345020
Epoch 28
Validation rmse = 3.345020
Epoch 29
Validation rmse = 3.345020
Model 0 best validation rmse = 3.345020 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.139655
Ensemble test rmse = 2.139655
1-fold cross validation
Seed 0 ==> test rmse = 2.139655
Overall test rmse = 2.139655 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'delaney_toy.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.644090
Epoch 1
Validation rmse = 3.644090
Epoch 2
Validation rmse = 3.644090
Epoch 3
Validation rmse = 3.644090
Epoch 4
Validation rmse = 3.644090
Epoch 5
Validation rmse = 3.644090
Epoch 6
Validation rmse = 3.644090
Epoch 7
Validation rmse = 3.644090
Epoch 8
Validation rmse = 3.644090
Epoch 9
Validation rmse = 3.644090
Epoch 10
Validation rmse = 3.644090
Epoch 11
Validation rmse = 3.644090
Epoch 12
Validation rmse = 3.644090
Epoch 13
Validation rmse = 3.644090
Epoch 14
Validation rmse = 3.644090
Epoch 15
Validation rmse = 3.644090
Epoch 16
Validation rmse = 3.644090
Epoch 17
Validation rmse = 3.644090
Epoch 18
Validation rmse = 3.644090
Epoch 19
Validation rmse = 3.644090
Epoch 20
Validation rmse = 3.644090
Epoch 21
Validation rmse = 3.644090
Epoch 22
Validation rmse = 3.644090
Epoch 23
Validation rmse = 3.644090
Epoch 24
Validation rmse = 3.644090
Epoch 25
Validation rmse = 3.644090
Epoch 26
Validation rmse = 3.644090
Epoch 27
Validation rmse = 3.644090
Epoch 28
Validation rmse = 3.644090
Epoch 29
Validation rmse = 3.644090
Model 0 best validation rmse = 3.644090 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.924077
Ensemble test rmse = 1.924077
1-fold cross validation
Seed 0 ==> test rmse = 1.924077
Overall test rmse = 1.924077 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.685719
Epoch 1
Validation rmse = 2.685719
Epoch 2
Validation rmse = 2.685719
Epoch 3
Validation rmse = 2.685719
Epoch 4
Validation rmse = 2.685719
Epoch 5
Validation rmse = 2.685719
Epoch 6
Validation rmse = 2.685719
Epoch 7
Validation rmse = 2.685719
Epoch 8
Validation rmse = 2.685719
Epoch 9
Validation rmse = 2.685719
Epoch 10
Validation rmse = 2.685719
Epoch 11
Validation rmse = 2.685719
Epoch 12
Validation rmse = 2.685719
Epoch 13
Validation rmse = 2.685719
Epoch 14
Validation rmse = 2.685719
Epoch 15
Validation rmse = 2.685719
Epoch 16
Validation rmse = 2.685719
Epoch 17
Validation rmse = 2.685719
Epoch 18
Validation rmse = 2.685719
Epoch 19
Validation rmse = 2.685719
Epoch 20
Validation rmse = 2.685719
Epoch 21
Validation rmse = 2.685719
Epoch 22
Validation rmse = 2.685719
Epoch 23
Validation rmse = 2.685719
Epoch 24
Validation rmse = 2.685719
Epoch 25
Validation rmse = 2.685719
Epoch 26
Validation rmse = 2.685719
Epoch 27
Validation rmse = 2.685719
Epoch 28
Validation rmse = 2.685719
Epoch 29
Validation rmse = 2.685719
Model 0 best validation rmse = 2.685719 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 3.156571
Ensemble test rmse = 3.156571
1-fold cross validation
Seed 0 ==> test rmse = 3.156571
Overall test rmse = 3.156571 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.581639
Epoch 1
Validation rmse = 3.581639
Epoch 2
Validation rmse = 3.581639
Epoch 3
Validation rmse = 3.581639
Epoch 4
Validation rmse = 3.581639
Epoch 5
Validation rmse = 3.581639
Epoch 6
Validation rmse = 3.581639
Epoch 7
Validation rmse = 3.581639
Epoch 8
Validation rmse = 3.581639
Epoch 9
Validation rmse = 3.581639
Epoch 10
Validation rmse = 3.581639
Epoch 11
Validation rmse = 3.581639
Epoch 12
Validation rmse = 3.581639
Epoch 13
Validation rmse = 3.581639
Epoch 14
Validation rmse = 3.581639
Epoch 15
Validation rmse = 3.581639
Epoch 16
Validation rmse = 3.581639
Epoch 17
Validation rmse = 3.581639
Epoch 18
Validation rmse = 3.581639
Epoch 19
Validation rmse = 3.581639
Epoch 20
Validation rmse = 3.581639
Epoch 21
Validation rmse = 3.581639
Epoch 22
Validation rmse = 3.581639
Epoch 23
Validation rmse = 3.581639
Epoch 24
Validation rmse = 3.581639
Epoch 25
Validation rmse = 3.581639
Epoch 26
Validation rmse = 3.581639
Epoch 27
Validation rmse = 3.581639
Epoch 28
Validation rmse = 3.581639
Epoch 29
Validation rmse = 3.581639
Model 0 best validation rmse = 3.581639 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.188797
Ensemble test rmse = 2.188797
1-fold cross validation
Seed 0 ==> test rmse = 2.188797
Overall test rmse = 2.188797 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.739936
Epoch 1
Validation rmse = 3.739936
Epoch 2
Validation rmse = 3.739936
Epoch 3
Validation rmse = 3.739936
Epoch 4
Validation rmse = 3.739936
Epoch 5
Validation rmse = 3.739936
Epoch 6
Validation rmse = 3.739936
Epoch 7
Validation rmse = 3.739936
Epoch 8
Validation rmse = 3.739936
Epoch 9
Validation rmse = 3.739936
Epoch 10
Validation rmse = 3.739936
Epoch 11
Validation rmse = 3.739936
Epoch 12
Validation rmse = 3.739936
Epoch 13
Validation rmse = 3.739936
Epoch 14
Validation rmse = 3.739936
Epoch 15
Validation rmse = 3.739936
Epoch 16
Validation rmse = 3.739936
Epoch 17
Validation rmse = 3.739936
Epoch 18
Validation rmse = 3.739936
Epoch 19
Validation rmse = 3.739936
Epoch 20
Validation rmse = 3.739936
Epoch 21
Validation rmse = 3.739936
Epoch 22
Validation rmse = 3.739936
Epoch 23
Validation rmse = 3.739936
Epoch 24
Validation rmse = 3.739936
Epoch 25
Validation rmse = 3.739936
Epoch 26
Validation rmse = 3.739936
Epoch 27
Validation rmse = 3.739936
Epoch 28
Validation rmse = 3.739936
Epoch 29
Validation rmse = 3.739936
Model 0 best validation rmse = 3.739936 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.510565
Ensemble test rmse = 1.510565
1-fold cross validation
Seed 0 ==> test rmse = 1.510565
Overall test rmse = 1.510565 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.838164
Epoch 1
Validation rmse = 2.838164
Epoch 2
Validation rmse = 2.838164
Epoch 3
Validation rmse = 2.838164
Epoch 4
Validation rmse = 2.838164
Epoch 5
Validation rmse = 2.838164
Epoch 6
Validation rmse = 2.838164
Epoch 7
Validation rmse = 2.838164
Epoch 8
Validation rmse = 2.838164
Epoch 9
Validation rmse = 2.838164
Epoch 10
Validation rmse = 2.838164
Epoch 11
Validation rmse = 2.838164
Epoch 12
Validation rmse = 2.838164
Epoch 13
Validation rmse = 2.838164
Epoch 14
Validation rmse = 2.838164
Epoch 15
Validation rmse = 2.838164
Epoch 16
Validation rmse = 2.838164
Epoch 17
Validation rmse = 2.838164
Epoch 18
Validation rmse = 2.838164
Epoch 19
Validation rmse = 2.838164
Epoch 20
Validation rmse = 2.838164
Epoch 21
Validation rmse = 2.838164
Epoch 22
Validation rmse = 2.838164
Epoch 23
Validation rmse = 2.838164
Epoch 24
Validation rmse = 2.838164
Epoch 25
Validation rmse = 2.838164
Epoch 26
Validation rmse = 2.838164
Epoch 27
Validation rmse = 2.838164
Epoch 28
Validation rmse = 2.838164
Epoch 29
Validation rmse = 2.838164
Model 0 best validation rmse = 2.838164 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.572972
Ensemble test rmse = 2.572972
1-fold cross validation
Seed 0 ==> test rmse = 2.572972
Overall test rmse = 2.572972 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.650416
Epoch 1
Validation rmse = 2.650416
Epoch 2
Validation rmse = 2.650416
Epoch 3
Validation rmse = 2.650416
Epoch 4
Validation rmse = 2.650416
Epoch 5
Validation rmse = 2.650416
Epoch 6
Validation rmse = 2.650416
Epoch 7
Validation rmse = 2.650416
Epoch 8
Validation rmse = 2.650416
Epoch 9
Validation rmse = 2.650416
Epoch 10
Validation rmse = 2.650416
Epoch 11
Validation rmse = 2.650416
Epoch 12
Validation rmse = 2.650416
Epoch 13
Validation rmse = 2.650416
Epoch 14
Validation rmse = 2.650416
Epoch 15
Validation rmse = 2.650416
Epoch 16
Validation rmse = 2.650416
Epoch 17
Validation rmse = 2.650416
Epoch 18
Validation rmse = 2.650416
Epoch 19
Validation rmse = 2.650416
Epoch 20
Validation rmse = 2.650416
Epoch 21
Validation rmse = 2.650416
Epoch 22
Validation rmse = 2.650416
Epoch 23
Validation rmse = 2.650416
Epoch 24
Validation rmse = 2.650416
Epoch 25
Validation rmse = 2.650416
Epoch 26
Validation rmse = 2.650416
Epoch 27
Validation rmse = 2.650416
Epoch 28
Validation rmse = 2.650416
Epoch 29
Validation rmse = 2.650416
Model 0 best validation rmse = 2.650416 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.594536
Ensemble test rmse = 2.594536
1-fold cross validation
Seed 0 ==> test rmse = 2.594536
Overall test rmse = 2.594536 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../bazley_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../bazley_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': 'logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../bazley_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../bazley_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../bazley_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../bazley_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 3.013429
Epoch 1
Validation rmse = 3.013429
Epoch 2
Validation rmse = 3.013429
Epoch 3
Validation rmse = 3.013429
Epoch 4
Validation rmse = 3.013429
Epoch 5
Validation rmse = 3.013429
Epoch 6
Validation rmse = 3.013429
Epoch 7
Validation rmse = 3.013429
Epoch 8
Validation rmse = 3.013429
Epoch 9
Validation rmse = 3.013429
Epoch 10
Validation rmse = 3.013429
Epoch 11
Validation rmse = 3.013429
Epoch 12
Validation rmse = 3.013429
Epoch 13
Validation rmse = 3.013429
Epoch 14
Validation rmse = 3.013429
Epoch 15
Validation rmse = 3.013429
Epoch 16
Validation rmse = 3.013429
Epoch 17
Validation rmse = 3.013429
Epoch 18
Validation rmse = 3.013429
Epoch 19
Validation rmse = 3.013429
Epoch 20
Validation rmse = 3.013429
Epoch 21
Validation rmse = 3.013429
Epoch 22
Validation rmse = 3.013429
Epoch 23
Validation rmse = 3.013429
Epoch 24
Validation rmse = 3.013429
Epoch 25
Validation rmse = 3.013429
Epoch 26
Validation rmse = 3.013429
Epoch 27
Validation rmse = 3.013429
Epoch 28
Validation rmse = 3.013429
Epoch 29
Validation rmse = 3.013429
Model 0 best validation rmse = 3.013429 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.624269
Ensemble test rmse = 2.624269
1-fold cross validation
Seed 0 ==> test rmse = 2.624269
Overall test rmse = 2.624269 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.706975
Epoch 1
Validation rmse = 2.706975
Epoch 2
Validation rmse = 2.706975
Epoch 3
Validation rmse = 2.706975
Epoch 4
Validation rmse = 2.706975
Epoch 5
Validation rmse = 2.706975
Epoch 6
Validation rmse = 2.706975
Epoch 7
Validation rmse = 2.706975
Epoch 8
Validation rmse = 2.706975
Epoch 9
Validation rmse = 2.706975
Epoch 10
Validation rmse = 2.706975
Epoch 11
Validation rmse = 2.706975
Epoch 12
Validation rmse = 2.706975
Epoch 13
Validation rmse = 2.706975
Epoch 14
Validation rmse = 2.706975
Epoch 15
Validation rmse = 2.706975
Epoch 16
Validation rmse = 2.706975
Epoch 17
Validation rmse = 2.706975
Epoch 18
Validation rmse = 2.706975
Epoch 19
Validation rmse = 2.706975
Epoch 20
Validation rmse = 2.706975
Epoch 21
Validation rmse = 2.706975
Epoch 22
Validation rmse = 2.706975
Epoch 23
Validation rmse = 2.706975
Epoch 24
Validation rmse = 2.706975
Epoch 25
Validation rmse = 2.706975
Epoch 26
Validation rmse = 2.706975
Epoch 27
Validation rmse = 2.706975
Epoch 28
Validation rmse = 2.706975
Epoch 29
Validation rmse = 2.706975
Model 0 best validation rmse = 2.706975 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.821340
Ensemble test rmse = 2.821340
1-fold cross validation
Seed 0 ==> test rmse = 2.821340
Overall test rmse = 2.821340 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 4.093718
Epoch 1
Validation rmse = 4.093718
Epoch 2
Validation rmse = 4.093718
Epoch 3
Validation rmse = 4.093718
Epoch 4
Validation rmse = 4.093718
Epoch 5
Validation rmse = 4.093718
Epoch 6
Validation rmse = 4.093718
Epoch 7
Validation rmse = 4.093718
Epoch 8
Validation rmse = 4.093718
Epoch 9
Validation rmse = 4.093718
Epoch 10
Validation rmse = 4.093718
Epoch 11
Validation rmse = 4.093718
Epoch 12
Validation rmse = 4.093718
Epoch 13
Validation rmse = 4.093718
Epoch 14
Validation rmse = 4.093718
Epoch 15
Validation rmse = 4.093718
Epoch 16
Validation rmse = 4.093718
Epoch 17
Validation rmse = 4.093718
Epoch 18
Validation rmse = 4.093718
Epoch 19
Validation rmse = 4.093718
Epoch 20
Validation rmse = 4.093718
Epoch 21
Validation rmse = 4.093718
Epoch 22
Validation rmse = 4.093718
Epoch 23
Validation rmse = 4.093718
Epoch 24
Validation rmse = 4.093718
Epoch 25
Validation rmse = 4.093718
Epoch 26
Validation rmse = 4.093718
Epoch 27
Validation rmse = 4.093718
Epoch 28
Validation rmse = 4.093718
Epoch 29
Validation rmse = 4.093718
Model 0 best validation rmse = 4.093718 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.658072
Ensemble test rmse = 1.658072
1-fold cross validation
Seed 0 ==> test rmse = 1.658072
Overall test rmse = 1.658072 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11 | train size = 8 | val size = 1 | test size = 2
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Validation rmse = 2.568686
Epoch 1
Validation rmse = 2.568686
Epoch 2
Validation rmse = 2.568686
Epoch 3
Validation rmse = 2.568686
Epoch 4
Validation rmse = 2.568686
Epoch 5
Validation rmse = 2.568686
Epoch 6
Validation rmse = 2.568686
Epoch 7
Validation rmse = 2.568686
Epoch 8
Validation rmse = 2.568686
Epoch 9
Validation rmse = 2.568686
Epoch 10
Validation rmse = 2.568686
Epoch 11
Validation rmse = 2.568686
Epoch 12
Validation rmse = 2.568686
Epoch 13
Validation rmse = 2.568686
Epoch 14
Validation rmse = 2.568686
Epoch 15
Validation rmse = 2.568686
Epoch 16
Validation rmse = 2.568686
Epoch 17
Validation rmse = 2.568686
Epoch 18
Validation rmse = 2.568686
Epoch 19
Validation rmse = 2.568686
Epoch 20
Validation rmse = 2.568686
Epoch 21
Validation rmse = 2.568686
Epoch 22
Validation rmse = 2.568686
Epoch 23
Validation rmse = 2.568686
Epoch 24
Validation rmse = 2.568686
Epoch 25
Validation rmse = 2.568686
Epoch 26
Validation rmse = 2.568686
Epoch 27
Validation rmse = 2.568686
Epoch 28
Validation rmse = 2.568686
Epoch 29
Validation rmse = 2.568686
Model 0 best validation rmse = 2.568686 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 2.465281
Ensemble test rmse = 2.465281
1-fold cross validation
Seed 0 ==> test rmse = 2.465281
Overall test rmse = 2.465281 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,200 | train size = 3,360 | val size = 420 | test size = 420
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Loss = 1.9635e-02, PNorm = 33.9986, GNorm = 2.1310, lr_0 = 1.6716e-04
Loss = 1.9240e-02, PNorm = 34.0026, GNorm = 2.8844, lr_0 = 2.3433e-04
Loss = 1.9044e-02, PNorm = 34.0091, GNorm = 1.7182, lr_0 = 3.0149e-04
Loss = 1.9524e-02, PNorm = 34.0193, GNorm = 1.7624, lr_0 = 3.6866e-04
Loss = 1.9318e-02, PNorm = 34.0329, GNorm = 0.9338, lr_0 = 4.3582e-04
Loss = 1.9656e-02, PNorm = 34.0487, GNorm = 1.1645, lr_0 = 5.0299e-04
Validation rmse = 1.095526
Epoch 1
Loss = 1.6044e-02, PNorm = 34.0701, GNorm = 0.9862, lr_0 = 5.7015e-04
Loss = 1.7047e-02, PNorm = 34.1032, GNorm = 1.6607, lr_0 = 6.3731e-04
Loss = 1.6668e-02, PNorm = 34.1483, GNorm = 7.8476, lr_0 = 7.0448e-04
Loss = 1.9529e-02, PNorm = 34.2032, GNorm = 1.2675, lr_0 = 7.7164e-04
Loss = 1.6175e-02, PNorm = 34.2580, GNorm = 1.7707, lr_0 = 8.3881e-04
Loss = 1.5232e-02, PNorm = 34.3143, GNorm = 1.6356, lr_0 = 9.0597e-04
Loss = 1.4442e-02, PNorm = 34.3795, GNorm = 3.1514, lr_0 = 9.7313e-04
Validation rmse = 1.029643
Epoch 2
Loss = 1.4233e-02, PNorm = 34.4482, GNorm = 7.9219, lr_0 = 9.9266e-04
Loss = 1.4764e-02, PNorm = 34.5148, GNorm = 4.6443, lr_0 = 9.8055e-04
Loss = 1.5017e-02, PNorm = 34.5785, GNorm = 7.7074, lr_0 = 9.6859e-04
Loss = 1.3021e-02, PNorm = 34.6348, GNorm = 4.5609, lr_0 = 9.5678e-04
Loss = 1.3708e-02, PNorm = 34.6987, GNorm = 2.3397, lr_0 = 9.4510e-04
Loss = 1.1839e-02, PNorm = 34.7677, GNorm = 1.7372, lr_0 = 9.3358e-04
Loss = 1.2465e-02, PNorm = 34.8304, GNorm = 5.1364, lr_0 = 9.2219e-04
Validation rmse = 0.950239
Epoch 3
Loss = 1.1824e-02, PNorm = 34.8897, GNorm = 0.9320, lr_0 = 9.1094e-04
Loss = 1.2816e-02, PNorm = 34.9612, GNorm = 1.8658, lr_0 = 8.9982e-04
Loss = 1.0779e-02, PNorm = 35.0367, GNorm = 7.2344, lr_0 = 8.8885e-04
Loss = 1.1514e-02, PNorm = 35.0998, GNorm = 2.1037, lr_0 = 8.7800e-04
Loss = 1.0074e-02, PNorm = 35.1768, GNorm = 2.8362, lr_0 = 8.6729e-04
Loss = 1.0128e-02, PNorm = 35.2325, GNorm = 10.3264, lr_0 = 8.5671e-04
Validation rmse = 0.846252
Epoch 4
Loss = 1.0805e-02, PNorm = 35.2887, GNorm = 1.5275, lr_0 = 8.4626e-04
Loss = 1.0541e-02, PNorm = 35.3580, GNorm = 1.5353, lr_0 = 8.3594e-04
Loss = 9.5189e-03, PNorm = 35.4198, GNorm = 5.7374, lr_0 = 8.2574e-04
Loss = 9.2285e-03, PNorm = 35.4776, GNorm = 7.6870, lr_0 = 8.1567e-04
Loss = 1.0676e-02, PNorm = 35.5325, GNorm = 4.5256, lr_0 = 8.0572e-04
Loss = 1.1402e-02, PNorm = 35.5899, GNorm = 0.8381, lr_0 = 7.9589e-04
Loss = 9.8085e-03, PNorm = 35.6430, GNorm = 0.8764, lr_0 = 7.8618e-04
Validation rmse = 0.777617
Epoch 5
Loss = 6.4190e-03, PNorm = 35.6904, GNorm = 2.8859, lr_0 = 7.7659e-04
Loss = 8.0051e-03, PNorm = 35.7453, GNorm = 2.7702, lr_0 = 7.6712e-04
Loss = 7.7349e-03, PNorm = 35.8037, GNorm = 6.1730, lr_0 = 7.5776e-04
Loss = 8.5634e-03, PNorm = 35.8543, GNorm = 2.7631, lr_0 = 7.4851e-04
Loss = 9.2651e-03, PNorm = 35.8980, GNorm = 3.3167, lr_0 = 7.3938e-04
Loss = 7.9233e-03, PNorm = 35.9421, GNorm = 1.9432, lr_0 = 7.3036e-04
Loss = 8.6501e-03, PNorm = 35.9755, GNorm = 1.5888, lr_0 = 7.2145e-04
Validation rmse = 0.716362
Epoch 6
Loss = 6.6289e-03, PNorm = 36.0088, GNorm = 3.8814, lr_0 = 7.1265e-04
Loss = 7.2560e-03, PNorm = 36.0503, GNorm = 1.6963, lr_0 = 7.0396e-04
Loss = 8.5494e-03, PNorm = 36.0922, GNorm = 2.2000, lr_0 = 6.9537e-04
Loss = 7.9188e-03, PNorm = 36.1401, GNorm = 2.7192, lr_0 = 6.8689e-04
Loss = 6.9564e-03, PNorm = 36.1852, GNorm = 2.1374, lr_0 = 6.7851e-04
Loss = 7.0961e-03, PNorm = 36.2274, GNorm = 5.6835, lr_0 = 6.7023e-04
Validation rmse = 0.681483
Epoch 7
Loss = 4.9227e-03, PNorm = 36.2613, GNorm = 1.2720, lr_0 = 6.6206e-04
Loss = 7.6363e-03, PNorm = 36.2941, GNorm = 1.7070, lr_0 = 6.5398e-04
Loss = 7.3297e-03, PNorm = 36.3282, GNorm = 2.6868, lr_0 = 6.4600e-04
Loss = 5.9951e-03, PNorm = 36.3700, GNorm = 2.1641, lr_0 = 6.3812e-04
Loss = 6.4864e-03, PNorm = 36.4097, GNorm = 3.9875, lr_0 = 6.3034e-04
Loss = 6.6216e-03, PNorm = 36.4438, GNorm = 5.4106, lr_0 = 6.2265e-04
Loss = 7.6402e-03, PNorm = 36.4830, GNorm = 11.0386, lr_0 = 6.1505e-04
Validation rmse = 0.660948
Epoch 8
Loss = 6.7731e-03, PNorm = 36.5121, GNorm = 1.3113, lr_0 = 6.0755e-04
Loss = 5.7406e-03, PNorm = 36.5516, GNorm = 2.8906, lr_0 = 6.0014e-04
Loss = 6.3031e-03, PNorm = 36.5912, GNorm = 1.4041, lr_0 = 5.9282e-04
Loss = 6.5100e-03, PNorm = 36.6124, GNorm = 2.2330, lr_0 = 5.8559e-04
Loss = 5.8835e-03, PNorm = 36.6455, GNorm = 1.1399, lr_0 = 5.7844e-04
Loss = 5.5183e-03, PNorm = 36.6756, GNorm = 2.5231, lr_0 = 5.7139e-04
Loss = 6.4744e-03, PNorm = 36.6923, GNorm = 4.5361, lr_0 = 5.6442e-04
Validation rmse = 0.673744
Epoch 9
Loss = 5.6547e-03, PNorm = 36.7265, GNorm = 1.3932, lr_0 = 5.5753e-04
Loss = 5.7399e-03, PNorm = 36.7610, GNorm = 5.5116, lr_0 = 5.5073e-04
Loss = 6.3788e-03, PNorm = 36.7931, GNorm = 7.7552, lr_0 = 5.4401e-04
Loss = 5.0080e-03, PNorm = 36.8238, GNorm = 3.2221, lr_0 = 5.3737e-04
Loss = 6.5154e-03, PNorm = 36.8530, GNorm = 2.1949, lr_0 = 5.3082e-04
Loss = 5.3984e-03, PNorm = 36.8785, GNorm = 1.1273, lr_0 = 5.2434e-04
Loss = 5.9605e-03, PNorm = 36.9015, GNorm = 2.1992, lr_0 = 5.1795e-04
Validation rmse = 0.612470
Epoch 10
Loss = 4.1801e-03, PNorm = 36.9297, GNorm = 1.5980, lr_0 = 5.1163e-04
Loss = 5.3338e-03, PNorm = 36.9519, GNorm = 5.5563, lr_0 = 5.0539e-04
Loss = 5.3487e-03, PNorm = 36.9768, GNorm = 2.9012, lr_0 = 4.9922e-04
Loss = 4.7721e-03, PNorm = 37.0032, GNorm = 6.2997, lr_0 = 4.9313e-04
Loss = 5.3035e-03, PNorm = 37.0244, GNorm = 5.0070, lr_0 = 4.8712e-04
Loss = 5.4475e-03, PNorm = 37.0452, GNorm = 1.3148, lr_0 = 4.8117e-04
Validation rmse = 0.599152
Epoch 11
Loss = 4.6106e-03, PNorm = 37.0686, GNorm = 1.2948, lr_0 = 4.7530e-04
Loss = 4.5494e-03, PNorm = 37.0973, GNorm = 2.9446, lr_0 = 4.6951e-04
Loss = 4.5904e-03, PNorm = 37.1205, GNorm = 4.4674, lr_0 = 4.6378e-04
Loss = 6.5441e-03, PNorm = 37.1449, GNorm = 4.1758, lr_0 = 4.5812e-04
Loss = 5.2728e-03, PNorm = 37.1623, GNorm = 1.2148, lr_0 = 4.5253e-04
Loss = 5.8128e-03, PNorm = 37.1879, GNorm = 3.4893, lr_0 = 4.4701e-04
Loss = 6.1061e-03, PNorm = 37.2128, GNorm = 4.3911, lr_0 = 4.4156e-04
Validation rmse = 0.601886
Epoch 12
Loss = 4.9635e-03, PNorm = 37.2358, GNorm = 3.5449, lr_0 = 4.3617e-04
Loss = 5.3584e-03, PNorm = 37.2557, GNorm = 2.7497, lr_0 = 4.3085e-04
Loss = 5.1249e-03, PNorm = 37.2756, GNorm = 1.3065, lr_0 = 4.2560e-04
Loss = 5.3470e-03, PNorm = 37.2975, GNorm = 3.6193, lr_0 = 4.2040e-04
Loss = 5.1561e-03, PNorm = 37.3210, GNorm = 2.4965, lr_0 = 4.1528e-04
Loss = 4.9798e-03, PNorm = 37.3407, GNorm = 5.5098, lr_0 = 4.1021e-04
Loss = 4.3126e-03, PNorm = 37.3599, GNorm = 1.4467, lr_0 = 4.0521e-04
Validation rmse = 0.586711
Epoch 13
Loss = 4.5511e-03, PNorm = 37.3852, GNorm = 3.0332, lr_0 = 4.0026e-04
Loss = 4.5924e-03, PNorm = 37.4029, GNorm = 1.8525, lr_0 = 3.9538e-04
Loss = 4.2703e-03, PNorm = 37.4182, GNorm = 1.5502, lr_0 = 3.9056e-04
Loss = 4.4100e-03, PNorm = 37.4361, GNorm = 1.6179, lr_0 = 3.8579e-04
Loss = 5.4158e-03, PNorm = 37.4565, GNorm = 3.3711, lr_0 = 3.8109e-04
Loss = 4.6872e-03, PNorm = 37.4727, GNorm = 4.4248, lr_0 = 3.7644e-04
Validation rmse = 0.606866
Epoch 14
Loss = 5.1392e-03, PNorm = 37.4893, GNorm = 1.2645, lr_0 = 3.7185e-04
Loss = 3.7369e-03, PNorm = 37.5064, GNorm = 1.2063, lr_0 = 3.6731e-04
Loss = 4.4548e-03, PNorm = 37.5262, GNorm = 1.2384, lr_0 = 3.6283e-04
Loss = 4.1758e-03, PNorm = 37.5435, GNorm = 3.2905, lr_0 = 3.5840e-04
Loss = 4.2098e-03, PNorm = 37.5595, GNorm = 3.0112, lr_0 = 3.5403e-04
Loss = 4.5514e-03, PNorm = 37.5756, GNorm = 1.1340, lr_0 = 3.4971e-04
Loss = 5.0324e-03, PNorm = 37.5939, GNorm = 5.6657, lr_0 = 3.4545e-04
Validation rmse = 0.598335
Epoch 15
Loss = 5.6946e-03, PNorm = 37.6053, GNorm = 6.0967, lr_0 = 3.4123e-04
Loss = 3.9965e-03, PNorm = 37.6220, GNorm = 3.5777, lr_0 = 3.3707e-04
Loss = 3.7355e-03, PNorm = 37.6402, GNorm = 2.0344, lr_0 = 3.3296e-04
Loss = 4.0475e-03, PNorm = 37.6580, GNorm = 2.8410, lr_0 = 3.2890e-04
Loss = 4.1408e-03, PNorm = 37.6771, GNorm = 4.5834, lr_0 = 3.2488e-04
Loss = 4.5729e-03, PNorm = 37.6957, GNorm = 1.5447, lr_0 = 3.2092e-04
Loss = 4.1455e-03, PNorm = 37.7043, GNorm = 1.5346, lr_0 = 3.1700e-04
Validation rmse = 0.565701
Epoch 16
Loss = 4.1059e-03, PNorm = 37.7184, GNorm = 1.7130, lr_0 = 3.1314e-04
Loss = 4.2016e-03, PNorm = 37.7344, GNorm = 3.5562, lr_0 = 3.0932e-04
Loss = 3.2505e-03, PNorm = 37.7476, GNorm = 5.2061, lr_0 = 3.0554e-04
Loss = 4.0497e-03, PNorm = 37.7603, GNorm = 1.4310, lr_0 = 3.0182e-04
Loss = 3.6370e-03, PNorm = 37.7750, GNorm = 1.0919, lr_0 = 2.9814e-04
Loss = 3.6589e-03, PNorm = 37.7924, GNorm = 1.3211, lr_0 = 2.9450e-04
Validation rmse = 0.541609
Epoch 17
Loss = 3.0500e-03, PNorm = 37.8067, GNorm = 1.3624, lr_0 = 2.9091e-04
Loss = 3.6296e-03, PNorm = 37.8223, GNorm = 1.4078, lr_0 = 2.8736e-04
Loss = 3.9889e-03, PNorm = 37.8371, GNorm = 1.9305, lr_0 = 2.8385e-04
Loss = 3.3339e-03, PNorm = 37.8508, GNorm = 3.5065, lr_0 = 2.8039e-04
Loss = 3.7669e-03, PNorm = 37.8627, GNorm = 1.9477, lr_0 = 2.7697e-04
Loss = 4.8995e-03, PNorm = 37.8760, GNorm = 4.6606, lr_0 = 2.7359e-04
Loss = 3.6820e-03, PNorm = 37.8869, GNorm = 2.1990, lr_0 = 2.7025e-04
Validation rmse = 0.543562
Epoch 18
Loss = 3.0512e-03, PNorm = 37.8991, GNorm = 1.0363, lr_0 = 2.6696e-04
Loss = 3.3484e-03, PNorm = 37.9118, GNorm = 0.8725, lr_0 = 2.6370e-04
Loss = 4.5987e-03, PNorm = 37.9248, GNorm = 1.4793, lr_0 = 2.6048e-04
Loss = 3.3593e-03, PNorm = 37.9391, GNorm = 1.1897, lr_0 = 2.5730e-04
Loss = 3.6747e-03, PNorm = 37.9526, GNorm = 3.6469, lr_0 = 2.5417e-04
Loss = 3.2625e-03, PNorm = 37.9634, GNorm = 1.4566, lr_0 = 2.5107e-04
Loss = 3.6711e-03, PNorm = 37.9750, GNorm = 0.9230, lr_0 = 2.4800e-04
Validation rmse = 0.537183
Epoch 19
Loss = 3.3440e-03, PNorm = 37.9880, GNorm = 1.4766, lr_0 = 2.4498e-04
Loss = 3.4332e-03, PNorm = 38.0002, GNorm = 1.5556, lr_0 = 2.4199e-04
Loss = 2.9066e-03, PNorm = 38.0139, GNorm = 3.1226, lr_0 = 2.3904e-04
Loss = 4.0602e-03, PNorm = 38.0262, GNorm = 2.2099, lr_0 = 2.3612e-04
Loss = 3.7012e-03, PNorm = 38.0344, GNorm = 2.1436, lr_0 = 2.3324e-04
Loss = 3.3536e-03, PNorm = 38.0425, GNorm = 1.9469, lr_0 = 2.3040e-04
Loss = 3.0597e-03, PNorm = 38.0531, GNorm = 2.1156, lr_0 = 2.2758e-04
Validation rmse = 0.531237
Epoch 20
Loss = 3.0151e-03, PNorm = 38.0641, GNorm = 1.0571, lr_0 = 2.2481e-04
Loss = 3.5742e-03, PNorm = 38.0740, GNorm = 2.4846, lr_0 = 2.2207e-04
Loss = 3.0753e-03, PNorm = 38.0815, GNorm = 1.1035, lr_0 = 2.1936e-04
Loss = 3.3813e-03, PNorm = 38.0891, GNorm = 1.9528, lr_0 = 2.1668e-04
Loss = 3.8942e-03, PNorm = 38.1001, GNorm = 2.1567, lr_0 = 2.1404e-04
Loss = 3.4523e-03, PNorm = 38.1146, GNorm = 1.2984, lr_0 = 2.1143e-04
Validation rmse = 0.525805
Epoch 21
Loss = 3.6819e-03, PNorm = 38.1292, GNorm = 2.7738, lr_0 = 2.0885e-04
Loss = 2.9065e-03, PNorm = 38.1402, GNorm = 1.4524, lr_0 = 2.0630e-04
Loss = 3.4467e-03, PNorm = 38.1520, GNorm = 4.8129, lr_0 = 2.0378e-04
Loss = 3.4461e-03, PNorm = 38.1637, GNorm = 1.4634, lr_0 = 2.0130e-04
Loss = 3.0484e-03, PNorm = 38.1729, GNorm = 1.8656, lr_0 = 1.9884e-04
Loss = 3.2701e-03, PNorm = 38.1808, GNorm = 1.6662, lr_0 = 1.9642e-04
Loss = 3.2014e-03, PNorm = 38.1874, GNorm = 2.1883, lr_0 = 1.9402e-04
Validation rmse = 0.524640
Epoch 22
Loss = 3.5637e-03, PNorm = 38.1951, GNorm = 1.5870, lr_0 = 1.9165e-04
Loss = 2.8577e-03, PNorm = 38.2039, GNorm = 3.0806, lr_0 = 1.8932e-04
Loss = 3.3500e-03, PNorm = 38.2123, GNorm = 3.3143, lr_0 = 1.8701e-04
Loss = 2.8640e-03, PNorm = 38.2211, GNorm = 1.4091, lr_0 = 1.8472e-04
Loss = 3.0947e-03, PNorm = 38.2299, GNorm = 1.8447, lr_0 = 1.8247e-04
Loss = 2.9902e-03, PNorm = 38.2387, GNorm = 3.2432, lr_0 = 1.8025e-04
Loss = 3.2346e-03, PNorm = 38.2480, GNorm = 2.0456, lr_0 = 1.7805e-04
Validation rmse = 0.530219
Epoch 23
Loss = 2.8087e-03, PNorm = 38.2575, GNorm = 1.2037, lr_0 = 1.7587e-04
Loss = 2.8452e-03, PNorm = 38.2670, GNorm = 2.9396, lr_0 = 1.7373e-04
Loss = 3.1016e-03, PNorm = 38.2747, GNorm = 4.2044, lr_0 = 1.7161e-04
Loss = 2.7522e-03, PNorm = 38.2850, GNorm = 1.2059, lr_0 = 1.6952e-04
Loss = 2.9767e-03, PNorm = 38.2926, GNorm = 2.3357, lr_0 = 1.6745e-04
Loss = 3.6008e-03, PNorm = 38.3011, GNorm = 3.1109, lr_0 = 1.6541e-04
Validation rmse = 0.517032
Epoch 24
Loss = 2.9599e-03, PNorm = 38.3086, GNorm = 1.4131, lr_0 = 1.6339e-04
Loss = 2.6028e-03, PNorm = 38.3158, GNorm = 1.3346, lr_0 = 1.6139e-04
Loss = 3.0420e-03, PNorm = 38.3250, GNorm = 4.3678, lr_0 = 1.5943e-04
Loss = 2.7094e-03, PNorm = 38.3334, GNorm = 3.8561, lr_0 = 1.5748e-04
Loss = 2.7347e-03, PNorm = 38.3391, GNorm = 2.9236, lr_0 = 1.5556e-04
Loss = 3.0846e-03, PNorm = 38.3446, GNorm = 2.8234, lr_0 = 1.5366e-04
Loss = 3.2909e-03, PNorm = 38.3514, GNorm = 2.3545, lr_0 = 1.5179e-04
Validation rmse = 0.529135
Epoch 25
Loss = 3.5794e-03, PNorm = 38.3596, GNorm = 2.6789, lr_0 = 1.4994e-04
Loss = 3.1947e-03, PNorm = 38.3677, GNorm = 2.0553, lr_0 = 1.4811e-04
Loss = 2.8398e-03, PNorm = 38.3762, GNorm = 2.7322, lr_0 = 1.4630e-04
Loss = 2.9100e-03, PNorm = 38.3822, GNorm = 1.0721, lr_0 = 1.4452e-04
Loss = 2.7231e-03, PNorm = 38.3890, GNorm = 2.0353, lr_0 = 1.4275e-04
Loss = 2.8082e-03, PNorm = 38.3958, GNorm = 0.6785, lr_0 = 1.4101e-04
Loss = 2.5995e-03, PNorm = 38.4018, GNorm = 3.1732, lr_0 = 1.3929e-04
Validation rmse = 0.510215
Epoch 26
Loss = 3.1875e-03, PNorm = 38.4089, GNorm = 2.3514, lr_0 = 1.3759e-04
Loss = 2.9524e-03, PNorm = 38.4159, GNorm = 2.5945, lr_0 = 1.3591e-04
Loss = 2.3868e-03, PNorm = 38.4224, GNorm = 2.0598, lr_0 = 1.3426e-04
Loss = 2.7212e-03, PNorm = 38.4285, GNorm = 3.6998, lr_0 = 1.3262e-04
Loss = 2.7205e-03, PNorm = 38.4347, GNorm = 3.2960, lr_0 = 1.3100e-04
Loss = 2.6178e-03, PNorm = 38.4421, GNorm = 2.2159, lr_0 = 1.2940e-04
Validation rmse = 0.514637
Epoch 27
Loss = 2.0818e-03, PNorm = 38.4485, GNorm = 1.0071, lr_0 = 1.2782e-04
Loss = 2.3575e-03, PNorm = 38.4546, GNorm = 3.4831, lr_0 = 1.2626e-04
Loss = 2.3104e-03, PNorm = 38.4597, GNorm = 1.5971, lr_0 = 1.2472e-04
Loss = 3.0159e-03, PNorm = 38.4630, GNorm = 5.7555, lr_0 = 1.2320e-04
Loss = 2.7325e-03, PNorm = 38.4693, GNorm = 1.7628, lr_0 = 1.2170e-04
Loss = 2.9116e-03, PNorm = 38.4769, GNorm = 2.5739, lr_0 = 1.2021e-04
Loss = 3.0264e-03, PNorm = 38.4825, GNorm = 1.0363, lr_0 = 1.1875e-04
Validation rmse = 0.516597
Epoch 28
Loss = 2.0260e-03, PNorm = 38.4884, GNorm = 1.4459, lr_0 = 1.1730e-04
Loss = 2.3834e-03, PNorm = 38.4951, GNorm = 2.2503, lr_0 = 1.1587e-04
Loss = 2.8299e-03, PNorm = 38.4997, GNorm = 1.6589, lr_0 = 1.1446e-04
Loss = 2.7989e-03, PNorm = 38.5039, GNorm = 0.9790, lr_0 = 1.1306e-04
Loss = 2.5980e-03, PNorm = 38.5103, GNorm = 2.8744, lr_0 = 1.1168e-04
Loss = 2.7048e-03, PNorm = 38.5163, GNorm = 1.5564, lr_0 = 1.1032e-04
Loss = 2.3039e-03, PNorm = 38.5225, GNorm = 2.2567, lr_0 = 1.0897e-04
Validation rmse = 0.511678
Epoch 29
Loss = 2.9617e-03, PNorm = 38.5269, GNorm = 3.0897, lr_0 = 1.0764e-04
Loss = 2.2998e-03, PNorm = 38.5325, GNorm = 2.9167, lr_0 = 1.0633e-04
Loss = 2.7842e-03, PNorm = 38.5377, GNorm = 3.7482, lr_0 = 1.0503e-04
Loss = 2.4315e-03, PNorm = 38.5428, GNorm = 1.2837, lr_0 = 1.0375e-04
Loss = 2.2847e-03, PNorm = 38.5479, GNorm = 1.8349, lr_0 = 1.0249e-04
Loss = 2.5091e-03, PNorm = 38.5520, GNorm = 1.7072, lr_0 = 1.0123e-04
Loss = 2.8803e-03, PNorm = 38.5554, GNorm = 6.1535, lr_0 = 1.0000e-04
Validation rmse = 0.517539
Model 0 best validation rmse = 0.510215 on epoch 25
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.556735
Ensemble test rmse = 0.556735
1-fold cross validation
Seed 0 ==> test rmse = 0.556735
Overall test rmse = 0.556735 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 14,176 | train size = 11,340 | val size = 1,418 | test size = 1,418
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Loss = 2.0204e-02, PNorm = 34.0401, GNorm = 2.7945, lr_0 = 1.1991e-04
Loss = 1.8125e-02, PNorm = 34.0432, GNorm = 7.2876, lr_0 = 1.3982e-04
Loss = 1.5964e-02, PNorm = 34.0479, GNorm = 1.2827, lr_0 = 1.5973e-04
Loss = 1.6675e-02, PNorm = 34.0539, GNorm = 7.2174, lr_0 = 1.7965e-04
Loss = 1.3668e-02, PNorm = 34.0622, GNorm = 1.2930, lr_0 = 1.9956e-04
Loss = 1.1120e-02, PNorm = 34.0745, GNorm = 2.8352, lr_0 = 2.1947e-04
Loss = 1.1026e-02, PNorm = 34.0846, GNorm = 5.0577, lr_0 = 2.3938e-04
Loss = 1.0569e-02, PNorm = 34.0957, GNorm = 12.5033, lr_0 = 2.5929e-04
Loss = 1.0805e-02, PNorm = 34.1037, GNorm = 10.1283, lr_0 = 2.7920e-04
Loss = 9.8852e-03, PNorm = 34.1148, GNorm = 3.3495, lr_0 = 2.9912e-04
Loss = 1.0829e-02, PNorm = 34.1294, GNorm = 16.7376, lr_0 = 3.1903e-04
Loss = 1.1644e-02, PNorm = 34.1396, GNorm = 24.4931, lr_0 = 3.3894e-04
Loss = 9.9775e-03, PNorm = 34.1508, GNorm = 10.6780, lr_0 = 3.5885e-04
Loss = 1.0524e-02, PNorm = 34.1628, GNorm = 4.0065, lr_0 = 3.7876e-04
Loss = 9.1791e-03, PNorm = 34.1776, GNorm = 2.5791, lr_0 = 3.9867e-04
Loss = 7.3814e-03, PNorm = 34.1967, GNorm = 5.9641, lr_0 = 4.1858e-04
Loss = 6.5735e-03, PNorm = 34.2153, GNorm = 7.6910, lr_0 = 4.3850e-04
Loss = 6.9693e-03, PNorm = 34.2330, GNorm = 1.3352, lr_0 = 4.5841e-04
Loss = 7.7716e-03, PNorm = 34.2474, GNorm = 5.2007, lr_0 = 4.7832e-04
Loss = 8.0315e-03, PNorm = 34.2642, GNorm = 2.4837, lr_0 = 4.9823e-04
Loss = 6.9018e-03, PNorm = 34.2825, GNorm = 3.8032, lr_0 = 5.1814e-04
Loss = 7.0289e-03, PNorm = 34.3047, GNorm = 9.1042, lr_0 = 5.3805e-04
Validation rmse = 1.080244
Epoch 1
Loss = 6.7592e-03, PNorm = 34.3269, GNorm = 10.0340, lr_0 = 5.5796e-04
Loss = 6.7454e-03, PNorm = 34.3542, GNorm = 5.3271, lr_0 = 5.7788e-04
Loss = 5.8445e-03, PNorm = 34.3810, GNorm = 14.7404, lr_0 = 5.9779e-04
Loss = 5.4496e-03, PNorm = 34.4018, GNorm = 6.2499, lr_0 = 6.1770e-04
Loss = 7.4997e-03, PNorm = 34.4239, GNorm = 4.4459, lr_0 = 6.3761e-04
Loss = 6.1857e-03, PNorm = 34.4550, GNorm = 3.1791, lr_0 = 6.5752e-04
Loss = 5.5781e-03, PNorm = 34.4828, GNorm = 7.4939, lr_0 = 6.7743e-04
Loss = 4.9240e-03, PNorm = 34.5111, GNorm = 7.1633, lr_0 = 6.9735e-04
Loss = 5.1324e-03, PNorm = 34.5430, GNorm = 4.7726, lr_0 = 7.1726e-04
Loss = 5.2637e-03, PNorm = 34.5810, GNorm = 4.5512, lr_0 = 7.3717e-04
Loss = 5.7360e-03, PNorm = 34.6042, GNorm = 6.4522, lr_0 = 7.5708e-04
Loss = 4.4733e-03, PNorm = 34.6321, GNorm = 2.0007, lr_0 = 7.7699e-04
Loss = 4.6513e-03, PNorm = 34.6653, GNorm = 10.7526, lr_0 = 7.9690e-04
Loss = 4.5753e-03, PNorm = 34.6973, GNorm = 8.1051, lr_0 = 8.1681e-04
Loss = 6.9435e-03, PNorm = 34.7258, GNorm = 11.0628, lr_0 = 8.3673e-04
Loss = 5.9546e-03, PNorm = 34.7617, GNorm = 2.8102, lr_0 = 8.5664e-04
Loss = 4.1687e-03, PNorm = 34.7969, GNorm = 1.9306, lr_0 = 8.7655e-04
Loss = 4.5953e-03, PNorm = 34.8318, GNorm = 1.6189, lr_0 = 8.9646e-04
Loss = 4.4475e-03, PNorm = 34.8699, GNorm = 2.0506, lr_0 = 9.1637e-04
Loss = 5.2249e-03, PNorm = 34.9041, GNorm = 5.8861, lr_0 = 9.3628e-04
Loss = 5.4519e-03, PNorm = 34.9392, GNorm = 2.1274, lr_0 = 9.5619e-04
Loss = 4.5658e-03, PNorm = 34.9751, GNorm = 1.5745, lr_0 = 9.7611e-04
Loss = 4.4346e-03, PNorm = 35.0112, GNorm = 4.3205, lr_0 = 9.9602e-04
Validation rmse = 0.784941
Epoch 2
Loss = 3.1846e-03, PNorm = 35.0507, GNorm = 6.2256, lr_0 = 9.9709e-04
Loss = 4.9430e-03, PNorm = 35.0806, GNorm = 7.4084, lr_0 = 9.9347e-04
Loss = 3.7065e-03, PNorm = 35.1084, GNorm = 1.0910, lr_0 = 9.8986e-04
Loss = 4.1002e-03, PNorm = 35.1397, GNorm = 1.4720, lr_0 = 9.8627e-04
Loss = 4.7082e-03, PNorm = 35.1755, GNorm = 2.3326, lr_0 = 9.8269e-04
Loss = 3.0687e-03, PNorm = 35.2005, GNorm = 9.6599, lr_0 = 9.7912e-04
Loss = 3.5627e-03, PNorm = 35.2297, GNorm = 2.5691, lr_0 = 9.7556e-04
Loss = 4.0838e-03, PNorm = 35.2605, GNorm = 3.7831, lr_0 = 9.7202e-04
Loss = 3.2091e-03, PNorm = 35.2939, GNorm = 1.6931, lr_0 = 9.6849e-04
Loss = 4.2535e-03, PNorm = 35.3228, GNorm = 6.8035, lr_0 = 9.6497e-04
Loss = 3.8574e-03, PNorm = 35.3561, GNorm = 5.6788, lr_0 = 9.6146e-04
Loss = 3.9423e-03, PNorm = 35.3833, GNorm = 2.5765, lr_0 = 9.5797e-04
Loss = 5.0573e-03, PNorm = 35.4142, GNorm = 5.1707, lr_0 = 9.5449e-04
Loss = 3.7524e-03, PNorm = 35.4469, GNorm = 4.6643, lr_0 = 9.5103e-04
Loss = 3.8261e-03, PNorm = 35.4836, GNorm = 0.8024, lr_0 = 9.4757e-04
Loss = 3.4909e-03, PNorm = 35.5060, GNorm = 1.4836, lr_0 = 9.4413e-04
Loss = 3.0896e-03, PNorm = 35.5372, GNorm = 1.8792, lr_0 = 9.4070e-04
Loss = 3.5032e-03, PNorm = 35.5634, GNorm = 3.2852, lr_0 = 9.3728e-04
Loss = 3.7636e-03, PNorm = 35.5948, GNorm = 2.9743, lr_0 = 9.3388e-04
Loss = 3.3184e-03, PNorm = 35.6230, GNorm = 1.3367, lr_0 = 9.3049e-04
Loss = 2.7674e-03, PNorm = 35.6333, GNorm = 4.2364, lr_0 = 9.2711e-04
Loss = 3.1651e-03, PNorm = 35.6505, GNorm = 4.1136, lr_0 = 9.2374e-04
Validation rmse = 0.674669
Epoch 3
Loss = 3.7117e-03, PNorm = 35.6735, GNorm = 4.6711, lr_0 = 9.2039e-04
Loss = 3.0578e-03, PNorm = 35.7011, GNorm = 4.9553, lr_0 = 9.1704e-04
Loss = 2.7098e-03, PNorm = 35.7273, GNorm = 1.7422, lr_0 = 9.1371e-04
Loss = 2.3973e-03, PNorm = 35.7502, GNorm = 1.6875, lr_0 = 9.1039e-04
Loss = 3.3592e-03, PNorm = 35.7580, GNorm = 5.2143, lr_0 = 9.0709e-04
Loss = 2.6768e-03, PNorm = 35.7857, GNorm = 1.2400, lr_0 = 9.0379e-04
Loss = 2.5758e-03, PNorm = 35.8091, GNorm = 0.6035, lr_0 = 9.0051e-04
Loss = 2.8314e-03, PNorm = 35.8297, GNorm = 1.5279, lr_0 = 8.9724e-04
Loss = 2.8033e-03, PNorm = 35.8520, GNorm = 1.5825, lr_0 = 8.9398e-04
Loss = 2.2247e-03, PNorm = 35.8709, GNorm = 0.9891, lr_0 = 8.9073e-04
Loss = 3.0408e-03, PNorm = 35.8972, GNorm = 6.1006, lr_0 = 8.8750e-04
Loss = 3.4018e-03, PNorm = 35.9144, GNorm = 4.1608, lr_0 = 8.8427e-04
Loss = 3.5377e-03, PNorm = 35.9344, GNorm = 2.1335, lr_0 = 8.8106e-04
Loss = 2.6147e-03, PNorm = 35.9590, GNorm = 5.5782, lr_0 = 8.7786e-04
Loss = 2.5204e-03, PNorm = 35.9756, GNorm = 3.5657, lr_0 = 8.7467e-04
Loss = 2.3308e-03, PNorm = 36.0006, GNorm = 0.7514, lr_0 = 8.7150e-04
Loss = 2.4497e-03, PNorm = 36.0243, GNorm = 1.4262, lr_0 = 8.6833e-04
Loss = 2.2790e-03, PNorm = 36.0454, GNorm = 1.0882, lr_0 = 8.6518e-04
Loss = 3.1815e-03, PNorm = 36.0694, GNorm = 4.1937, lr_0 = 8.6203e-04
Loss = 3.3172e-03, PNorm = 36.0889, GNorm = 3.2771, lr_0 = 8.5890e-04
Loss = 3.0676e-03, PNorm = 36.1087, GNorm = 1.6853, lr_0 = 8.5578e-04
Loss = 2.9388e-03, PNorm = 36.1328, GNorm = 1.9816, lr_0 = 8.5268e-04
Loss = 2.8646e-03, PNorm = 36.1602, GNorm = 1.4655, lr_0 = 8.4958e-04
Validation rmse = 0.842809
Epoch 4
Loss = 2.9622e-03, PNorm = 36.1772, GNorm = 1.3800, lr_0 = 8.4649e-04
Loss = 2.4349e-03, PNorm = 36.2077, GNorm = 0.5850, lr_0 = 8.4342e-04
Loss = 3.0021e-03, PNorm = 36.2292, GNorm = 1.5422, lr_0 = 8.4035e-04
Loss = 2.0628e-03, PNorm = 36.2532, GNorm = 4.2251, lr_0 = 8.3730e-04
Loss = 2.9473e-03, PNorm = 36.2773, GNorm = 1.9472, lr_0 = 8.3426e-04
Loss = 2.0345e-03, PNorm = 36.2946, GNorm = 0.5681, lr_0 = 8.3123e-04
Loss = 2.1910e-03, PNorm = 36.3130, GNorm = 1.3359, lr_0 = 8.2821e-04
Loss = 2.3287e-03, PNorm = 36.3340, GNorm = 2.3237, lr_0 = 8.2520e-04
Loss = 2.3055e-03, PNorm = 36.3475, GNorm = 2.2559, lr_0 = 8.2221e-04
Loss = 2.3587e-03, PNorm = 36.3615, GNorm = 2.5474, lr_0 = 8.1922e-04
Loss = 2.3243e-03, PNorm = 36.3799, GNorm = 4.4716, lr_0 = 8.1624e-04
Loss = 2.1155e-03, PNorm = 36.4003, GNorm = 0.6391, lr_0 = 8.1328e-04
Loss = 2.2182e-03, PNorm = 36.4136, GNorm = 3.7473, lr_0 = 8.1033e-04
Loss = 2.7097e-03, PNorm = 36.4305, GNorm = 3.3027, lr_0 = 8.0738e-04
Loss = 2.2746e-03, PNorm = 36.4522, GNorm = 1.0251, lr_0 = 8.0445e-04
Loss = 2.6408e-03, PNorm = 36.4716, GNorm = 0.9302, lr_0 = 8.0153e-04
Loss = 2.9328e-03, PNorm = 36.4861, GNorm = 5.7940, lr_0 = 7.9862e-04
Loss = 2.3162e-03, PNorm = 36.5056, GNorm = 2.9840, lr_0 = 7.9572e-04
Loss = 2.5023e-03, PNorm = 36.5237, GNorm = 2.6203, lr_0 = 7.9283e-04
Loss = 2.8763e-03, PNorm = 36.5425, GNorm = 1.9202, lr_0 = 7.8995e-04
Loss = 1.9788e-03, PNorm = 36.5630, GNorm = 2.6096, lr_0 = 7.8708e-04
Loss = 2.5897e-03, PNorm = 36.5767, GNorm = 4.3750, lr_0 = 7.8422e-04
Loss = 2.5747e-03, PNorm = 36.5943, GNorm = 3.8729, lr_0 = 7.8137e-04
Validation rmse = 0.672854
Epoch 5
Loss = 2.3393e-03, PNorm = 36.6109, GNorm = 2.3968, lr_0 = 7.7853e-04
Loss = 2.2909e-03, PNorm = 36.6294, GNorm = 0.7823, lr_0 = 7.7570e-04
Loss = 2.2054e-03, PNorm = 36.6485, GNorm = 4.1565, lr_0 = 7.7289e-04
Loss = 3.0285e-03, PNorm = 36.6743, GNorm = 1.4589, lr_0 = 7.7008e-04
Loss = 2.1350e-03, PNorm = 36.6914, GNorm = 1.0123, lr_0 = 7.6728e-04
Loss = 2.1394e-03, PNorm = 36.7039, GNorm = 1.9269, lr_0 = 7.6450e-04
Loss = 1.7447e-03, PNorm = 36.7223, GNorm = 1.8084, lr_0 = 7.6172e-04
Loss = 2.0935e-03, PNorm = 36.7433, GNorm = 2.3420, lr_0 = 7.5895e-04
Loss = 2.8077e-03, PNorm = 36.7606, GNorm = 7.4820, lr_0 = 7.5620e-04
Loss = 2.1181e-03, PNorm = 36.7730, GNorm = 4.4106, lr_0 = 7.5345e-04
Loss = 2.0408e-03, PNorm = 36.7896, GNorm = 2.5071, lr_0 = 7.5071e-04
Loss = 1.8811e-03, PNorm = 36.8100, GNorm = 0.7225, lr_0 = 7.4799e-04
Loss = 2.3219e-03, PNorm = 36.8224, GNorm = 1.1386, lr_0 = 7.4527e-04
Loss = 2.7213e-03, PNorm = 36.8351, GNorm = 4.5994, lr_0 = 7.4256e-04
Loss = 2.1196e-03, PNorm = 36.8526, GNorm = 2.8525, lr_0 = 7.3987e-04
Loss = 2.5181e-03, PNorm = 36.8655, GNorm = 2.7387, lr_0 = 7.3718e-04
Loss = 1.8549e-03, PNorm = 36.8775, GNorm = 0.8659, lr_0 = 7.3450e-04
Loss = 2.2106e-03, PNorm = 36.8874, GNorm = 2.5404, lr_0 = 7.3183e-04
Loss = 1.9901e-03, PNorm = 36.9025, GNorm = 3.9796, lr_0 = 7.2918e-04
Loss = 1.6775e-03, PNorm = 36.9204, GNorm = 1.1878, lr_0 = 7.2653e-04
Loss = 2.1351e-03, PNorm = 36.9402, GNorm = 1.6588, lr_0 = 7.2389e-04
Loss = 2.2175e-03, PNorm = 36.9562, GNorm = 6.5675, lr_0 = 7.2126e-04
Validation rmse = 0.571246
Epoch 6
Loss = 1.7898e-03, PNorm = 36.9743, GNorm = 1.1275, lr_0 = 7.1864e-04
Loss = 2.0605e-03, PNorm = 36.9900, GNorm = 3.5789, lr_0 = 7.1603e-04
Loss = 2.1124e-03, PNorm = 37.0063, GNorm = 2.4897, lr_0 = 7.1343e-04
Loss = 1.7492e-03, PNorm = 37.0174, GNorm = 3.2604, lr_0 = 7.1084e-04
Loss = 1.8614e-03, PNorm = 37.0334, GNorm = 2.4075, lr_0 = 7.0825e-04
Loss = 1.7141e-03, PNorm = 37.0547, GNorm = 1.7581, lr_0 = 7.0568e-04
Loss = 2.2710e-03, PNorm = 37.0686, GNorm = 3.2564, lr_0 = 7.0312e-04
Loss = 2.3524e-03, PNorm = 37.0874, GNorm = 0.9178, lr_0 = 7.0057e-04
Loss = 2.0289e-03, PNorm = 37.1013, GNorm = 2.1055, lr_0 = 6.9802e-04
Loss = 1.9243e-03, PNorm = 37.1124, GNorm = 1.4115, lr_0 = 6.9549e-04
Loss = 1.6080e-03, PNorm = 37.1267, GNorm = 1.1488, lr_0 = 6.9296e-04
Loss = 1.9554e-03, PNorm = 37.1470, GNorm = 0.9283, lr_0 = 6.9044e-04
Loss = 2.0045e-03, PNorm = 37.1584, GNorm = 1.1485, lr_0 = 6.8794e-04
Loss = 1.6424e-03, PNorm = 37.1749, GNorm = 2.7636, lr_0 = 6.8544e-04
Loss = 2.0473e-03, PNorm = 37.1899, GNorm = 2.0303, lr_0 = 6.8295e-04
Loss = 1.9905e-03, PNorm = 37.2034, GNorm = 3.1145, lr_0 = 6.8047e-04
Loss = 2.4520e-03, PNorm = 37.2197, GNorm = 6.5140, lr_0 = 6.7799e-04
Loss = 1.9157e-03, PNorm = 37.2366, GNorm = 1.1692, lr_0 = 6.7553e-04
Loss = 1.8297e-03, PNorm = 37.2521, GNorm = 1.0895, lr_0 = 6.7308e-04
Loss = 2.0262e-03, PNorm = 37.2656, GNorm = 2.5273, lr_0 = 6.7063e-04
Loss = 1.7923e-03, PNorm = 37.2738, GNorm = 1.9249, lr_0 = 6.6820e-04
Loss = 1.7840e-03, PNorm = 37.2887, GNorm = 1.1284, lr_0 = 6.6577e-04
Loss = 2.1704e-03, PNorm = 37.3025, GNorm = 1.4123, lr_0 = 6.6335e-04
Validation rmse = 0.555050
Epoch 7
Loss = 1.6634e-03, PNorm = 37.3184, GNorm = 0.8137, lr_0 = 6.6094e-04
Loss = 1.7768e-03, PNorm = 37.3297, GNorm = 1.6151, lr_0 = 6.5854e-04
Loss = 1.8577e-03, PNorm = 37.3447, GNorm = 4.5003, lr_0 = 6.5615e-04
Loss = 1.6833e-03, PNorm = 37.3592, GNorm = 0.6302, lr_0 = 6.5377e-04
Loss = 1.3089e-03, PNorm = 37.3708, GNorm = 0.7692, lr_0 = 6.5139e-04
Loss = 1.8554e-03, PNorm = 37.3838, GNorm = 0.6881, lr_0 = 6.4903e-04
Loss = 1.9898e-03, PNorm = 37.3945, GNorm = 3.3621, lr_0 = 6.4667e-04
Loss = 1.7678e-03, PNorm = 37.4084, GNorm = 0.6236, lr_0 = 6.4432e-04
Loss = 1.3514e-03, PNorm = 37.4233, GNorm = 1.2090, lr_0 = 6.4198e-04
Loss = 1.6973e-03, PNorm = 37.4342, GNorm = 0.8167, lr_0 = 6.3965e-04
Loss = 1.9983e-03, PNorm = 37.4514, GNorm = 0.8780, lr_0 = 6.3733e-04
Loss = 1.8420e-03, PNorm = 37.4611, GNorm = 0.7989, lr_0 = 6.3501e-04
Loss = 1.5963e-03, PNorm = 37.4766, GNorm = 1.1573, lr_0 = 6.3270e-04
Loss = 1.5976e-03, PNorm = 37.4888, GNorm = 0.6752, lr_0 = 6.3041e-04
Loss = 1.5998e-03, PNorm = 37.5059, GNorm = 1.1366, lr_0 = 6.2812e-04
Loss = 2.0361e-03, PNorm = 37.5196, GNorm = 1.5495, lr_0 = 6.2584e-04
Loss = 1.8272e-03, PNorm = 37.5286, GNorm = 2.2615, lr_0 = 6.2356e-04
Loss = 1.9378e-03, PNorm = 37.5429, GNorm = 1.7138, lr_0 = 6.2130e-04
Loss = 1.6869e-03, PNorm = 37.5557, GNorm = 0.5198, lr_0 = 6.1904e-04
Loss = 1.6360e-03, PNorm = 37.5693, GNorm = 0.6645, lr_0 = 6.1679e-04
Loss = 1.3012e-03, PNorm = 37.5834, GNorm = 0.8399, lr_0 = 6.1455e-04
Loss = 1.1491e-03, PNorm = 37.5944, GNorm = 2.1492, lr_0 = 6.1232e-04
Validation rmse = 0.522097
Epoch 8
Loss = 1.6457e-03, PNorm = 37.6067, GNorm = 2.2548, lr_0 = 6.1010e-04
Loss = 1.9202e-03, PNorm = 37.6183, GNorm = 3.3897, lr_0 = 6.0788e-04
Loss = 1.5577e-03, PNorm = 37.6322, GNorm = 0.6687, lr_0 = 6.0567e-04
Loss = 1.7172e-03, PNorm = 37.6447, GNorm = 2.4880, lr_0 = 6.0347e-04
Loss = 1.2843e-03, PNorm = 37.6577, GNorm = 1.5530, lr_0 = 6.0128e-04
Loss = 1.7322e-03, PNorm = 37.6764, GNorm = 1.5032, lr_0 = 5.9910e-04
Loss = 1.5144e-03, PNorm = 37.6952, GNorm = 2.4063, lr_0 = 5.9692e-04
Loss = 1.9626e-03, PNorm = 37.7048, GNorm = 1.4500, lr_0 = 5.9475e-04
Loss = 1.9750e-03, PNorm = 37.7127, GNorm = 1.0410, lr_0 = 5.9259e-04
Loss = 1.7377e-03, PNorm = 37.7267, GNorm = 2.3839, lr_0 = 5.9044e-04
Loss = 1.4176e-03, PNorm = 37.7390, GNorm = 0.6718, lr_0 = 5.8830e-04
Loss = 1.4007e-03, PNorm = 37.7538, GNorm = 1.1839, lr_0 = 5.8616e-04
Loss = 1.6286e-03, PNorm = 37.7637, GNorm = 1.0086, lr_0 = 5.8403e-04
Loss = 1.5732e-03, PNorm = 37.7788, GNorm = 0.9640, lr_0 = 5.8191e-04
Loss = 1.6224e-03, PNorm = 37.7874, GNorm = 2.6360, lr_0 = 5.7979e-04
Loss = 1.8538e-03, PNorm = 37.7923, GNorm = 1.3577, lr_0 = 5.7769e-04
Loss = 1.3838e-03, PNorm = 37.8036, GNorm = 2.6582, lr_0 = 5.7559e-04
Loss = 1.6467e-03, PNorm = 37.8190, GNorm = 0.7000, lr_0 = 5.7350e-04
Loss = 1.6907e-03, PNorm = 37.8314, GNorm = 2.1326, lr_0 = 5.7142e-04
Loss = 2.0534e-03, PNorm = 37.8475, GNorm = 2.2117, lr_0 = 5.6934e-04
Loss = 1.6302e-03, PNorm = 37.8597, GNorm = 3.8884, lr_0 = 5.6727e-04
Loss = 1.6399e-03, PNorm = 37.8734, GNorm = 1.4164, lr_0 = 5.6521e-04
Loss = 1.7721e-03, PNorm = 37.8905, GNorm = 0.9844, lr_0 = 5.6316e-04
Validation rmse = 0.547011
Epoch 9
Loss = 1.8680e-03, PNorm = 37.9020, GNorm = 1.4068, lr_0 = 5.6111e-04
Loss = 1.4457e-03, PNorm = 37.9130, GNorm = 1.2629, lr_0 = 5.5908e-04
Loss = 1.6431e-03, PNorm = 37.9273, GNorm = 1.2984, lr_0 = 5.5705e-04
Loss = 1.3963e-03, PNorm = 37.9425, GNorm = 1.7057, lr_0 = 5.5502e-04
Loss = 1.6918e-03, PNorm = 37.9609, GNorm = 0.7483, lr_0 = 5.5301e-04
Loss = 1.4785e-03, PNorm = 37.9727, GNorm = 1.3734, lr_0 = 5.5100e-04
Loss = 1.4102e-03, PNorm = 37.9839, GNorm = 1.5637, lr_0 = 5.4900e-04
Loss = 1.6527e-03, PNorm = 38.0000, GNorm = 0.7657, lr_0 = 5.4700e-04
Loss = 1.3502e-03, PNorm = 38.0096, GNorm = 0.8555, lr_0 = 5.4502e-04
Loss = 1.2486e-03, PNorm = 38.0238, GNorm = 1.4679, lr_0 = 5.4304e-04
Loss = 1.3752e-03, PNorm = 38.0356, GNorm = 1.8731, lr_0 = 5.4106e-04
Loss = 1.3873e-03, PNorm = 38.0450, GNorm = 2.2732, lr_0 = 5.3910e-04
Loss = 1.5074e-03, PNorm = 38.0564, GNorm = 2.9185, lr_0 = 5.3714e-04
Loss = 1.2053e-03, PNorm = 38.0667, GNorm = 0.6804, lr_0 = 5.3519e-04
Loss = 1.4076e-03, PNorm = 38.0725, GNorm = 1.5341, lr_0 = 5.3325e-04
Loss = 1.3536e-03, PNorm = 38.0810, GNorm = 1.4268, lr_0 = 5.3131e-04
Loss = 1.6120e-03, PNorm = 38.0954, GNorm = 0.9226, lr_0 = 5.2938e-04
Loss = 1.6477e-03, PNorm = 38.1063, GNorm = 2.3168, lr_0 = 5.2746e-04
Loss = 1.7701e-03, PNorm = 38.1195, GNorm = 3.6522, lr_0 = 5.2554e-04
Loss = 1.7999e-03, PNorm = 38.1322, GNorm = 2.6582, lr_0 = 5.2363e-04
Loss = 2.1014e-03, PNorm = 38.1429, GNorm = 2.5815, lr_0 = 5.2173e-04
Loss = 1.6381e-03, PNorm = 38.1498, GNorm = 1.3409, lr_0 = 5.1984e-04
Loss = 1.7100e-03, PNorm = 38.1608, GNorm = 4.0370, lr_0 = 5.1795e-04
Validation rmse = 0.519525
Epoch 10
Loss = 1.7196e-03, PNorm = 38.1748, GNorm = 2.0374, lr_0 = 5.1607e-04
Loss = 1.3822e-03, PNorm = 38.1897, GNorm = 1.5534, lr_0 = 5.1419e-04
Loss = 1.7229e-03, PNorm = 38.2045, GNorm = 2.7724, lr_0 = 5.1232e-04
Loss = 1.8192e-03, PNorm = 38.2170, GNorm = 2.2138, lr_0 = 5.1046e-04
Loss = 1.3456e-03, PNorm = 38.2335, GNorm = 1.3993, lr_0 = 5.0861e-04
Loss = 1.3430e-03, PNorm = 38.2430, GNorm = 1.3710, lr_0 = 5.0676e-04
Loss = 9.6773e-04, PNorm = 38.2487, GNorm = 0.8831, lr_0 = 5.0492e-04
Loss = 1.8672e-03, PNorm = 38.2594, GNorm = 1.7316, lr_0 = 5.0309e-04
Loss = 1.3369e-03, PNorm = 38.2651, GNorm = 1.6819, lr_0 = 5.0126e-04
Loss = 1.3240e-03, PNorm = 38.2714, GNorm = 2.6840, lr_0 = 4.9944e-04
Loss = 1.4858e-03, PNorm = 38.2811, GNorm = 0.6031, lr_0 = 4.9763e-04
Loss = 1.4649e-03, PNorm = 38.2944, GNorm = 1.1238, lr_0 = 4.9582e-04
Loss = 1.2874e-03, PNorm = 38.3060, GNorm = 3.0182, lr_0 = 4.9402e-04
Loss = 1.8392e-03, PNorm = 38.3175, GNorm = 2.8417, lr_0 = 4.9222e-04
Loss = 1.1499e-03, PNorm = 38.3276, GNorm = 1.1482, lr_0 = 4.9044e-04
Loss = 1.6408e-03, PNorm = 38.3361, GNorm = 2.8088, lr_0 = 4.8865e-04
Loss = 1.7028e-03, PNorm = 38.3464, GNorm = 3.0351, lr_0 = 4.8688e-04
Loss = 1.2620e-03, PNorm = 38.3595, GNorm = 2.5147, lr_0 = 4.8511e-04
Loss = 1.3781e-03, PNorm = 38.3688, GNorm = 0.7413, lr_0 = 4.8335e-04
Loss = 1.5655e-03, PNorm = 38.3758, GNorm = 1.2316, lr_0 = 4.8159e-04
Loss = 1.2513e-03, PNorm = 38.3870, GNorm = 1.7063, lr_0 = 4.7984e-04
Loss = 1.2492e-03, PNorm = 38.3963, GNorm = 2.0124, lr_0 = 4.7810e-04
Validation rmse = 0.494788
Epoch 11
Loss = 1.4802e-03, PNorm = 38.4090, GNorm = 1.0530, lr_0 = 4.7636e-04
Loss = 1.2738e-03, PNorm = 38.4193, GNorm = 2.5087, lr_0 = 4.7463e-04
Loss = 1.0504e-03, PNorm = 38.4308, GNorm = 2.1111, lr_0 = 4.7291e-04
Loss = 1.2175e-03, PNorm = 38.4370, GNorm = 0.7616, lr_0 = 4.7119e-04
Loss = 1.3122e-03, PNorm = 38.4500, GNorm = 0.6448, lr_0 = 4.6948e-04
Loss = 1.1500e-03, PNorm = 38.4591, GNorm = 2.1492, lr_0 = 4.6778e-04
Loss = 1.4813e-03, PNorm = 38.4657, GNorm = 1.8727, lr_0 = 4.6608e-04
Loss = 1.0976e-03, PNorm = 38.4751, GNorm = 0.8907, lr_0 = 4.6438e-04
Loss = 1.1851e-03, PNorm = 38.4881, GNorm = 1.4720, lr_0 = 4.6270e-04
Loss = 1.4213e-03, PNorm = 38.4995, GNorm = 2.7028, lr_0 = 4.6102e-04
Loss = 1.2075e-03, PNorm = 38.5093, GNorm = 1.8326, lr_0 = 4.5934e-04
Loss = 1.0174e-03, PNorm = 38.5170, GNorm = 0.7337, lr_0 = 4.5767e-04
Loss = 1.0593e-03, PNorm = 38.5233, GNorm = 0.5504, lr_0 = 4.5601e-04
Loss = 1.5975e-03, PNorm = 38.5319, GNorm = 1.2172, lr_0 = 4.5436e-04
Loss = 1.5899e-03, PNorm = 38.5425, GNorm = 1.4844, lr_0 = 4.5271e-04
Loss = 1.1067e-03, PNorm = 38.5539, GNorm = 0.7733, lr_0 = 4.5106e-04
Loss = 1.2972e-03, PNorm = 38.5644, GNorm = 0.9729, lr_0 = 4.4942e-04
Loss = 1.0662e-03, PNorm = 38.5741, GNorm = 0.4389, lr_0 = 4.4779e-04
Loss = 1.4674e-03, PNorm = 38.5828, GNorm = 0.7967, lr_0 = 4.4616e-04
Loss = 1.3373e-03, PNorm = 38.5899, GNorm = 1.1748, lr_0 = 4.4454e-04
Loss = 1.3334e-03, PNorm = 38.5994, GNorm = 1.2156, lr_0 = 4.4293e-04
Loss = 1.2402e-03, PNorm = 38.6042, GNorm = 1.5107, lr_0 = 4.4132e-04
Loss = 1.9898e-03, PNorm = 38.6103, GNorm = 1.0545, lr_0 = 4.3972e-04
Validation rmse = 0.491825
Epoch 12
Loss = 1.4764e-03, PNorm = 38.6183, GNorm = 1.9023, lr_0 = 4.3812e-04
Loss = 1.3474e-03, PNorm = 38.6324, GNorm = 0.8484, lr_0 = 4.3653e-04
Loss = 1.0086e-03, PNorm = 38.6427, GNorm = 2.0449, lr_0 = 4.3494e-04
Loss = 1.5483e-03, PNorm = 38.6546, GNorm = 3.9707, lr_0 = 4.3336e-04
Loss = 1.5261e-03, PNorm = 38.6667, GNorm = 2.4887, lr_0 = 4.3179e-04
Loss = 1.3157e-03, PNorm = 38.6733, GNorm = 1.0243, lr_0 = 4.3022e-04
Loss = 1.1729e-03, PNorm = 38.6835, GNorm = 1.0981, lr_0 = 4.2866e-04
Loss = 1.2444e-03, PNorm = 38.6963, GNorm = 1.0365, lr_0 = 4.2710e-04
Loss = 1.1287e-03, PNorm = 38.7011, GNorm = 0.8715, lr_0 = 4.2555e-04
Loss = 1.1976e-03, PNorm = 38.7087, GNorm = 2.2628, lr_0 = 4.2400e-04
Loss = 1.4211e-03, PNorm = 38.7182, GNorm = 0.7873, lr_0 = 4.2246e-04
Loss = 1.5738e-03, PNorm = 38.7292, GNorm = 2.0474, lr_0 = 4.2093e-04
Loss = 1.2527e-03, PNorm = 38.7383, GNorm = 1.1468, lr_0 = 4.1940e-04
Loss = 1.0992e-03, PNorm = 38.7451, GNorm = 1.9089, lr_0 = 4.1788e-04
Loss = 1.0751e-03, PNorm = 38.7537, GNorm = 1.8759, lr_0 = 4.1636e-04
Loss = 1.2970e-03, PNorm = 38.7626, GNorm = 0.5553, lr_0 = 4.1485e-04
Loss = 1.1539e-03, PNorm = 38.7722, GNorm = 0.7137, lr_0 = 4.1334e-04
Loss = 1.0906e-03, PNorm = 38.7808, GNorm = 0.6225, lr_0 = 4.1184e-04
Loss = 1.1471e-03, PNorm = 38.7897, GNorm = 0.7994, lr_0 = 4.1034e-04
Loss = 1.0601e-03, PNorm = 38.7927, GNorm = 1.3646, lr_0 = 4.0885e-04
Loss = 1.2314e-03, PNorm = 38.7985, GNorm = 2.3523, lr_0 = 4.0737e-04
Loss = 1.1500e-03, PNorm = 38.8068, GNorm = 1.8581, lr_0 = 4.0589e-04
Validation rmse = 0.468476
Epoch 13
Loss = 7.6246e-04, PNorm = 38.8138, GNorm = 0.7470, lr_0 = 4.0441e-04
Loss = 1.0968e-03, PNorm = 38.8210, GNorm = 3.3051, lr_0 = 4.0295e-04
Loss = 1.4458e-03, PNorm = 38.8343, GNorm = 3.3930, lr_0 = 4.0148e-04
Loss = 1.3410e-03, PNorm = 38.8446, GNorm = 3.6848, lr_0 = 4.0002e-04
Loss = 1.4337e-03, PNorm = 38.8566, GNorm = 0.5558, lr_0 = 3.9857e-04
Loss = 1.2347e-03, PNorm = 38.8666, GNorm = 2.3501, lr_0 = 3.9712e-04
Loss = 1.2691e-03, PNorm = 38.8720, GNorm = 0.6405, lr_0 = 3.9568e-04
Loss = 1.0946e-03, PNorm = 38.8798, GNorm = 1.1356, lr_0 = 3.9424e-04
Loss = 1.3642e-03, PNorm = 38.8894, GNorm = 2.0145, lr_0 = 3.9281e-04
Loss = 1.3844e-03, PNorm = 38.8943, GNorm = 0.9994, lr_0 = 3.9139e-04
Loss = 1.2405e-03, PNorm = 38.9030, GNorm = 0.8511, lr_0 = 3.8996e-04
Loss = 1.2930e-03, PNorm = 38.9132, GNorm = 0.9632, lr_0 = 3.8855e-04
Loss = 1.4216e-03, PNorm = 38.9212, GNorm = 2.3310, lr_0 = 3.8714e-04
Loss = 1.1452e-03, PNorm = 38.9268, GNorm = 0.9169, lr_0 = 3.8573e-04
Loss = 1.4252e-03, PNorm = 38.9345, GNorm = 0.8123, lr_0 = 3.8433e-04
Loss = 8.8995e-04, PNorm = 38.9429, GNorm = 0.7221, lr_0 = 3.8293e-04
Loss = 1.1830e-03, PNorm = 38.9488, GNorm = 1.3092, lr_0 = 3.8154e-04
Loss = 1.0552e-03, PNorm = 38.9515, GNorm = 0.6849, lr_0 = 3.8016e-04
Loss = 1.2819e-03, PNorm = 38.9572, GNorm = 2.5244, lr_0 = 3.7878e-04
Loss = 1.3255e-03, PNorm = 38.9643, GNorm = 1.8919, lr_0 = 3.7740e-04
Loss = 1.0509e-03, PNorm = 38.9701, GNorm = 1.0657, lr_0 = 3.7603e-04
Loss = 1.2813e-03, PNorm = 38.9816, GNorm = 1.5325, lr_0 = 3.7466e-04
Loss = 8.5868e-04, PNorm = 38.9914, GNorm = 0.8942, lr_0 = 3.7330e-04
Validation rmse = 0.486558
Epoch 14
Loss = 1.2627e-03, PNorm = 38.9998, GNorm = 0.7965, lr_0 = 3.7195e-04
Loss = 7.9869e-04, PNorm = 39.0070, GNorm = 1.0498, lr_0 = 3.7060e-04
Loss = 1.1953e-03, PNorm = 39.0154, GNorm = 1.4242, lr_0 = 3.6925e-04
Loss = 1.0228e-03, PNorm = 39.0256, GNorm = 2.1871, lr_0 = 3.6791e-04
Loss = 8.7019e-04, PNorm = 39.0307, GNorm = 1.6972, lr_0 = 3.6657e-04
Loss = 1.0448e-03, PNorm = 39.0358, GNorm = 1.0491, lr_0 = 3.6524e-04
Loss = 1.2367e-03, PNorm = 39.0431, GNorm = 3.1801, lr_0 = 3.6391e-04
Loss = 1.4962e-03, PNorm = 39.0508, GNorm = 1.3922, lr_0 = 3.6259e-04
Loss = 1.1867e-03, PNorm = 39.0541, GNorm = 2.0999, lr_0 = 3.6128e-04
Loss = 1.1292e-03, PNorm = 39.0596, GNorm = 0.7496, lr_0 = 3.5996e-04
Loss = 1.0414e-03, PNorm = 39.0684, GNorm = 1.4206, lr_0 = 3.5866e-04
Loss = 1.0506e-03, PNorm = 39.0749, GNorm = 0.5996, lr_0 = 3.5735e-04
Loss = 1.1427e-03, PNorm = 39.0827, GNorm = 1.3074, lr_0 = 3.5605e-04
Loss = 1.4728e-03, PNorm = 39.0889, GNorm = 1.4452, lr_0 = 3.5476e-04
Loss = 1.1713e-03, PNorm = 39.0896, GNorm = 0.7174, lr_0 = 3.5347e-04
Loss = 9.3502e-04, PNorm = 39.0941, GNorm = 1.7413, lr_0 = 3.5219e-04
Loss = 9.1529e-04, PNorm = 39.1047, GNorm = 0.7062, lr_0 = 3.5091e-04
Loss = 1.2402e-03, PNorm = 39.1112, GNorm = 1.6585, lr_0 = 3.4964e-04
Loss = 9.5659e-04, PNorm = 39.1205, GNorm = 0.4737, lr_0 = 3.4837e-04
Loss = 8.7381e-04, PNorm = 39.1254, GNorm = 1.4818, lr_0 = 3.4710e-04
Loss = 1.3290e-03, PNorm = 39.1307, GNorm = 1.5191, lr_0 = 3.4584e-04
Loss = 1.0267e-03, PNorm = 39.1393, GNorm = 0.7691, lr_0 = 3.4458e-04
Loss = 9.3646e-04, PNorm = 39.1445, GNorm = 0.9218, lr_0 = 3.4333e-04
Validation rmse = 0.479527
Epoch 15
Loss = 1.0928e-03, PNorm = 39.1505, GNorm = 0.8964, lr_0 = 3.4208e-04
Loss = 8.5519e-04, PNorm = 39.1607, GNorm = 0.4753, lr_0 = 3.4084e-04
Loss = 1.1198e-03, PNorm = 39.1666, GNorm = 0.8145, lr_0 = 3.3960e-04
Loss = 9.2479e-04, PNorm = 39.1727, GNorm = 0.6207, lr_0 = 3.3837e-04
Loss = 9.5902e-04, PNorm = 39.1775, GNorm = 0.8187, lr_0 = 3.3714e-04
Loss = 8.6091e-04, PNorm = 39.1858, GNorm = 0.6113, lr_0 = 3.3592e-04
Loss = 8.8721e-04, PNorm = 39.1913, GNorm = 0.9636, lr_0 = 3.3470e-04
Loss = 9.9731e-04, PNorm = 39.1997, GNorm = 1.5046, lr_0 = 3.3348e-04
Loss = 1.3086e-03, PNorm = 39.2042, GNorm = 1.1728, lr_0 = 3.3227e-04
Loss = 1.0241e-03, PNorm = 39.2093, GNorm = 0.5921, lr_0 = 3.3106e-04
Loss = 1.2671e-03, PNorm = 39.2175, GNorm = 1.7033, lr_0 = 3.2986e-04
Loss = 8.4426e-04, PNorm = 39.2249, GNorm = 2.4182, lr_0 = 3.2866e-04
Loss = 1.0684e-03, PNorm = 39.2277, GNorm = 1.3338, lr_0 = 3.2747e-04
Loss = 1.0509e-03, PNorm = 39.2295, GNorm = 1.4341, lr_0 = 3.2628e-04
Loss = 9.4647e-04, PNorm = 39.2399, GNorm = 0.7110, lr_0 = 3.2509e-04
Loss = 1.1980e-03, PNorm = 39.2460, GNorm = 1.7288, lr_0 = 3.2391e-04
Loss = 1.3241e-03, PNorm = 39.2526, GNorm = 1.0062, lr_0 = 3.2274e-04
Loss = 8.7434e-04, PNorm = 39.2601, GNorm = 0.8567, lr_0 = 3.2157e-04
Loss = 1.1774e-03, PNorm = 39.2650, GNorm = 1.9232, lr_0 = 3.2040e-04
Loss = 1.2807e-03, PNorm = 39.2729, GNorm = 1.2949, lr_0 = 3.1923e-04
Loss = 1.3783e-03, PNorm = 39.2821, GNorm = 2.5331, lr_0 = 3.1807e-04
Loss = 1.1094e-03, PNorm = 39.2883, GNorm = 0.8377, lr_0 = 3.1692e-04
Validation rmse = 0.508928
Epoch 16
Loss = 8.4803e-04, PNorm = 39.2938, GNorm = 1.1627, lr_0 = 3.1577e-04
Loss = 9.6947e-04, PNorm = 39.2985, GNorm = 1.1302, lr_0 = 3.1462e-04
Loss = 1.1166e-03, PNorm = 39.3041, GNorm = 1.1191, lr_0 = 3.1348e-04
Loss = 9.2892e-04, PNorm = 39.3110, GNorm = 1.2564, lr_0 = 3.1234e-04
Loss = 9.6835e-04, PNorm = 39.3204, GNorm = 1.3005, lr_0 = 3.1121e-04
Loss = 1.0611e-03, PNorm = 39.3283, GNorm = 1.4406, lr_0 = 3.1007e-04
Loss = 9.8579e-04, PNorm = 39.3325, GNorm = 1.7988, lr_0 = 3.0895e-04
Loss = 1.4813e-03, PNorm = 39.3416, GNorm = 1.7398, lr_0 = 3.0783e-04
Loss = 1.4145e-03, PNorm = 39.3494, GNorm = 1.6646, lr_0 = 3.0671e-04
Loss = 7.9247e-04, PNorm = 39.3556, GNorm = 0.5798, lr_0 = 3.0559e-04
Loss = 1.2024e-03, PNorm = 39.3654, GNorm = 1.2991, lr_0 = 3.0448e-04
Loss = 9.0217e-04, PNorm = 39.3716, GNorm = 1.3330, lr_0 = 3.0338e-04
Loss = 8.6161e-04, PNorm = 39.3783, GNorm = 0.9248, lr_0 = 3.0228e-04
Loss = 8.4657e-04, PNorm = 39.3836, GNorm = 1.2263, lr_0 = 3.0118e-04
Loss = 9.2264e-04, PNorm = 39.3900, GNorm = 1.2556, lr_0 = 3.0008e-04
Loss = 1.0934e-03, PNorm = 39.3969, GNorm = 0.7188, lr_0 = 2.9899e-04
Loss = 1.0054e-03, PNorm = 39.3991, GNorm = 0.8282, lr_0 = 2.9791e-04
Loss = 1.1539e-03, PNorm = 39.4053, GNorm = 1.0445, lr_0 = 2.9683e-04
Loss = 9.1140e-04, PNorm = 39.4076, GNorm = 1.1519, lr_0 = 2.9575e-04
Loss = 9.3500e-04, PNorm = 39.4077, GNorm = 1.6721, lr_0 = 2.9467e-04
Loss = 8.9337e-04, PNorm = 39.4122, GNorm = 2.0196, lr_0 = 2.9360e-04
Loss = 9.6635e-04, PNorm = 39.4187, GNorm = 0.8434, lr_0 = 2.9254e-04
Loss = 1.1719e-03, PNorm = 39.4238, GNorm = 0.8273, lr_0 = 2.9148e-04
Validation rmse = 0.460841
Epoch 17
Loss = 9.3297e-04, PNorm = 39.4294, GNorm = 0.8681, lr_0 = 2.9042e-04
Loss = 8.7436e-04, PNorm = 39.4352, GNorm = 0.9487, lr_0 = 2.8936e-04
Loss = 8.5970e-04, PNorm = 39.4416, GNorm = 0.7508, lr_0 = 2.8831e-04
Loss = 1.0601e-03, PNorm = 39.4463, GNorm = 1.5891, lr_0 = 2.8726e-04
Loss = 8.0675e-04, PNorm = 39.4495, GNorm = 0.5116, lr_0 = 2.8622e-04
Loss = 1.0355e-03, PNorm = 39.4524, GNorm = 0.8064, lr_0 = 2.8518e-04
Loss = 8.8070e-04, PNorm = 39.4542, GNorm = 1.5811, lr_0 = 2.8414e-04
Loss = 1.0507e-03, PNorm = 39.4588, GNorm = 0.7466, lr_0 = 2.8311e-04
Loss = 9.9446e-04, PNorm = 39.4663, GNorm = 0.6862, lr_0 = 2.8208e-04
Loss = 9.0440e-04, PNorm = 39.4731, GNorm = 2.2122, lr_0 = 2.8106e-04
Loss = 1.1803e-03, PNorm = 39.4816, GNorm = 1.8737, lr_0 = 2.8004e-04
Loss = 7.6462e-04, PNorm = 39.4894, GNorm = 0.7831, lr_0 = 2.7902e-04
Loss = 1.1492e-03, PNorm = 39.4946, GNorm = 1.0979, lr_0 = 2.7801e-04
Loss = 1.1064e-03, PNorm = 39.5004, GNorm = 1.0966, lr_0 = 2.7700e-04
Loss = 8.1605e-04, PNorm = 39.5060, GNorm = 0.5426, lr_0 = 2.7599e-04
Loss = 7.7784e-04, PNorm = 39.5109, GNorm = 1.4869, lr_0 = 2.7499e-04
Loss = 8.3856e-04, PNorm = 39.5166, GNorm = 1.9381, lr_0 = 2.7399e-04
Loss = 9.7984e-04, PNorm = 39.5213, GNorm = 1.1403, lr_0 = 2.7300e-04
Loss = 8.4225e-04, PNorm = 39.5262, GNorm = 0.4851, lr_0 = 2.7200e-04
Loss = 8.9821e-04, PNorm = 39.5323, GNorm = 1.9125, lr_0 = 2.7102e-04
Loss = 1.1087e-03, PNorm = 39.5401, GNorm = 1.8527, lr_0 = 2.7003e-04
Loss = 9.5506e-04, PNorm = 39.5423, GNorm = 1.1222, lr_0 = 2.6905e-04
Validation rmse = 0.462244
Epoch 18
Loss = 9.2667e-04, PNorm = 39.5446, GNorm = 1.0927, lr_0 = 2.6807e-04
Loss = 1.0656e-03, PNorm = 39.5511, GNorm = 0.8620, lr_0 = 2.6710e-04
Loss = 1.0229e-03, PNorm = 39.5593, GNorm = 1.8627, lr_0 = 2.6613e-04
Loss = 8.7039e-04, PNorm = 39.5668, GNorm = 1.5578, lr_0 = 2.6516e-04
Loss = 8.3814e-04, PNorm = 39.5722, GNorm = 0.8721, lr_0 = 2.6420e-04
Loss = 7.8862e-04, PNorm = 39.5768, GNorm = 0.9956, lr_0 = 2.6324e-04
Loss = 6.2341e-04, PNorm = 39.5815, GNorm = 0.5888, lr_0 = 2.6229e-04
Loss = 9.8819e-04, PNorm = 39.5871, GNorm = 0.7130, lr_0 = 2.6133e-04
Loss = 8.9326e-04, PNorm = 39.5907, GNorm = 2.3909, lr_0 = 2.6038e-04
Loss = 1.1443e-03, PNorm = 39.5934, GNorm = 1.9032, lr_0 = 2.5944e-04
Loss = 1.0552e-03, PNorm = 39.5990, GNorm = 1.1870, lr_0 = 2.5850e-04
Loss = 8.1751e-04, PNorm = 39.6037, GNorm = 0.6904, lr_0 = 2.5756e-04
Loss = 7.7123e-04, PNorm = 39.6073, GNorm = 1.3870, lr_0 = 2.5662e-04
Loss = 8.9613e-04, PNorm = 39.6117, GNorm = 0.8585, lr_0 = 2.5569e-04
Loss = 8.2319e-04, PNorm = 39.6161, GNorm = 0.6672, lr_0 = 2.5476e-04
Loss = 9.2125e-04, PNorm = 39.6223, GNorm = 1.3869, lr_0 = 2.5383e-04
Loss = 8.9117e-04, PNorm = 39.6267, GNorm = 0.7608, lr_0 = 2.5291e-04
Loss = 6.7672e-04, PNorm = 39.6308, GNorm = 0.6714, lr_0 = 2.5199e-04
Loss = 1.3922e-03, PNorm = 39.6369, GNorm = 3.6986, lr_0 = 2.5108e-04
Loss = 9.6591e-04, PNorm = 39.6413, GNorm = 2.1450, lr_0 = 2.5017e-04
Loss = 9.1638e-04, PNorm = 39.6435, GNorm = 0.7278, lr_0 = 2.4926e-04
Loss = 1.0163e-03, PNorm = 39.6484, GNorm = 1.1292, lr_0 = 2.4835e-04
Loss = 9.3533e-04, PNorm = 39.6528, GNorm = 0.9855, lr_0 = 2.4745e-04
Validation rmse = 0.448110
Epoch 19
Loss = 8.5263e-04, PNorm = 39.6594, GNorm = 0.6556, lr_0 = 2.4655e-04
Loss = 7.5495e-04, PNorm = 39.6642, GNorm = 0.8177, lr_0 = 2.4566e-04
Loss = 1.0583e-03, PNorm = 39.6693, GNorm = 1.5274, lr_0 = 2.4476e-04
Loss = 8.3148e-04, PNorm = 39.6745, GNorm = 1.4933, lr_0 = 2.4388e-04
Loss = 7.4746e-04, PNorm = 39.6786, GNorm = 1.8682, lr_0 = 2.4299e-04
Loss = 9.5040e-04, PNorm = 39.6814, GNorm = 1.0759, lr_0 = 2.4211e-04
Loss = 8.2010e-04, PNorm = 39.6847, GNorm = 0.8053, lr_0 = 2.4123e-04
Loss = 1.0665e-03, PNorm = 39.6909, GNorm = 1.0200, lr_0 = 2.4035e-04
Loss = 8.9254e-04, PNorm = 39.6956, GNorm = 1.6716, lr_0 = 2.3948e-04
Loss = 9.2945e-04, PNorm = 39.7007, GNorm = 0.6957, lr_0 = 2.3861e-04
Loss = 7.2321e-04, PNorm = 39.7059, GNorm = 1.0664, lr_0 = 2.3774e-04
Loss = 1.0279e-03, PNorm = 39.7099, GNorm = 1.2358, lr_0 = 2.3688e-04
Loss = 8.4962e-04, PNorm = 39.7167, GNorm = 1.7081, lr_0 = 2.3602e-04
Loss = 7.6728e-04, PNorm = 39.7223, GNorm = 0.6625, lr_0 = 2.3516e-04
Loss = 9.2402e-04, PNorm = 39.7264, GNorm = 1.0229, lr_0 = 2.3431e-04
Loss = 8.0175e-04, PNorm = 39.7292, GNorm = 0.5363, lr_0 = 2.3346e-04
Loss = 1.4506e-03, PNorm = 39.7326, GNorm = 1.0284, lr_0 = 2.3261e-04
Loss = 8.5291e-04, PNorm = 39.7381, GNorm = 2.1554, lr_0 = 2.3176e-04
Loss = 8.8178e-04, PNorm = 39.7423, GNorm = 1.6596, lr_0 = 2.3092e-04
Loss = 7.5832e-04, PNorm = 39.7451, GNorm = 1.0753, lr_0 = 2.3008e-04
Loss = 8.7084e-04, PNorm = 39.7510, GNorm = 1.5636, lr_0 = 2.2925e-04
Loss = 8.6446e-04, PNorm = 39.7543, GNorm = 2.3261, lr_0 = 2.2841e-04
Loss = 1.0896e-03, PNorm = 39.7591, GNorm = 0.5896, lr_0 = 2.2758e-04
Validation rmse = 0.451991
Epoch 20
Loss = 7.2138e-04, PNorm = 39.7638, GNorm = 1.3298, lr_0 = 2.2676e-04
Loss = 7.8816e-04, PNorm = 39.7700, GNorm = 0.7469, lr_0 = 2.2593e-04
Loss = 8.2527e-04, PNorm = 39.7741, GNorm = 0.5176, lr_0 = 2.2511e-04
Loss = 9.8022e-04, PNorm = 39.7791, GNorm = 1.5229, lr_0 = 2.2430e-04
Loss = 7.2770e-04, PNorm = 39.7819, GNorm = 1.6357, lr_0 = 2.2348e-04
Loss = 8.3384e-04, PNorm = 39.7853, GNorm = 0.8369, lr_0 = 2.2267e-04
Loss = 6.7981e-04, PNorm = 39.7879, GNorm = 1.7120, lr_0 = 2.2186e-04
Loss = 9.2354e-04, PNorm = 39.7922, GNorm = 1.4704, lr_0 = 2.2106e-04
Loss = 8.5468e-04, PNorm = 39.7962, GNorm = 0.7993, lr_0 = 2.2025e-04
Loss = 7.5418e-04, PNorm = 39.8007, GNorm = 0.8672, lr_0 = 2.1945e-04
Loss = 8.2968e-04, PNorm = 39.8050, GNorm = 0.9557, lr_0 = 2.1866e-04
Loss = 1.0454e-03, PNorm = 39.8071, GNorm = 1.2054, lr_0 = 2.1786e-04
Loss = 9.3965e-04, PNorm = 39.8106, GNorm = 1.1619, lr_0 = 2.1707e-04
Loss = 7.6939e-04, PNorm = 39.8158, GNorm = 1.3746, lr_0 = 2.1628e-04
Loss = 8.0375e-04, PNorm = 39.8208, GNorm = 0.6026, lr_0 = 2.1550e-04
Loss = 9.9844e-04, PNorm = 39.8227, GNorm = 1.1672, lr_0 = 2.1471e-04
Loss = 9.0631e-04, PNorm = 39.8255, GNorm = 0.7929, lr_0 = 2.1393e-04
Loss = 7.9048e-04, PNorm = 39.8287, GNorm = 1.6759, lr_0 = 2.1316e-04
Loss = 8.0386e-04, PNorm = 39.8340, GNorm = 1.6227, lr_0 = 2.1238e-04
Loss = 7.9300e-04, PNorm = 39.8409, GNorm = 1.7469, lr_0 = 2.1161e-04
Loss = 9.0178e-04, PNorm = 39.8456, GNorm = 0.8350, lr_0 = 2.1084e-04
Loss = 1.0837e-03, PNorm = 39.8487, GNorm = 1.7360, lr_0 = 2.1008e-04
Validation rmse = 0.465142
Epoch 21
Loss = 5.3791e-04, PNorm = 39.8518, GNorm = 0.6994, lr_0 = 2.0931e-04
Loss = 7.0102e-04, PNorm = 39.8559, GNorm = 0.7734, lr_0 = 2.0855e-04
Loss = 8.7616e-04, PNorm = 39.8606, GNorm = 0.8378, lr_0 = 2.0780e-04
Loss = 8.1579e-04, PNorm = 39.8643, GNorm = 1.4035, lr_0 = 2.0704e-04
Loss = 7.9910e-04, PNorm = 39.8666, GNorm = 0.5511, lr_0 = 2.0629e-04
Loss = 6.8558e-04, PNorm = 39.8706, GNorm = 0.8108, lr_0 = 2.0554e-04
Loss = 9.0564e-04, PNorm = 39.8738, GNorm = 2.2290, lr_0 = 2.0479e-04
Loss = 8.1019e-04, PNorm = 39.8770, GNorm = 1.0095, lr_0 = 2.0405e-04
Loss = 6.5814e-04, PNorm = 39.8801, GNorm = 0.9958, lr_0 = 2.0331e-04
Loss = 9.8437e-04, PNorm = 39.8839, GNorm = 1.2010, lr_0 = 2.0257e-04
Loss = 7.2127e-04, PNorm = 39.8870, GNorm = 1.5399, lr_0 = 2.0183e-04
Loss = 1.0870e-03, PNorm = 39.8898, GNorm = 0.7830, lr_0 = 2.0110e-04
Loss = 9.0021e-04, PNorm = 39.8935, GNorm = 1.0793, lr_0 = 2.0037e-04
Loss = 7.6199e-04, PNorm = 39.8980, GNorm = 0.8250, lr_0 = 1.9964e-04
Loss = 7.0608e-04, PNorm = 39.9025, GNorm = 0.5686, lr_0 = 1.9892e-04
Loss = 6.2174e-04, PNorm = 39.9063, GNorm = 0.3441, lr_0 = 1.9819e-04
Loss = 1.0975e-03, PNorm = 39.9108, GNorm = 1.3052, lr_0 = 1.9747e-04
Loss = 9.8870e-04, PNorm = 39.9140, GNorm = 1.8956, lr_0 = 1.9676e-04
Loss = 8.7503e-04, PNorm = 39.9167, GNorm = 0.6392, lr_0 = 1.9604e-04
Loss = 7.6601e-04, PNorm = 39.9190, GNorm = 0.8208, lr_0 = 1.9533e-04
Loss = 6.4668e-04, PNorm = 39.9223, GNorm = 0.4443, lr_0 = 1.9462e-04
Loss = 8.2771e-04, PNorm = 39.9267, GNorm = 1.5588, lr_0 = 1.9391e-04
Loss = 7.1099e-04, PNorm = 39.9313, GNorm = 0.8828, lr_0 = 1.9321e-04
Validation rmse = 0.454144
Epoch 22
Loss = 7.0923e-04, PNorm = 39.9322, GNorm = 1.3403, lr_0 = 1.9251e-04
Loss = 6.9348e-04, PNorm = 39.9353, GNorm = 1.2754, lr_0 = 1.9181e-04
Loss = 6.1443e-04, PNorm = 39.9392, GNorm = 0.6670, lr_0 = 1.9111e-04
Loss = 8.9330e-04, PNorm = 39.9426, GNorm = 1.3399, lr_0 = 1.9042e-04
Loss = 7.4082e-04, PNorm = 39.9461, GNorm = 0.5942, lr_0 = 1.8973e-04
Loss = 1.2633e-03, PNorm = 39.9494, GNorm = 1.1612, lr_0 = 1.8904e-04
Loss = 8.8833e-04, PNorm = 39.9540, GNorm = 1.2681, lr_0 = 1.8835e-04
Loss = 6.7086e-04, PNorm = 39.9569, GNorm = 0.6408, lr_0 = 1.8767e-04
Loss = 6.3532e-04, PNorm = 39.9614, GNorm = 0.6505, lr_0 = 1.8699e-04
Loss = 9.6925e-04, PNorm = 39.9649, GNorm = 0.8299, lr_0 = 1.8631e-04
Loss = 8.7901e-04, PNorm = 39.9701, GNorm = 1.6070, lr_0 = 1.8563e-04
Loss = 7.7501e-04, PNorm = 39.9743, GNorm = 1.4556, lr_0 = 1.8496e-04
Loss = 8.5730e-04, PNorm = 39.9783, GNorm = 1.1781, lr_0 = 1.8428e-04
Loss = 1.0188e-03, PNorm = 39.9826, GNorm = 1.8590, lr_0 = 1.8361e-04
Loss = 9.4146e-04, PNorm = 39.9841, GNorm = 1.4766, lr_0 = 1.8295e-04
Loss = 8.8705e-04, PNorm = 39.9874, GNorm = 0.8016, lr_0 = 1.8228e-04
Loss = 7.3669e-04, PNorm = 39.9897, GNorm = 1.1870, lr_0 = 1.8162e-04
Loss = 6.9101e-04, PNorm = 39.9930, GNorm = 1.3705, lr_0 = 1.8096e-04
Loss = 7.2527e-04, PNorm = 39.9972, GNorm = 0.6601, lr_0 = 1.8030e-04
Loss = 8.3289e-04, PNorm = 40.0025, GNorm = 0.5506, lr_0 = 1.7965e-04
Loss = 8.0238e-04, PNorm = 40.0052, GNorm = 1.7615, lr_0 = 1.7900e-04
Loss = 6.2392e-04, PNorm = 40.0077, GNorm = 0.9749, lr_0 = 1.7835e-04
Validation rmse = 0.450317
Epoch 23
Loss = 6.7893e-04, PNorm = 40.0108, GNorm = 0.5619, lr_0 = 1.7770e-04
Loss = 9.1949e-04, PNorm = 40.0134, GNorm = 0.5418, lr_0 = 1.7705e-04
Loss = 5.2420e-04, PNorm = 40.0156, GNorm = 1.2098, lr_0 = 1.7641e-04
Loss = 7.3347e-04, PNorm = 40.0189, GNorm = 0.6640, lr_0 = 1.7577e-04
Loss = 8.2888e-04, PNorm = 40.0213, GNorm = 1.0208, lr_0 = 1.7513e-04
Loss = 9.6467e-04, PNorm = 40.0236, GNorm = 0.8721, lr_0 = 1.7449e-04
Loss = 7.0847e-04, PNorm = 40.0261, GNorm = 0.6104, lr_0 = 1.7386e-04
Loss = 6.7369e-04, PNorm = 40.0295, GNorm = 0.5642, lr_0 = 1.7323e-04
Loss = 6.0982e-04, PNorm = 40.0330, GNorm = 0.3906, lr_0 = 1.7260e-04
Loss = 9.1164e-04, PNorm = 40.0369, GNorm = 0.6601, lr_0 = 1.7197e-04
Loss = 7.3951e-04, PNorm = 40.0415, GNorm = 0.5619, lr_0 = 1.7135e-04
Loss = 7.5759e-04, PNorm = 40.0448, GNorm = 0.7195, lr_0 = 1.7073e-04
Loss = 9.5330e-04, PNorm = 40.0469, GNorm = 1.5064, lr_0 = 1.7011e-04
Loss = 8.7703e-04, PNorm = 40.0536, GNorm = 1.3541, lr_0 = 1.6949e-04
Loss = 6.8675e-04, PNorm = 40.0577, GNorm = 0.5916, lr_0 = 1.6887e-04
Loss = 8.0717e-04, PNorm = 40.0615, GNorm = 0.5545, lr_0 = 1.6826e-04
Loss = 8.1254e-04, PNorm = 40.0651, GNorm = 1.1238, lr_0 = 1.6765e-04
Loss = 8.0147e-04, PNorm = 40.0684, GNorm = 0.6629, lr_0 = 1.6704e-04
Loss = 7.7018e-04, PNorm = 40.0707, GNorm = 0.9177, lr_0 = 1.6643e-04
Loss = 6.8534e-04, PNorm = 40.0738, GNorm = 0.4374, lr_0 = 1.6583e-04
Loss = 9.0287e-04, PNorm = 40.0752, GNorm = 1.1179, lr_0 = 1.6523e-04
Loss = 6.8138e-04, PNorm = 40.0782, GNorm = 0.7388, lr_0 = 1.6463e-04
Loss = 7.8797e-04, PNorm = 40.0823, GNorm = 0.7335, lr_0 = 1.6403e-04
Validation rmse = 0.438182
Epoch 24
Loss = 8.7525e-04, PNorm = 40.0851, GNorm = 0.8944, lr_0 = 1.6343e-04
Loss = 5.7485e-04, PNorm = 40.0889, GNorm = 0.5555, lr_0 = 1.6284e-04
Loss = 5.7778e-04, PNorm = 40.0911, GNorm = 0.7551, lr_0 = 1.6225e-04
Loss = 6.8935e-04, PNorm = 40.0944, GNorm = 0.5233, lr_0 = 1.6166e-04
Loss = 6.7092e-04, PNorm = 40.0961, GNorm = 0.6224, lr_0 = 1.6107e-04
Loss = 8.2933e-04, PNorm = 40.0989, GNorm = 0.5947, lr_0 = 1.6049e-04
Loss = 5.7464e-04, PNorm = 40.0995, GNorm = 0.6919, lr_0 = 1.5990e-04
Loss = 8.9654e-04, PNorm = 40.1022, GNorm = 1.4151, lr_0 = 1.5932e-04
Loss = 1.0522e-03, PNorm = 40.1061, GNorm = 1.1360, lr_0 = 1.5874e-04
Loss = 1.0135e-03, PNorm = 40.1099, GNorm = 2.4533, lr_0 = 1.5817e-04
Loss = 7.8625e-04, PNorm = 40.1130, GNorm = 2.0863, lr_0 = 1.5759e-04
Loss = 8.2943e-04, PNorm = 40.1154, GNorm = 1.4711, lr_0 = 1.5702e-04
Loss = 8.9922e-04, PNorm = 40.1178, GNorm = 0.7297, lr_0 = 1.5645e-04
Loss = 6.7357e-04, PNorm = 40.1194, GNorm = 1.9778, lr_0 = 1.5588e-04
Loss = 4.8910e-04, PNorm = 40.1220, GNorm = 1.2261, lr_0 = 1.5532e-04
Loss = 6.2822e-04, PNorm = 40.1239, GNorm = 0.6342, lr_0 = 1.5475e-04
Loss = 7.8763e-04, PNorm = 40.1266, GNorm = 0.6045, lr_0 = 1.5419e-04
Loss = 7.7059e-04, PNorm = 40.1296, GNorm = 1.6499, lr_0 = 1.5363e-04
Loss = 8.3162e-04, PNorm = 40.1333, GNorm = 1.4392, lr_0 = 1.5307e-04
Loss = 5.8879e-04, PNorm = 40.1357, GNorm = 0.9734, lr_0 = 1.5251e-04
Loss = 6.3228e-04, PNorm = 40.1374, GNorm = 0.8311, lr_0 = 1.5196e-04
Loss = 7.1640e-04, PNorm = 40.1402, GNorm = 0.9908, lr_0 = 1.5141e-04
Loss = 9.3851e-04, PNorm = 40.1435, GNorm = 1.0307, lr_0 = 1.5086e-04
Validation rmse = 0.436573
Epoch 25
Loss = 7.1168e-04, PNorm = 40.1458, GNorm = 1.4381, lr_0 = 1.5031e-04
Loss = 6.8094e-04, PNorm = 40.1496, GNorm = 1.0237, lr_0 = 1.4977e-04
Loss = 6.3110e-04, PNorm = 40.1528, GNorm = 1.3966, lr_0 = 1.4922e-04
Loss = 8.0911e-04, PNorm = 40.1566, GNorm = 0.6661, lr_0 = 1.4868e-04
Loss = 8.0090e-04, PNorm = 40.1591, GNorm = 0.7248, lr_0 = 1.4814e-04
Loss = 8.0865e-04, PNorm = 40.1622, GNorm = 0.5554, lr_0 = 1.4760e-04
Loss = 7.2592e-04, PNorm = 40.1648, GNorm = 1.4349, lr_0 = 1.4707e-04
Loss = 6.5121e-04, PNorm = 40.1680, GNorm = 0.5005, lr_0 = 1.4653e-04
Loss = 8.1464e-04, PNorm = 40.1708, GNorm = 0.9491, lr_0 = 1.4600e-04
Loss = 6.9502e-04, PNorm = 40.1738, GNorm = 0.9377, lr_0 = 1.4547e-04
Loss = 6.8292e-04, PNorm = 40.1780, GNorm = 0.5691, lr_0 = 1.4494e-04
Loss = 7.3154e-04, PNorm = 40.1808, GNorm = 0.7819, lr_0 = 1.4441e-04
Loss = 7.1727e-04, PNorm = 40.1834, GNorm = 2.1653, lr_0 = 1.4389e-04
Loss = 1.1161e-03, PNorm = 40.1846, GNorm = 1.5572, lr_0 = 1.4337e-04
Loss = 8.8049e-04, PNorm = 40.1873, GNorm = 1.5437, lr_0 = 1.4285e-04
Loss = 8.2594e-04, PNorm = 40.1906, GNorm = 1.6792, lr_0 = 1.4233e-04
Loss = 6.3980e-04, PNorm = 40.1921, GNorm = 0.4881, lr_0 = 1.4181e-04
Loss = 7.8356e-04, PNorm = 40.1940, GNorm = 0.8014, lr_0 = 1.4129e-04
Loss = 5.8604e-04, PNorm = 40.1966, GNorm = 0.9941, lr_0 = 1.4078e-04
Loss = 6.7923e-04, PNorm = 40.1998, GNorm = 0.9569, lr_0 = 1.4027e-04
Loss = 6.0057e-04, PNorm = 40.2012, GNorm = 1.7807, lr_0 = 1.3976e-04
Loss = 6.9731e-04, PNorm = 40.2032, GNorm = 1.9515, lr_0 = 1.3925e-04
Validation rmse = 0.440660
Epoch 26
Loss = 6.9124e-04, PNorm = 40.2040, GNorm = 0.4626, lr_0 = 1.3875e-04
Loss = 6.0923e-04, PNorm = 40.2051, GNorm = 0.6328, lr_0 = 1.3824e-04
Loss = 7.4284e-04, PNorm = 40.2073, GNorm = 0.8916, lr_0 = 1.3774e-04
Loss = 6.9644e-04, PNorm = 40.2108, GNorm = 0.5098, lr_0 = 1.3724e-04
Loss = 7.1599e-04, PNorm = 40.2127, GNorm = 0.6798, lr_0 = 1.3674e-04
Loss = 7.1653e-04, PNorm = 40.2154, GNorm = 2.3212, lr_0 = 1.3625e-04
Loss = 7.0826e-04, PNorm = 40.2193, GNorm = 1.6672, lr_0 = 1.3575e-04
Loss = 7.3801e-04, PNorm = 40.2214, GNorm = 0.4549, lr_0 = 1.3526e-04
Loss = 8.7026e-04, PNorm = 40.2238, GNorm = 0.5810, lr_0 = 1.3477e-04
Loss = 9.2941e-04, PNorm = 40.2261, GNorm = 0.5428, lr_0 = 1.3428e-04
Loss = 5.3359e-04, PNorm = 40.2282, GNorm = 0.4641, lr_0 = 1.3379e-04
Loss = 6.2705e-04, PNorm = 40.2307, GNorm = 0.5168, lr_0 = 1.3330e-04
Loss = 8.8901e-04, PNorm = 40.2344, GNorm = 1.1463, lr_0 = 1.3282e-04
Loss = 6.1801e-04, PNorm = 40.2382, GNorm = 1.1981, lr_0 = 1.3234e-04
Loss = 6.0186e-04, PNorm = 40.2423, GNorm = 0.6244, lr_0 = 1.3186e-04
Loss = 7.1599e-04, PNorm = 40.2438, GNorm = 0.7124, lr_0 = 1.3138e-04
Loss = 6.4643e-04, PNorm = 40.2454, GNorm = 0.9393, lr_0 = 1.3090e-04
Loss = 5.6943e-04, PNorm = 40.2477, GNorm = 1.4315, lr_0 = 1.3042e-04
Loss = 6.1582e-04, PNorm = 40.2496, GNorm = 0.9987, lr_0 = 1.2995e-04
Loss = 6.7779e-04, PNorm = 40.2516, GNorm = 0.7287, lr_0 = 1.2948e-04
Loss = 9.4375e-04, PNorm = 40.2535, GNorm = 1.1536, lr_0 = 1.2901e-04
Loss = 6.4259e-04, PNorm = 40.2551, GNorm = 1.0305, lr_0 = 1.2854e-04
Loss = 8.3822e-04, PNorm = 40.2579, GNorm = 0.4093, lr_0 = 1.2807e-04
Validation rmse = 0.463945
Epoch 27
Loss = 1.0189e-03, PNorm = 40.2610, GNorm = 1.3505, lr_0 = 1.2761e-04
Loss = 6.0103e-04, PNorm = 40.2643, GNorm = 0.8094, lr_0 = 1.2714e-04
Loss = 5.6688e-04, PNorm = 40.2662, GNorm = 0.4049, lr_0 = 1.2668e-04
Loss = 6.4372e-04, PNorm = 40.2681, GNorm = 0.7712, lr_0 = 1.2622e-04
Loss = 6.0769e-04, PNorm = 40.2688, GNorm = 0.8105, lr_0 = 1.2576e-04
Loss = 6.2547e-04, PNorm = 40.2712, GNorm = 0.9869, lr_0 = 1.2531e-04
Loss = 6.7054e-04, PNorm = 40.2744, GNorm = 0.5866, lr_0 = 1.2485e-04
Loss = 4.9836e-04, PNorm = 40.2763, GNorm = 0.7062, lr_0 = 1.2440e-04
Loss = 5.5501e-04, PNorm = 40.2786, GNorm = 0.7661, lr_0 = 1.2395e-04
Loss = 8.0415e-04, PNorm = 40.2808, GNorm = 0.7143, lr_0 = 1.2350e-04
Loss = 5.7691e-04, PNorm = 40.2831, GNorm = 0.6369, lr_0 = 1.2305e-04
Loss = 7.4598e-04, PNorm = 40.2850, GNorm = 1.0056, lr_0 = 1.2260e-04
Loss = 7.9376e-04, PNorm = 40.2883, GNorm = 0.7406, lr_0 = 1.2216e-04
Loss = 6.4010e-04, PNorm = 40.2902, GNorm = 0.6506, lr_0 = 1.2171e-04
Loss = 7.0618e-04, PNorm = 40.2931, GNorm = 1.0009, lr_0 = 1.2127e-04
Loss = 9.8686e-04, PNorm = 40.2954, GNorm = 1.5570, lr_0 = 1.2083e-04
Loss = 7.2764e-04, PNorm = 40.2975, GNorm = 0.8837, lr_0 = 1.2039e-04
Loss = 7.0055e-04, PNorm = 40.2995, GNorm = 0.8474, lr_0 = 1.1995e-04
Loss = 5.7986e-04, PNorm = 40.3021, GNorm = 1.7063, lr_0 = 1.1952e-04
Loss = 6.2367e-04, PNorm = 40.3039, GNorm = 0.7975, lr_0 = 1.1908e-04
Loss = 6.0854e-04, PNorm = 40.3055, GNorm = 0.4525, lr_0 = 1.1865e-04
Loss = 7.9009e-04, PNorm = 40.3074, GNorm = 1.5129, lr_0 = 1.1822e-04
Validation rmse = 0.439668
Epoch 28
Loss = 4.1147e-04, PNorm = 40.3097, GNorm = 0.8495, lr_0 = 1.1779e-04
Loss = 9.1389e-04, PNorm = 40.3126, GNorm = 0.4465, lr_0 = 1.1736e-04
Loss = 7.5309e-04, PNorm = 40.3139, GNorm = 1.5366, lr_0 = 1.1694e-04
Loss = 7.6375e-04, PNorm = 40.3172, GNorm = 1.0088, lr_0 = 1.1651e-04
Loss = 4.9885e-04, PNorm = 40.3192, GNorm = 0.6606, lr_0 = 1.1609e-04
Loss = 6.6013e-04, PNorm = 40.3209, GNorm = 1.5325, lr_0 = 1.1567e-04
Loss = 7.3402e-04, PNorm = 40.3233, GNorm = 0.6010, lr_0 = 1.1525e-04
Loss = 5.2179e-04, PNorm = 40.3253, GNorm = 0.6502, lr_0 = 1.1483e-04
Loss = 7.2671e-04, PNorm = 40.3273, GNorm = 1.2438, lr_0 = 1.1441e-04
Loss = 7.8413e-04, PNorm = 40.3280, GNorm = 1.2934, lr_0 = 1.1400e-04
Loss = 7.3110e-04, PNorm = 40.3313, GNorm = 0.5189, lr_0 = 1.1358e-04
Loss = 5.6401e-04, PNorm = 40.3329, GNorm = 0.8519, lr_0 = 1.1317e-04
Loss = 5.8209e-04, PNorm = 40.3350, GNorm = 0.5287, lr_0 = 1.1276e-04
Loss = 6.0355e-04, PNorm = 40.3367, GNorm = 0.5590, lr_0 = 1.1235e-04
Loss = 6.5219e-04, PNorm = 40.3399, GNorm = 0.4644, lr_0 = 1.1194e-04
Loss = 5.9694e-04, PNorm = 40.3415, GNorm = 2.7580, lr_0 = 1.1153e-04
Loss = 6.6292e-04, PNorm = 40.3446, GNorm = 1.1285, lr_0 = 1.1113e-04
Loss = 5.7631e-04, PNorm = 40.3462, GNorm = 1.8798, lr_0 = 1.1073e-04
Loss = 7.0796e-04, PNorm = 40.3477, GNorm = 0.8131, lr_0 = 1.1032e-04
Loss = 6.9814e-04, PNorm = 40.3498, GNorm = 0.4487, lr_0 = 1.0992e-04
Loss = 5.6626e-04, PNorm = 40.3518, GNorm = 1.0795, lr_0 = 1.0952e-04
Loss = 7.5782e-04, PNorm = 40.3543, GNorm = 1.0760, lr_0 = 1.0913e-04
Loss = 8.9061e-04, PNorm = 40.3575, GNorm = 1.6767, lr_0 = 1.0873e-04
Validation rmse = 0.455229
Epoch 29
Loss = 5.7312e-04, PNorm = 40.3593, GNorm = 1.7500, lr_0 = 1.0833e-04
Loss = 4.1878e-04, PNorm = 40.3616, GNorm = 0.7972, lr_0 = 1.0794e-04
Loss = 4.9336e-04, PNorm = 40.3626, GNorm = 0.8201, lr_0 = 1.0755e-04
Loss = 6.6961e-04, PNorm = 40.3638, GNorm = 0.6452, lr_0 = 1.0716e-04
Loss = 4.6959e-04, PNorm = 40.3651, GNorm = 0.4705, lr_0 = 1.0677e-04
Loss = 7.6673e-04, PNorm = 40.3668, GNorm = 0.6459, lr_0 = 1.0638e-04
Loss = 6.0985e-04, PNorm = 40.3694, GNorm = 0.7139, lr_0 = 1.0599e-04
Loss = 5.7030e-04, PNorm = 40.3704, GNorm = 0.7863, lr_0 = 1.0561e-04
Loss = 7.2534e-04, PNorm = 40.3724, GNorm = 1.3132, lr_0 = 1.0523e-04
Loss = 5.7202e-04, PNorm = 40.3741, GNorm = 0.7559, lr_0 = 1.0484e-04
Loss = 5.6325e-04, PNorm = 40.3753, GNorm = 0.6282, lr_0 = 1.0446e-04
Loss = 6.5062e-04, PNorm = 40.3765, GNorm = 0.6338, lr_0 = 1.0408e-04
Loss = 8.0032e-04, PNorm = 40.3782, GNorm = 1.3545, lr_0 = 1.0371e-04
Loss = 6.9574e-04, PNorm = 40.3803, GNorm = 1.3233, lr_0 = 1.0333e-04
Loss = 7.2028e-04, PNorm = 40.3832, GNorm = 0.8672, lr_0 = 1.0295e-04
Loss = 6.8166e-04, PNorm = 40.3854, GNorm = 0.5017, lr_0 = 1.0258e-04
Loss = 5.6844e-04, PNorm = 40.3875, GNorm = 0.9122, lr_0 = 1.0221e-04
Loss = 6.3473e-04, PNorm = 40.3893, GNorm = 0.7718, lr_0 = 1.0184e-04
Loss = 5.2166e-04, PNorm = 40.3905, GNorm = 1.5194, lr_0 = 1.0147e-04
Loss = 5.4703e-04, PNorm = 40.3912, GNorm = 1.0445, lr_0 = 1.0110e-04
Loss = 1.1372e-03, PNorm = 40.3934, GNorm = 0.9875, lr_0 = 1.0073e-04
Loss = 6.4409e-04, PNorm = 40.3952, GNorm = 0.4926, lr_0 = 1.0036e-04
Loss = 7.2030e-04, PNorm = 40.3977, GNorm = 0.4900, lr_0 = 1.0000e-04
Validation rmse = 0.430835
Model 0 best validation rmse = 0.430835 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.412861
Ensemble test rmse = 0.412861
1-fold cross validation
Seed 0 ==> test rmse = 0.412861
Overall test rmse = 0.412861 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 14,176 | train size = 11,340 | val size = 1,418 | test size = 1,418
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Loss = 2.0067e-02, PNorm = 34.0037, GNorm = 2.2753, lr_0 = 1.1991e-04
Loss = 1.7838e-02, PNorm = 34.0081, GNorm = 5.0134, lr_0 = 1.3982e-04
Loss = 1.5607e-02, PNorm = 34.0151, GNorm = 0.7457, lr_0 = 1.5973e-04
Loss = 1.6090e-02, PNorm = 34.0217, GNorm = 6.3993, lr_0 = 1.7965e-04
Loss = 1.2783e-02, PNorm = 34.0314, GNorm = 1.1658, lr_0 = 1.9956e-04
Loss = 1.0569e-02, PNorm = 34.0438, GNorm = 1.6782, lr_0 = 2.1947e-04
Loss = 1.0812e-02, PNorm = 34.0529, GNorm = 3.0227, lr_0 = 2.3938e-04
Loss = 1.0095e-02, PNorm = 34.0645, GNorm = 13.7478, lr_0 = 2.5929e-04
Loss = 9.6326e-03, PNorm = 34.0751, GNorm = 4.6636, lr_0 = 2.7920e-04
Loss = 9.3119e-03, PNorm = 34.0899, GNorm = 7.0467, lr_0 = 2.9912e-04
Loss = 1.0241e-02, PNorm = 34.1079, GNorm = 5.1344, lr_0 = 3.1903e-04
Loss = 8.9470e-03, PNorm = 34.1239, GNorm = 5.2515, lr_0 = 3.3894e-04
Loss = 8.8737e-03, PNorm = 34.1407, GNorm = 10.0528, lr_0 = 3.5885e-04
Loss = 6.7512e-03, PNorm = 34.1605, GNorm = 11.0585, lr_0 = 3.7876e-04
Loss = 6.9681e-03, PNorm = 34.1791, GNorm = 6.7332, lr_0 = 3.9867e-04
Loss = 6.7888e-03, PNorm = 34.1987, GNorm = 3.3939, lr_0 = 4.1858e-04
Loss = 5.7617e-03, PNorm = 34.2193, GNorm = 1.5088, lr_0 = 4.3850e-04
Loss = 6.6872e-03, PNorm = 34.2395, GNorm = 6.1963, lr_0 = 4.5841e-04
Loss = 8.0022e-03, PNorm = 34.2538, GNorm = 11.8175, lr_0 = 4.7832e-04
Loss = 6.6442e-03, PNorm = 34.2752, GNorm = 11.1066, lr_0 = 4.9823e-04
Loss = 5.5961e-03, PNorm = 34.2977, GNorm = 5.5592, lr_0 = 5.1814e-04
Loss = 5.8674e-03, PNorm = 34.3212, GNorm = 3.7250, lr_0 = 5.3805e-04
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': '../barzilay_predictions/logger_dir/temp_CCS_training_df.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': True,
 'save_dir': '../barzilay_predictions/logger_dir\\fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 12,758 | train size = 10,206 | val size = 1,276 | test size = 1,276
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Epoch 0
Loss = 1.9164e-02, PNorm = 33.9828, GNorm = 3.9965, lr_0 = 1.2206e-04
Loss = 2.0015e-02, PNorm = 33.9859, GNorm = 2.4653, lr_0 = 1.4412e-04
Loss = 1.5258e-02, PNorm = 33.9911, GNorm = 3.9357, lr_0 = 1.6618e-04
Loss = 1.6984e-02, PNorm = 33.9997, GNorm = 2.5769, lr_0 = 1.8824e-04
Loss = 1.5547e-02, PNorm = 34.0096, GNorm = 8.2951, lr_0 = 2.1029e-04
Loss = 1.6010e-02, PNorm = 34.0175, GNorm = 7.4777, lr_0 = 2.3235e-04
Loss = 1.2209e-02, PNorm = 34.0277, GNorm = 8.5032, lr_0 = 2.5441e-04
Loss = 1.1308e-02, PNorm = 34.0427, GNorm = 10.5359, lr_0 = 2.7647e-04
Loss = 1.0544e-02, PNorm = 34.0574, GNorm = 9.6913, lr_0 = 2.9853e-04
Loss = 9.6738e-03, PNorm = 34.0726, GNorm = 3.8785, lr_0 = 3.2059e-04
Loss = 8.1783e-03, PNorm = 34.0899, GNorm = 4.7947, lr_0 = 3.4265e-04
Loss = 7.8365e-03, PNorm = 34.1063, GNorm = 8.4981, lr_0 = 3.6471e-04
Loss = 8.5387e-03, PNorm = 34.1253, GNorm = 2.2889, lr_0 = 3.8676e-04
Loss = 8.5067e-03, PNorm = 34.1434, GNorm = 3.2579, lr_0 = 4.0882e-04
Loss = 7.1449e-03, PNorm = 34.1631, GNorm = 2.6740, lr_0 = 4.3088e-04
Loss = 7.1282e-03, PNorm = 34.1863, GNorm = 3.0714, lr_0 = 4.5294e-04
Loss = 7.7552e-03, PNorm = 34.2095, GNorm = 4.8079, lr_0 = 4.7500e-04
Loss = 6.8408e-03, PNorm = 34.2383, GNorm = 3.2422, lr_0 = 4.9706e-04
Loss = 6.3270e-03, PNorm = 34.2609, GNorm = 3.4183, lr_0 = 5.1912e-04
Loss = 5.2721e-03, PNorm = 34.2833, GNorm = 3.5295, lr_0 = 5.4118e-04
Validation rmse = 0.991115
Epoch 1
Loss = 7.5972e-03, PNorm = 34.3106, GNorm = 13.7398, lr_0 = 5.6324e-04
Loss = 6.5550e-03, PNorm = 34.3387, GNorm = 2.2436, lr_0 = 5.8529e-04
Loss = 5.6843e-03, PNorm = 34.3679, GNorm = 9.6251, lr_0 = 6.0735e-04
Loss = 4.7256e-03, PNorm = 34.3951, GNorm = 2.2272, lr_0 = 6.2941e-04
Loss = 5.3055e-03, PNorm = 34.4217, GNorm = 2.1797, lr_0 = 6.5147e-04
Loss = 4.4662e-03, PNorm = 34.4448, GNorm = 5.2192, lr_0 = 6.7353e-04
Loss = 4.5003e-03, PNorm = 34.4747, GNorm = 4.2009, lr_0 = 6.9559e-04
Loss = 5.1954e-03, PNorm = 34.4987, GNorm = 6.4367, lr_0 = 7.1765e-04
Loss = 4.6277e-03, PNorm = 34.5296, GNorm = 5.2950, lr_0 = 7.3971e-04
Loss = 4.5522e-03, PNorm = 34.5678, GNorm = 3.4950, lr_0 = 7.6176e-04
Loss = 6.0140e-03, PNorm = 34.5974, GNorm = 15.2685, lr_0 = 7.8382e-04
Loss = 4.4547e-03, PNorm = 34.6315, GNorm = 5.2365, lr_0 = 8.0588e-04
Loss = 4.5577e-03, PNorm = 34.6672, GNorm = 2.1152, lr_0 = 8.2794e-04
Loss = 3.8767e-03, PNorm = 34.7031, GNorm = 4.2338, lr_0 = 8.5000e-04
Loss = 4.4501e-03, PNorm = 34.7210, GNorm = 10.0433, lr_0 = 8.7206e-04
Loss = 5.1168e-03, PNorm = 34.7531, GNorm = 0.7767, lr_0 = 8.9412e-04
Loss = 4.8729e-03, PNorm = 34.7896, GNorm = 3.5211, lr_0 = 9.1618e-04
Loss = 4.5134e-03, PNorm = 34.8310, GNorm = 5.0653, lr_0 = 9.3824e-04
Loss = 4.6917e-03, PNorm = 34.8707, GNorm = 8.8754, lr_0 = 9.6029e-04
Loss = 4.9468e-03, PNorm = 34.9168, GNorm = 3.6104, lr_0 = 9.8235e-04
Validation rmse = 0.840639
Epoch 2
Loss = 3.7684e-03, PNorm = 34.9569, GNorm = 2.7133, lr_0 = 9.9919e-04
Loss = 3.7804e-03, PNorm = 34.9935, GNorm = 8.1700, lr_0 = 9.9517e-04
Loss = 4.2031e-03, PNorm = 35.0333, GNorm = 4.9749, lr_0 = 9.9117e-04
Loss = 6.1976e-03, PNorm = 35.0660, GNorm = 5.6376, lr_0 = 9.8718e-04
Loss = 4.5542e-03, PNorm = 35.1101, GNorm = 6.1949, lr_0 = 9.8321e-04
Loss = 4.6292e-03, PNorm = 35.1549, GNorm = 9.2693, lr_0 = 9.7926e-04
Loss = 4.4572e-03, PNorm = 35.1953, GNorm = 5.3038, lr_0 = 9.7532e-04
Loss = 3.7005e-03, PNorm = 35.2325, GNorm = 2.8135, lr_0 = 9.7139e-04
Loss = 2.9371e-03, PNorm = 35.2652, GNorm = 1.4376, lr_0 = 9.6749e-04
Loss = 3.2499e-03, PNorm = 35.2950, GNorm = 2.7884, lr_0 = 9.6359e-04
Loss = 3.5127e-03, PNorm = 35.3229, GNorm = 2.6131, lr_0 = 9.5972e-04
Loss = 3.0715e-03, PNorm = 35.3471, GNorm = 2.0047, lr_0 = 9.5586e-04
Loss = 2.7081e-03, PNorm = 35.3654, GNorm = 2.4616, lr_0 = 9.5201e-04
Loss = 3.1123e-03, PNorm = 35.3890, GNorm = 8.2571, lr_0 = 9.4818e-04
Loss = 3.6311e-03, PNorm = 35.4171, GNorm = 1.2958, lr_0 = 9.4437e-04
Loss = 3.3475e-03, PNorm = 35.4540, GNorm = 4.3542, lr_0 = 9.4057e-04
Loss = 3.2766e-03, PNorm = 35.4776, GNorm = 2.1366, lr_0 = 9.3678e-04
Loss = 3.1779e-03, PNorm = 35.5035, GNorm = 3.1450, lr_0 = 9.3301e-04
Loss = 2.5585e-03, PNorm = 35.5276, GNorm = 3.5791, lr_0 = 9.2926e-04
Loss = 3.1023e-03, PNorm = 35.5506, GNorm = 6.1305, lr_0 = 9.2552e-04
Loss = 2.9385e-03, PNorm = 35.5717, GNorm = 3.4331, lr_0 = 9.2180e-04
Validation rmse = 0.874333
Epoch 3
Loss = 3.9317e-03, PNorm = 35.5971, GNorm = 2.1243, lr_0 = 9.1809e-04
Loss = 3.6727e-03, PNorm = 35.6338, GNorm = 5.1307, lr_0 = 9.1440e-04
Loss = 4.0048e-03, PNorm = 35.6756, GNorm = 4.5504, lr_0 = 9.1072e-04
Loss = 3.2678e-03, PNorm = 35.7102, GNorm = 4.1541, lr_0 = 9.0705e-04
Loss = 2.5554e-03, PNorm = 35.7379, GNorm = 3.8548, lr_0 = 9.0340e-04
Loss = 2.7376e-03, PNorm = 35.7684, GNorm = 2.0905, lr_0 = 8.9977e-04
Loss = 2.5926e-03, PNorm = 35.8050, GNorm = 3.5459, lr_0 = 8.9615e-04
Loss = 2.5846e-03, PNorm = 35.8276, GNorm = 3.7374, lr_0 = 8.9255e-04
Loss = 2.6232e-03, PNorm = 35.8456, GNorm = 3.8933, lr_0 = 8.8895e-04
Loss = 2.5091e-03, PNorm = 35.8674, GNorm = 2.9211, lr_0 = 8.8538e-04
Loss = 2.6912e-03, PNorm = 35.8935, GNorm = 1.7945, lr_0 = 8.8182e-04
Loss = 2.7395e-03, PNorm = 35.9214, GNorm = 3.1485, lr_0 = 8.7827e-04
Loss = 3.0088e-03, PNorm = 35.9544, GNorm = 4.8928, lr_0 = 8.7474e-04
Loss = 3.0497e-03, PNorm = 35.9788, GNorm = 1.0547, lr_0 = 8.7122e-04
Loss = 2.7305e-03, PNorm = 35.9974, GNorm = 4.8668, lr_0 = 8.6771e-04
Loss = 2.7096e-03, PNorm = 36.0215, GNorm = 1.9159, lr_0 = 8.6422e-04
Loss = 2.5884e-03, PNorm = 36.0489, GNorm = 1.1877, lr_0 = 8.6074e-04
Loss = 2.5242e-03, PNorm = 36.0732, GNorm = 2.0837, lr_0 = 8.5728e-04
Loss = 2.5788e-03, PNorm = 36.0949, GNorm = 0.9844, lr_0 = 8.5383e-04
Loss = 2.7025e-03, PNorm = 36.1145, GNorm = 2.1857, lr_0 = 8.5040e-04
Validation rmse = 0.624408
Epoch 4
Loss = 2.4136e-03, PNorm = 36.1362, GNorm = 1.4716, lr_0 = 8.4698e-04
Loss = 2.1054e-03, PNorm = 36.1520, GNorm = 1.6347, lr_0 = 8.4357e-04
Loss = 2.8681e-03, PNorm = 36.1761, GNorm = 6.8409, lr_0 = 8.4017e-04
Loss = 2.5908e-03, PNorm = 36.1970, GNorm = 0.4669, lr_0 = 8.3679e-04
Loss = 2.6519e-03, PNorm = 36.2304, GNorm = 1.1319, lr_0 = 8.3343e-04
Loss = 2.4482e-03, PNorm = 36.2544, GNorm = 1.6027, lr_0 = 8.3008e-04
Loss = 2.9974e-03, PNorm = 36.2713, GNorm = 0.8954, lr_0 = 8.2674e-04
Loss = 2.1759e-03, PNorm = 36.2933, GNorm = 1.6660, lr_0 = 8.2341e-04
Loss = 2.2503e-03, PNorm = 36.3219, GNorm = 1.0881, lr_0 = 8.2010e-04
Loss = 2.2807e-03, PNorm = 36.3480, GNorm = 2.3644, lr_0 = 8.1680e-04
Loss = 2.1775e-03, PNorm = 36.3669, GNorm = 2.1304, lr_0 = 8.1351e-04
Loss = 2.4243e-03, PNorm = 36.3870, GNorm = 6.0722, lr_0 = 8.1024e-04
Loss = 2.5945e-03, PNorm = 36.4099, GNorm = 2.0458, lr_0 = 8.0698e-04
Loss = 2.2785e-03, PNorm = 36.4313, GNorm = 3.1874, lr_0 = 8.0373e-04
Loss = 2.6529e-03, PNorm = 36.4525, GNorm = 6.4893, lr_0 = 8.0050e-04
Loss = 2.7254e-03, PNorm = 36.4774, GNorm = 1.1179, lr_0 = 7.9728e-04
Loss = 1.9277e-03, PNorm = 36.5029, GNorm = 1.5984, lr_0 = 7.9407e-04
Loss = 2.0350e-03, PNorm = 36.5201, GNorm = 4.4650, lr_0 = 7.9088e-04
Loss = 1.9651e-03, PNorm = 36.5227, GNorm = 2.1383, lr_0 = 7.8770e-04
Loss = 1.9490e-03, PNorm = 36.5427, GNorm = 1.4529, lr_0 = 7.8453e-04
Loss = 2.3321e-03, PNorm = 36.5661, GNorm = 2.3959, lr_0 = 7.8137e-04
Validation rmse = 0.665189
Epoch 5
Loss = 2.1244e-03, PNorm = 36.5862, GNorm = 4.7439, lr_0 = 7.7823e-04
Loss = 3.1712e-03, PNorm = 36.6093, GNorm = 3.9549, lr_0 = 7.7510e-04
Loss = 3.8244e-03, PNorm = 36.6429, GNorm = 0.6803, lr_0 = 7.7198e-04
Loss = 3.4204e-03, PNorm = 36.6740, GNorm = 2.0288, lr_0 = 7.6887e-04
Loss = 2.4718e-03, PNorm = 36.6978, GNorm = 0.9744, lr_0 = 7.6578e-04
Loss = 2.1874e-03, PNorm = 36.7232, GNorm = 2.4320, lr_0 = 7.6270e-04
Loss = 2.0935e-03, PNorm = 36.7424, GNorm = 1.3158, lr_0 = 7.5963e-04
Loss = 2.0185e-03, PNorm = 36.7560, GNorm = 0.7341, lr_0 = 7.5657e-04
Loss = 2.5960e-03, PNorm = 36.7742, GNorm = 0.5969, lr_0 = 7.5353e-04
Loss = 2.1854e-03, PNorm = 36.7971, GNorm = 3.6331, lr_0 = 7.5050e-04
Loss = 2.8444e-03, PNorm = 36.8227, GNorm = 2.3003, lr_0 = 7.4748e-04
Loss = 2.3727e-03, PNorm = 36.8574, GNorm = 5.3210, lr_0 = 7.4447e-04
Loss = 1.8488e-03, PNorm = 36.8850, GNorm = 3.5766, lr_0 = 7.4148e-04
Loss = 1.7381e-03, PNorm = 36.9035, GNorm = 1.6791, lr_0 = 7.3849e-04
Loss = 2.1948e-03, PNorm = 36.9213, GNorm = 1.2385, lr_0 = 7.3552e-04
Loss = 2.3339e-03, PNorm = 36.9397, GNorm = 2.3979, lr_0 = 7.3256e-04
Loss = 2.5767e-03, PNorm = 36.9574, GNorm = 0.6934, lr_0 = 7.2962e-04
Loss = 1.9936e-03, PNorm = 36.9846, GNorm = 0.6564, lr_0 = 7.2668e-04
Loss = 1.9637e-03, PNorm = 36.9994, GNorm = 4.1249, lr_0 = 7.2376e-04
Loss = 1.7903e-03, PNorm = 37.0030, GNorm = 2.9786, lr_0 = 7.2085e-04
Validation rmse = 0.594460
Epoch 6
Loss = 1.7451e-03, PNorm = 37.0243, GNorm = 1.2162, lr_0 = 7.1795e-04
Loss = 1.8004e-03, PNorm = 37.0405, GNorm = 1.6089, lr_0 = 7.1506e-04
Loss = 2.0899e-03, PNorm = 37.0655, GNorm = 1.9111, lr_0 = 7.1218e-04
Loss = 1.8106e-03, PNorm = 37.0735, GNorm = 1.9394, lr_0 = 7.0932e-04
Loss = 2.5808e-03, PNorm = 37.0953, GNorm = 1.1797, lr_0 = 7.0646e-04
Loss = 1.7962e-03, PNorm = 37.1117, GNorm = 1.8768, lr_0 = 7.0362e-04
Loss = 1.5249e-03, PNorm = 37.1308, GNorm = 1.2035, lr_0 = 7.0079e-04
Loss = 2.0246e-03, PNorm = 37.1472, GNorm = 2.2774, lr_0 = 6.9797e-04
Loss = 2.2877e-03, PNorm = 37.1629, GNorm = 3.3207, lr_0 = 6.9516e-04
Loss = 2.5825e-03, PNorm = 37.1863, GNorm = 2.1126, lr_0 = 6.9237e-04
Loss = 2.1998e-03, PNorm = 37.2077, GNorm = 1.9365, lr_0 = 6.8958e-04
Loss = 1.8705e-03, PNorm = 37.2209, GNorm = 2.7859, lr_0 = 6.8681e-04
Loss = 1.7472e-03, PNorm = 37.2322, GNorm = 4.3530, lr_0 = 6.8404e-04
Loss = 1.8100e-03, PNorm = 37.2461, GNorm = 3.9506, lr_0 = 6.8129e-04
Loss = 2.1435e-03, PNorm = 37.2705, GNorm = 3.4636, lr_0 = 6.7855e-04
Loss = 2.2301e-03, PNorm = 37.2924, GNorm = 3.9938, lr_0 = 6.7582e-04
Loss = 2.1774e-03, PNorm = 37.3148, GNorm = 3.2923, lr_0 = 6.7310e-04
Loss = 1.8067e-03, PNorm = 37.3376, GNorm = 0.9829, lr_0 = 6.7039e-04
Loss = 1.5086e-03, PNorm = 37.3554, GNorm = 0.8718, lr_0 = 6.6770e-04
Loss = 1.6298e-03, PNorm = 37.3683, GNorm = 0.4501, lr_0 = 6.6501e-04
Validation rmse = 0.565434
Epoch 7
Loss = 1.8911e-03, PNorm = 37.3832, GNorm = 3.0446, lr_0 = 6.6234e-04
Loss = 1.4282e-03, PNorm = 37.4019, GNorm = 0.8094, lr_0 = 6.5967e-04
Loss = 2.0447e-03, PNorm = 37.4202, GNorm = 1.7087, lr_0 = 6.5702e-04
Loss = 1.4785e-03, PNorm = 37.4375, GNorm = 3.5195, lr_0 = 6.5437e-04
Loss = 1.8060e-03, PNorm = 37.4570, GNorm = 1.1660, lr_0 = 6.5174e-04
Loss = 1.5444e-03, PNorm = 37.4743, GNorm = 2.8496, lr_0 = 6.4912e-04
Loss = 1.6687e-03, PNorm = 37.4935, GNorm = 0.6667, lr_0 = 6.4651e-04
Loss = 2.0158e-03, PNorm = 37.5115, GNorm = 2.9037, lr_0 = 6.4391e-04
Loss = 1.6196e-03, PNorm = 37.5266, GNorm = 1.5932, lr_0 = 6.4132e-04
Loss = 1.6680e-03, PNorm = 37.5464, GNorm = 1.4156, lr_0 = 6.3874e-04
Loss = 1.9829e-03, PNorm = 37.5650, GNorm = 5.5479, lr_0 = 6.3617e-04
Loss = 1.9478e-03, PNorm = 37.5848, GNorm = 1.7040, lr_0 = 6.3361e-04
Loss = 1.6491e-03, PNorm = 37.5967, GNorm = 1.1098, lr_0 = 6.3106e-04
Loss = 1.6733e-03, PNorm = 37.6127, GNorm = 1.0214, lr_0 = 6.2852e-04
Loss = 1.6357e-03, PNorm = 37.6271, GNorm = 1.0228, lr_0 = 6.2599e-04
Loss = 1.3973e-03, PNorm = 37.6426, GNorm = 2.5861, lr_0 = 6.2347e-04
Loss = 1.5509e-03, PNorm = 37.6589, GNorm = 2.9452, lr_0 = 6.2097e-04
Loss = 1.7380e-03, PNorm = 37.6705, GNorm = 3.3376, lr_0 = 6.1847e-04
Loss = 1.7186e-03, PNorm = 37.6881, GNorm = 2.8246, lr_0 = 6.1598e-04
Loss = 1.8100e-03, PNorm = 37.6938, GNorm = 1.3561, lr_0 = 6.1350e-04
Loss = 2.0232e-03, PNorm = 37.7141, GNorm = 1.0611, lr_0 = 6.1103e-04
Validation rmse = 0.548304
Epoch 8
Loss = 1.5036e-03, PNorm = 37.7254, GNorm = 0.7471, lr_0 = 6.0857e-04
Loss = 1.5536e-03, PNorm = 37.7375, GNorm = 3.3865, lr_0 = 6.0613e-04
Loss = 1.8475e-03, PNorm = 37.7527, GNorm = 3.8826, lr_0 = 6.0369e-04
Loss = 1.8587e-03, PNorm = 37.7715, GNorm = 4.1837, lr_0 = 6.0126e-04
Loss = 2.1166e-03, PNorm = 37.7994, GNorm = 1.4769, lr_0 = 5.9884e-04
Loss = 1.6395e-03, PNorm = 37.8213, GNorm = 2.2455, lr_0 = 5.9643e-04
Loss = 1.5569e-03, PNorm = 37.8344, GNorm = 1.2648, lr_0 = 5.9403e-04
Loss = 1.9186e-03, PNorm = 37.8499, GNorm = 0.7077, lr_0 = 5.9164e-04
Loss = 1.4429e-03, PNorm = 37.8621, GNorm = 2.0171, lr_0 = 5.8926e-04
Loss = 1.3999e-03, PNorm = 37.8743, GNorm = 1.4003, lr_0 = 5.8689e-04
Loss = 1.3885e-03, PNorm = 37.8863, GNorm = 3.8532, lr_0 = 5.8453e-04
Loss = 2.0315e-03, PNorm = 37.8966, GNorm = 1.6593, lr_0 = 5.8218e-04
Loss = 1.5195e-03, PNorm = 37.9122, GNorm = 1.1861, lr_0 = 5.7984e-04
Loss = 1.7923e-03, PNorm = 37.9312, GNorm = 1.0184, lr_0 = 5.7750e-04
Loss = 1.3960e-03, PNorm = 37.9467, GNorm = 1.5899, lr_0 = 5.7518e-04
Loss = 1.6546e-03, PNorm = 37.9613, GNorm = 1.1523, lr_0 = 5.7287e-04
Loss = 1.6345e-03, PNorm = 37.9736, GNorm = 1.1644, lr_0 = 5.7056e-04
Loss = 1.7695e-03, PNorm = 37.9848, GNorm = 0.8655, lr_0 = 5.6827e-04
Loss = 1.5161e-03, PNorm = 37.9985, GNorm = 1.2209, lr_0 = 5.6598e-04
Loss = 1.4596e-03, PNorm = 38.0108, GNorm = 4.1529, lr_0 = 5.6370e-04
Validation rmse = 0.543844
Epoch 9
Loss = 1.1734e-03, PNorm = 38.0233, GNorm = 2.7344, lr_0 = 5.6144e-04
Loss = 1.2866e-03, PNorm = 38.0361, GNorm = 0.8918, lr_0 = 5.5918e-04
Loss = 1.3952e-03, PNorm = 38.0464, GNorm = 1.4358, lr_0 = 5.5693e-04
Loss = 1.3831e-03, PNorm = 38.0638, GNorm = 2.4673, lr_0 = 5.5469e-04
Loss = 1.7607e-03, PNorm = 38.0818, GNorm = 1.0172, lr_0 = 5.5246e-04
Loss = 1.2027e-03, PNorm = 38.0963, GNorm = 1.2499, lr_0 = 5.5023e-04
Loss = 1.5809e-03, PNorm = 38.1083, GNorm = 1.5698, lr_0 = 5.4802e-04
Loss = 1.3843e-03, PNorm = 38.1247, GNorm = 3.8462, lr_0 = 5.4581e-04
Loss = 1.2461e-03, PNorm = 38.1415, GNorm = 2.2049, lr_0 = 5.4362e-04
Loss = 1.3455e-03, PNorm = 38.1561, GNorm = 1.4561, lr_0 = 5.4143e-04
Loss = 1.6285e-03, PNorm = 38.1616, GNorm = 0.9375, lr_0 = 5.3925e-04
Loss = 1.7942e-03, PNorm = 38.1804, GNorm = 0.7515, lr_0 = 5.3708e-04
Loss = 1.9343e-03, PNorm = 38.1913, GNorm = 3.5931, lr_0 = 5.3492e-04
Loss = 1.5507e-03, PNorm = 38.1986, GNorm = 0.9045, lr_0 = 5.3277e-04
Loss = 1.6258e-03, PNorm = 38.2061, GNorm = 2.6420, lr_0 = 5.3063e-04
Loss = 2.0463e-03, PNorm = 38.2199, GNorm = 2.2620, lr_0 = 5.2849e-04
Loss = 1.6712e-03, PNorm = 38.2338, GNorm = 3.2962, lr_0 = 5.2637e-04
Loss = 1.1070e-03, PNorm = 38.2487, GNorm = 1.0005, lr_0 = 5.2425e-04
Loss = 1.4858e-03, PNorm = 38.2638, GNorm = 1.7088, lr_0 = 5.2214e-04
Loss = 1.6308e-03, PNorm = 38.2763, GNorm = 3.3064, lr_0 = 5.2004e-04
Loss = 1.4916e-03, PNorm = 38.2907, GNorm = 1.4842, lr_0 = 5.1795e-04
Validation rmse = 0.527789
Epoch 10
Loss = 1.4903e-03, PNorm = 38.3028, GNorm = 2.0667, lr_0 = 5.1586e-04
Loss = 1.1290e-03, PNorm = 38.3127, GNorm = 0.6471, lr_0 = 5.1379e-04
Loss = 1.2451e-03, PNorm = 38.3217, GNorm = 3.6187, lr_0 = 5.1172e-04
Loss = 1.1986e-03, PNorm = 38.3313, GNorm = 1.0001, lr_0 = 5.0966e-04
Loss = 1.2350e-03, PNorm = 38.3392, GNorm = 1.7651, lr_0 = 5.0761e-04
Loss = 1.2502e-03, PNorm = 38.3526, GNorm = 0.5908, lr_0 = 5.0557e-04
Loss = 1.2597e-03, PNorm = 38.3648, GNorm = 1.4940, lr_0 = 5.0354e-04
Loss = 1.1823e-03, PNorm = 38.3719, GNorm = 0.7335, lr_0 = 5.0151e-04
Loss = 1.5496e-03, PNorm = 38.3858, GNorm = 2.2536, lr_0 = 4.9949e-04
Loss = 1.3157e-03, PNorm = 38.4000, GNorm = 0.6211, lr_0 = 4.9748e-04
Loss = 1.6773e-03, PNorm = 38.4156, GNorm = 2.2696, lr_0 = 4.9548e-04
Loss = 1.0620e-03, PNorm = 38.4299, GNorm = 0.5000, lr_0 = 4.9349e-04
Loss = 1.3098e-03, PNorm = 38.4408, GNorm = 2.7200, lr_0 = 4.9150e-04
Loss = 1.5766e-03, PNorm = 38.4549, GNorm = 2.1002, lr_0 = 4.8953e-04
Loss = 1.5671e-03, PNorm = 38.4632, GNorm = 2.4998, lr_0 = 4.8756e-04
Loss = 1.4156e-03, PNorm = 38.4695, GNorm = 4.2628, lr_0 = 4.8560e-04
Loss = 1.8294e-03, PNorm = 38.4815, GNorm = 3.2022, lr_0 = 4.8364e-04
Loss = 1.6823e-03, PNorm = 38.4940, GNorm = 1.7511, lr_0 = 4.8170e-04
Loss = 1.3089e-03, PNorm = 38.5095, GNorm = 1.1733, lr_0 = 4.7976e-04
Loss = 1.2400e-03, PNorm = 38.5213, GNorm = 1.1798, lr_0 = 4.7783e-04
Validation rmse = 0.505512
Epoch 11
Loss = 1.1061e-03, PNorm = 38.5344, GNorm = 0.8594, lr_0 = 4.7591e-04
Loss = 9.6542e-04, PNorm = 38.5491, GNorm = 0.7520, lr_0 = 4.7399e-04
Loss = 1.1589e-03, PNorm = 38.5590, GNorm = 0.7034, lr_0 = 4.7208e-04
Loss = 1.4897e-03, PNorm = 38.5717, GNorm = 0.8807, lr_0 = 4.7019e-04
Loss = 1.1293e-03, PNorm = 38.5841, GNorm = 1.7391, lr_0 = 4.6829e-04
Loss = 1.0829e-03, PNorm = 38.5917, GNorm = 2.0576, lr_0 = 4.6641e-04
Loss = 1.5045e-03, PNorm = 38.6019, GNorm = 0.8475, lr_0 = 4.6453e-04
Loss = 1.7024e-03, PNorm = 38.6145, GNorm = 2.5693, lr_0 = 4.6266e-04
Loss = 1.3985e-03, PNorm = 38.6338, GNorm = 1.1956, lr_0 = 4.6080e-04
Loss = 1.0546e-03, PNorm = 38.6471, GNorm = 0.9296, lr_0 = 4.5895e-04
Loss = 1.3516e-03, PNorm = 38.6539, GNorm = 1.1567, lr_0 = 4.5710e-04
Loss = 1.3935e-03, PNorm = 38.6634, GNorm = 4.5775, lr_0 = 4.5526e-04
Loss = 1.2175e-03, PNorm = 38.6762, GNorm = 1.1984, lr_0 = 4.5343e-04
Loss = 2.0682e-03, PNorm = 38.6891, GNorm = 2.8441, lr_0 = 4.5161e-04
Loss = 1.2044e-03, PNorm = 38.6987, GNorm = 0.7391, lr_0 = 4.4979e-04
Loss = 1.5751e-03, PNorm = 38.7102, GNorm = 3.0942, lr_0 = 4.4798e-04
Loss = 1.2308e-03, PNorm = 38.7241, GNorm = 1.5030, lr_0 = 4.4618e-04
Loss = 1.2102e-03, PNorm = 38.7324, GNorm = 1.9978, lr_0 = 4.4438e-04
Loss = 1.1509e-03, PNorm = 38.7420, GNorm = 2.8667, lr_0 = 4.4260e-04
Loss = 1.3252e-03, PNorm = 38.7508, GNorm = 2.0937, lr_0 = 4.4082e-04
Validation rmse = 0.615632
Epoch 12
Loss = 1.5304e-03, PNorm = 38.7564, GNorm = 2.2303, lr_0 = 4.3904e-04
Loss = 1.2639e-03, PNorm = 38.7641, GNorm = 1.0980, lr_0 = 4.3728e-04
Loss = 1.2998e-03, PNorm = 38.7727, GNorm = 2.5648, lr_0 = 4.3552e-04
Loss = 1.0817e-03, PNorm = 38.7815, GNorm = 0.8131, lr_0 = 4.3377e-04
Loss = 1.1071e-03, PNorm = 38.7930, GNorm = 0.7835, lr_0 = 4.3202e-04
Loss = 1.2012e-03, PNorm = 38.8055, GNorm = 0.5282, lr_0 = 4.3028e-04
Loss = 9.6481e-04, PNorm = 38.8130, GNorm = 1.2104, lr_0 = 4.2855e-04
Loss = 1.4946e-03, PNorm = 38.8247, GNorm = 1.1472, lr_0 = 4.2683e-04
Loss = 1.0357e-03, PNorm = 38.8352, GNorm = 1.1030, lr_0 = 4.2511e-04
Loss = 1.1880e-03, PNorm = 38.8416, GNorm = 1.4501, lr_0 = 4.2340e-04
Loss = 1.4122e-03, PNorm = 38.8461, GNorm = 4.7341, lr_0 = 4.2170e-04
Loss = 1.1952e-03, PNorm = 38.8565, GNorm = 2.2187, lr_0 = 4.2000e-04
Loss = 1.2704e-03, PNorm = 38.8680, GNorm = 0.4557, lr_0 = 4.1831e-04
Loss = 9.1032e-04, PNorm = 38.8754, GNorm = 0.3299, lr_0 = 4.1663e-04
Loss = 1.7696e-03, PNorm = 38.8839, GNorm = 0.7032, lr_0 = 4.1495e-04
Loss = 1.1509e-03, PNorm = 38.8942, GNorm = 0.9088, lr_0 = 4.1328e-04
Loss = 1.0318e-03, PNorm = 38.8995, GNorm = 1.5293, lr_0 = 4.1162e-04
Loss = 1.1770e-03, PNorm = 38.9115, GNorm = 1.4458, lr_0 = 4.0996e-04
Loss = 9.1376e-04, PNorm = 38.9212, GNorm = 2.0448, lr_0 = 4.0831e-04
Loss = 9.1875e-04, PNorm = 38.9304, GNorm = 1.0216, lr_0 = 4.0667e-04
Loss = 1.0621e-03, PNorm = 38.9385, GNorm = 1.1785, lr_0 = 4.0504e-04
Validation rmse = 0.500677
Epoch 13
Loss = 1.4615e-03, PNorm = 38.9479, GNorm = 2.3600, lr_0 = 4.0341e-04
Loss = 9.5197e-04, PNorm = 38.9583, GNorm = 1.2680, lr_0 = 4.0178e-04
Loss = 9.7851e-04, PNorm = 38.9641, GNorm = 0.7381, lr_0 = 4.0017e-04
Loss = 1.0794e-03, PNorm = 38.9670, GNorm = 2.2211, lr_0 = 3.9856e-04
Loss = 8.9605e-04, PNorm = 38.9737, GNorm = 0.5767, lr_0 = 3.9695e-04
Loss = 9.3002e-04, PNorm = 38.9815, GNorm = 1.8910, lr_0 = 3.9536e-04
Loss = 1.0248e-03, PNorm = 38.9899, GNorm = 1.4997, lr_0 = 3.9377e-04
Loss = 1.3536e-03, PNorm = 38.9998, GNorm = 0.7657, lr_0 = 3.9218e-04
Loss = 1.3021e-03, PNorm = 39.0092, GNorm = 0.9593, lr_0 = 3.9060e-04
Loss = 1.0185e-03, PNorm = 39.0175, GNorm = 1.1281, lr_0 = 3.8903e-04
Loss = 9.9552e-04, PNorm = 39.0213, GNorm = 2.0014, lr_0 = 3.8747e-04
Loss = 1.0409e-03, PNorm = 39.0312, GNorm = 1.4657, lr_0 = 3.8591e-04
Loss = 9.8299e-04, PNorm = 39.0394, GNorm = 1.2208, lr_0 = 3.8436e-04
Loss = 8.0735e-04, PNorm = 39.0467, GNorm = 0.7482, lr_0 = 3.8281e-04
Loss = 1.3065e-03, PNorm = 39.0537, GNorm = 0.9327, lr_0 = 3.8127e-04
Loss = 1.0574e-03, PNorm = 39.0662, GNorm = 1.7763, lr_0 = 3.7974e-04
Loss = 1.1440e-03, PNorm = 39.0727, GNorm = 0.8040, lr_0 = 3.7821e-04
Loss = 1.3806e-03, PNorm = 39.0838, GNorm = 3.0283, lr_0 = 3.7669e-04
Loss = 1.5657e-03, PNorm = 39.0941, GNorm = 0.6787, lr_0 = 3.7517e-04
Loss = 1.3475e-03, PNorm = 39.1006, GNorm = 1.1951, lr_0 = 3.7366e-04
Validation rmse = 0.496573
Epoch 14
Loss = 1.0999e-03, PNorm = 39.1104, GNorm = 3.1618, lr_0 = 3.7216e-04
Loss = 1.1332e-03, PNorm = 39.1217, GNorm = 1.8249, lr_0 = 3.7066e-04
Loss = 1.0306e-03, PNorm = 39.1316, GNorm = 1.6002, lr_0 = 3.6917e-04
Loss = 8.5566e-04, PNorm = 39.1390, GNorm = 1.0017, lr_0 = 3.6769e-04
Loss = 1.1512e-03, PNorm = 39.1459, GNorm = 1.0043, lr_0 = 3.6621e-04
Loss = 9.3849e-04, PNorm = 39.1542, GNorm = 0.8695, lr_0 = 3.6473e-04
Loss = 1.2097e-03, PNorm = 39.1643, GNorm = 1.2559, lr_0 = 3.6327e-04
Loss = 9.9714e-04, PNorm = 39.1763, GNorm = 2.1519, lr_0 = 3.6180e-04
Loss = 1.1330e-03, PNorm = 39.1818, GNorm = 0.8264, lr_0 = 3.6035e-04
Loss = 1.3420e-03, PNorm = 39.1873, GNorm = 2.7126, lr_0 = 3.5890e-04
Loss = 9.2589e-04, PNorm = 39.1934, GNorm = 0.7008, lr_0 = 3.5745e-04
Loss = 1.6020e-03, PNorm = 39.2030, GNorm = 0.9681, lr_0 = 3.5602e-04
Loss = 8.6158e-04, PNorm = 39.2093, GNorm = 0.7966, lr_0 = 3.5458e-04
Loss = 1.0472e-03, PNorm = 39.2150, GNorm = 0.7181, lr_0 = 3.5316e-04
Loss = 9.3793e-04, PNorm = 39.2234, GNorm = 1.7393, lr_0 = 3.5174e-04
Loss = 1.3062e-03, PNorm = 39.2333, GNorm = 2.5758, lr_0 = 3.5032e-04
Loss = 9.7598e-04, PNorm = 39.2430, GNorm = 1.8070, lr_0 = 3.4891e-04
Loss = 9.8816e-04, PNorm = 39.2495, GNorm = 1.6749, lr_0 = 3.4751e-04
Loss = 9.0611e-04, PNorm = 39.2589, GNorm = 0.9414, lr_0 = 3.4611e-04
Loss = 1.5889e-03, PNorm = 39.2684, GNorm = 4.3916, lr_0 = 3.4472e-04
Loss = 1.1127e-03, PNorm = 39.2764, GNorm = 0.8880, lr_0 = 3.4333e-04
Validation rmse = 0.489124
Epoch 15
Loss = 1.1296e-03, PNorm = 39.2869, GNorm = 0.7097, lr_0 = 3.4195e-04
Loss = 1.0424e-03, PNorm = 39.2985, GNorm = 2.3602, lr_0 = 3.4058e-04
Loss = 1.2267e-03, PNorm = 39.3057, GNorm = 1.5808, lr_0 = 3.3920e-04
Loss = 1.0208e-03, PNorm = 39.3117, GNorm = 2.1243, lr_0 = 3.3784e-04
Loss = 8.4190e-04, PNorm = 39.3203, GNorm = 2.1532, lr_0 = 3.3648e-04
Loss = 1.0079e-03, PNorm = 39.3294, GNorm = 1.0825, lr_0 = 3.3513e-04
Loss = 9.5613e-04, PNorm = 39.3354, GNorm = 0.5917, lr_0 = 3.3378e-04
Loss = 1.1314e-03, PNorm = 39.3451, GNorm = 1.5621, lr_0 = 3.3244e-04
Loss = 9.5224e-04, PNorm = 39.3546, GNorm = 1.3853, lr_0 = 3.3110e-04
Loss = 1.0994e-03, PNorm = 39.3598, GNorm = 0.9867, lr_0 = 3.2977e-04
Loss = 1.1574e-03, PNorm = 39.3633, GNorm = 2.7928, lr_0 = 3.2844e-04
Loss = 8.9589e-04, PNorm = 39.3676, GNorm = 1.1718, lr_0 = 3.2712e-04
Loss = 1.3283e-03, PNorm = 39.3758, GNorm = 0.9339, lr_0 = 3.2580e-04
Loss = 1.0842e-03, PNorm = 39.3825, GNorm = 1.4309, lr_0 = 3.2449e-04
Loss = 9.4616e-04, PNorm = 39.3878, GNorm = 0.4544, lr_0 = 3.2319e-04
Loss = 1.0055e-03, PNorm = 39.3959, GNorm = 2.3098, lr_0 = 3.2189e-04
Loss = 1.0678e-03, PNorm = 39.4038, GNorm = 1.4834, lr_0 = 3.2059e-04
Loss = 1.0681e-03, PNorm = 39.4104, GNorm = 1.5862, lr_0 = 3.1930e-04
Loss = 1.2953e-03, PNorm = 39.4187, GNorm = 0.6348, lr_0 = 3.1802e-04
Loss = 7.0762e-04, PNorm = 39.4270, GNorm = 0.4806, lr_0 = 3.1674e-04
Validation rmse = 0.473341
Epoch 16
Loss = 8.1448e-04, PNorm = 39.4356, GNorm = 1.2093, lr_0 = 3.1546e-04
Loss = 9.8581e-04, PNorm = 39.4457, GNorm = 0.9007, lr_0 = 3.1419e-04
Loss = 7.0949e-04, PNorm = 39.4537, GNorm = 0.5279, lr_0 = 3.1293e-04
Loss = 6.7007e-04, PNorm = 39.4609, GNorm = 0.8190, lr_0 = 3.1167e-04
Loss = 1.0430e-03, PNorm = 39.4675, GNorm = 0.9255, lr_0 = 3.1042e-04
Loss = 1.6040e-03, PNorm = 39.4724, GNorm = 2.0446, lr_0 = 3.0917e-04
Loss = 9.8083e-04, PNorm = 39.4792, GNorm = 0.7462, lr_0 = 3.0793e-04
Loss = 8.8616e-04, PNorm = 39.4852, GNorm = 1.6908, lr_0 = 3.0669e-04
Loss = 9.0333e-04, PNorm = 39.4904, GNorm = 2.4632, lr_0 = 3.0545e-04
Loss = 1.2314e-03, PNorm = 39.4974, GNorm = 1.1618, lr_0 = 3.0422e-04
Loss = 1.1024e-03, PNorm = 39.5060, GNorm = 1.1073, lr_0 = 3.0300e-04
Loss = 9.5294e-04, PNorm = 39.5136, GNorm = 1.1133, lr_0 = 3.0178e-04
Loss = 9.8067e-04, PNorm = 39.5190, GNorm = 1.6394, lr_0 = 3.0057e-04
Loss = 8.9965e-04, PNorm = 39.5247, GNorm = 1.5368, lr_0 = 2.9936e-04
Loss = 8.8520e-04, PNorm = 39.5295, GNorm = 1.0353, lr_0 = 2.9815e-04
Loss = 8.9719e-04, PNorm = 39.5339, GNorm = 0.9409, lr_0 = 2.9695e-04
Loss = 9.7546e-04, PNorm = 39.5403, GNorm = 1.3888, lr_0 = 2.9576e-04
Loss = 1.1398e-03, PNorm = 39.5483, GNorm = 1.3282, lr_0 = 2.9457e-04
Loss = 9.6869e-04, PNorm = 39.5541, GNorm = 3.0710, lr_0 = 2.9338e-04
Loss = 9.8219e-04, PNorm = 39.5608, GNorm = 1.5267, lr_0 = 2.9220e-04
Validation rmse = 0.498688
Epoch 17
Loss = 1.1840e-03, PNorm = 39.5695, GNorm = 2.4098, lr_0 = 2.9103e-04
Loss = 1.1905e-03, PNorm = 39.5779, GNorm = 2.4213, lr_0 = 2.8986e-04
Loss = 1.4189e-03, PNorm = 39.5855, GNorm = 1.0630, lr_0 = 2.8869e-04
Loss = 8.3376e-04, PNorm = 39.5909, GNorm = 0.8589, lr_0 = 2.8753e-04
Loss = 8.6759e-04, PNorm = 39.5942, GNorm = 0.6543, lr_0 = 2.8637e-04
Loss = 1.1855e-03, PNorm = 39.6043, GNorm = 1.1195, lr_0 = 2.8522e-04
Loss = 8.4189e-04, PNorm = 39.6074, GNorm = 1.5833, lr_0 = 2.8407e-04
Loss = 9.0928e-04, PNorm = 39.6122, GNorm = 0.9407, lr_0 = 2.8293e-04
Loss = 1.0115e-03, PNorm = 39.6172, GNorm = 1.8599, lr_0 = 2.8179e-04
Loss = 9.2332e-04, PNorm = 39.6256, GNorm = 2.5841, lr_0 = 2.8066e-04
Loss = 9.1935e-04, PNorm = 39.6342, GNorm = 2.2797, lr_0 = 2.7953e-04
Loss = 9.2824e-04, PNorm = 39.6393, GNorm = 0.7439, lr_0 = 2.7841e-04
Loss = 6.9851e-04, PNorm = 39.6444, GNorm = 0.4898, lr_0 = 2.7729e-04
Loss = 1.1307e-03, PNorm = 39.6510, GNorm = 2.0630, lr_0 = 2.7617e-04
Loss = 1.1091e-03, PNorm = 39.6608, GNorm = 1.5333, lr_0 = 2.7506e-04
Loss = 1.0903e-03, PNorm = 39.6652, GNorm = 1.0816, lr_0 = 2.7395e-04
Loss = 9.3195e-04, PNorm = 39.6703, GNorm = 2.7036, lr_0 = 2.7285e-04
Loss = 9.8365e-04, PNorm = 39.6760, GNorm = 0.9042, lr_0 = 2.7175e-04
Loss = 1.1130e-03, PNorm = 39.6821, GNorm = 0.9158, lr_0 = 2.7066e-04
Loss = 8.0509e-04, PNorm = 39.6865, GNorm = 2.0144, lr_0 = 2.6957e-04
Loss = 8.2724e-04, PNorm = 39.6894, GNorm = 3.0309, lr_0 = 2.6849e-04
Validation rmse = 0.467612
Epoch 18
Loss = 8.0783e-04, PNorm = 39.6969, GNorm = 1.5115, lr_0 = 2.6741e-04
Loss = 9.6230e-04, PNorm = 39.7025, GNorm = 1.2023, lr_0 = 2.6633e-04
Loss = 8.2634e-04, PNorm = 39.7062, GNorm = 0.7432, lr_0 = 2.6526e-04
Loss = 1.0909e-03, PNorm = 39.7167, GNorm = 2.6539, lr_0 = 2.6419e-04
Loss = 1.3112e-03, PNorm = 39.7239, GNorm = 1.3996, lr_0 = 2.6313e-04
Loss = 9.7322e-04, PNorm = 39.7313, GNorm = 1.9629, lr_0 = 2.6207e-04
Loss = 1.0490e-03, PNorm = 39.7372, GNorm = 1.4821, lr_0 = 2.6102e-04
Loss = 9.7757e-04, PNorm = 39.7404, GNorm = 1.2359, lr_0 = 2.5997e-04
Loss = 9.8875e-04, PNorm = 39.7477, GNorm = 0.9157, lr_0 = 2.5892e-04
Loss = 1.0128e-03, PNorm = 39.7523, GNorm = 0.6581, lr_0 = 2.5788e-04
Loss = 7.9290e-04, PNorm = 39.7570, GNorm = 1.9988, lr_0 = 2.5684e-04
Loss = 9.5860e-04, PNorm = 39.7592, GNorm = 0.3933, lr_0 = 2.5581e-04
Loss = 9.0263e-04, PNorm = 39.7657, GNorm = 1.5900, lr_0 = 2.5478e-04
Loss = 9.5266e-04, PNorm = 39.7691, GNorm = 1.5301, lr_0 = 2.5375e-04
Loss = 9.8372e-04, PNorm = 39.7771, GNorm = 1.3179, lr_0 = 2.5273e-04
Loss = 7.0817e-04, PNorm = 39.7817, GNorm = 1.7616, lr_0 = 2.5172e-04
Loss = 9.7518e-04, PNorm = 39.7882, GNorm = 2.3897, lr_0 = 2.5070e-04
Loss = 7.5783e-04, PNorm = 39.7959, GNorm = 1.6907, lr_0 = 2.4969e-04
Loss = 1.0381e-03, PNorm = 39.8032, GNorm = 2.9549, lr_0 = 2.4869e-04
Loss = 1.1950e-03, PNorm = 39.8105, GNorm = 0.8768, lr_0 = 2.4769e-04
Validation rmse = 0.476160
Epoch 19
Loss = 9.8592e-04, PNorm = 39.8158, GNorm = 1.7636, lr_0 = 2.4669e-04
Loss = 9.3268e-04, PNorm = 39.8207, GNorm = 1.1938, lr_0 = 2.4570e-04
Loss = 8.8671e-04, PNorm = 39.8241, GNorm = 0.4252, lr_0 = 2.4471e-04
Loss = 9.4818e-04, PNorm = 39.8302, GNorm = 1.0765, lr_0 = 2.4373e-04
Loss = 7.7546e-04, PNorm = 39.8358, GNorm = 0.6582, lr_0 = 2.4275e-04
Loss = 7.4428e-04, PNorm = 39.8415, GNorm = 1.0080, lr_0 = 2.4177e-04
Loss = 7.7325e-04, PNorm = 39.8431, GNorm = 1.5083, lr_0 = 2.4080e-04
Loss = 8.3227e-04, PNorm = 39.8488, GNorm = 0.9954, lr_0 = 2.3983e-04
Loss = 6.8826e-04, PNorm = 39.8535, GNorm = 0.6824, lr_0 = 2.3886e-04
Loss = 7.3375e-04, PNorm = 39.8577, GNorm = 1.2528, lr_0 = 2.3790e-04
Loss = 7.2273e-04, PNorm = 39.8600, GNorm = 0.9017, lr_0 = 2.3695e-04
Loss = 7.2159e-04, PNorm = 39.8659, GNorm = 0.9570, lr_0 = 2.3599e-04
Loss = 1.1100e-03, PNorm = 39.8701, GNorm = 1.0677, lr_0 = 2.3504e-04
Loss = 1.1689e-03, PNorm = 39.8723, GNorm = 0.5601, lr_0 = 2.3410e-04
Loss = 9.6752e-04, PNorm = 39.8757, GNorm = 1.3849, lr_0 = 2.3316e-04
Loss = 9.4996e-04, PNorm = 39.8796, GNorm = 0.6234, lr_0 = 2.3222e-04
Loss = 7.8872e-04, PNorm = 39.8853, GNorm = 0.9425, lr_0 = 2.3128e-04
Loss = 8.6085e-04, PNorm = 39.8912, GNorm = 1.0261, lr_0 = 2.3035e-04
Loss = 7.7440e-04, PNorm = 39.8967, GNorm = 0.7959, lr_0 = 2.2943e-04
Loss = 9.0187e-04, PNorm = 39.9033, GNorm = 0.7730, lr_0 = 2.2850e-04
Loss = 9.5878e-04, PNorm = 39.9094, GNorm = 1.1588, lr_0 = 2.2758e-04
Validation rmse = 0.475001
Epoch 20
Loss = 8.8289e-04, PNorm = 39.9160, GNorm = 0.8143, lr_0 = 2.2667e-04
Loss = 1.0548e-03, PNorm = 39.9227, GNorm = 2.5938, lr_0 = 2.2576e-04
Loss = 1.0912e-03, PNorm = 39.9286, GNorm = 2.6379, lr_0 = 2.2485e-04
Loss = 8.8127e-04, PNorm = 39.9361, GNorm = 2.0995, lr_0 = 2.2394e-04
Loss = 1.1811e-03, PNorm = 39.9442, GNorm = 3.3278, lr_0 = 2.2304e-04
Loss = 9.3591e-04, PNorm = 39.9502, GNorm = 1.3267, lr_0 = 2.2215e-04
Loss = 5.8708e-04, PNorm = 39.9558, GNorm = 0.7119, lr_0 = 2.2125e-04
Loss = 7.4411e-04, PNorm = 39.9591, GNorm = 1.4990, lr_0 = 2.2036e-04
Loss = 7.9222e-04, PNorm = 39.9610, GNorm = 0.6251, lr_0 = 2.1948e-04
Loss = 6.6445e-04, PNorm = 39.9650, GNorm = 0.8826, lr_0 = 2.1859e-04
Loss = 7.7245e-04, PNorm = 39.9715, GNorm = 0.7199, lr_0 = 2.1771e-04
Loss = 7.6777e-04, PNorm = 39.9766, GNorm = 1.6370, lr_0 = 2.1684e-04
Loss = 9.3313e-04, PNorm = 39.9798, GNorm = 1.3766, lr_0 = 2.1597e-04
Loss = 8.0062e-04, PNorm = 39.9810, GNorm = 1.0458, lr_0 = 2.1510e-04
Loss = 7.0844e-04, PNorm = 39.9847, GNorm = 0.6387, lr_0 = 2.1423e-04
Loss = 8.9203e-04, PNorm = 39.9869, GNorm = 0.9314, lr_0 = 2.1337e-04
Loss = 9.4774e-04, PNorm = 39.9904, GNorm = 0.6249, lr_0 = 2.1251e-04
Loss = 7.4982e-04, PNorm = 39.9945, GNorm = 0.4334, lr_0 = 2.1166e-04
Loss = 8.7790e-04, PNorm = 39.9983, GNorm = 0.9832, lr_0 = 2.1080e-04
Loss = 6.7350e-04, PNorm = 40.0029, GNorm = 0.7628, lr_0 = 2.0996e-04
Validation rmse = 0.457776
Epoch 21
Loss = 6.3769e-04, PNorm = 40.0060, GNorm = 0.9384, lr_0 = 2.0911e-04
Loss = 7.6075e-04, PNorm = 40.0097, GNorm = 0.4073, lr_0 = 2.0827e-04
Loss = 8.6379e-04, PNorm = 40.0132, GNorm = 1.0318, lr_0 = 2.0743e-04
Loss = 8.4832e-04, PNorm = 40.0178, GNorm = 1.6959, lr_0 = 2.0660e-04
Loss = 7.4014e-04, PNorm = 40.0211, GNorm = 0.9550, lr_0 = 2.0577e-04
Loss = 8.2675e-04, PNorm = 40.0247, GNorm = 0.5437, lr_0 = 2.0494e-04
Loss = 7.0500e-04, PNorm = 40.0287, GNorm = 0.8699, lr_0 = 2.0411e-04
Loss = 7.6257e-04, PNorm = 40.0325, GNorm = 0.7473, lr_0 = 2.0329e-04
Loss = 7.2534e-04, PNorm = 40.0377, GNorm = 0.6017, lr_0 = 2.0248e-04
Loss = 9.2435e-04, PNorm = 40.0421, GNorm = 0.7320, lr_0 = 2.0166e-04
Loss = 8.3414e-04, PNorm = 40.0456, GNorm = 1.4734, lr_0 = 2.0085e-04
Loss = 9.5436e-04, PNorm = 40.0517, GNorm = 0.7574, lr_0 = 2.0004e-04
Loss = 8.4439e-04, PNorm = 40.0557, GNorm = 0.9620, lr_0 = 1.9924e-04
Loss = 6.6104e-04, PNorm = 40.0612, GNorm = 1.0145, lr_0 = 1.9844e-04
Loss = 7.2598e-04, PNorm = 40.0667, GNorm = 0.6526, lr_0 = 1.9764e-04
Loss = 9.1143e-04, PNorm = 40.0703, GNorm = 0.9487, lr_0 = 1.9684e-04
Loss = 8.3080e-04, PNorm = 40.0728, GNorm = 0.6806, lr_0 = 1.9605e-04
Loss = 7.1195e-04, PNorm = 40.0763, GNorm = 1.1252, lr_0 = 1.9526e-04
Loss = 6.8852e-04, PNorm = 40.0810, GNorm = 1.0846, lr_0 = 1.9448e-04
Loss = 7.8685e-04, PNorm = 40.0845, GNorm = 0.8742, lr_0 = 1.9369e-04
Validation rmse = 0.467174
Epoch 22
Loss = 4.9988e-04, PNorm = 40.0860, GNorm = 0.8692, lr_0 = 1.9291e-04
Loss = 6.7163e-04, PNorm = 40.0890, GNorm = 0.7975, lr_0 = 1.9214e-04
Loss = 5.3172e-04, PNorm = 40.0924, GNorm = 1.1674, lr_0 = 1.9137e-04
Loss = 6.8877e-04, PNorm = 40.0957, GNorm = 0.9839, lr_0 = 1.9060e-04
Loss = 1.0113e-03, PNorm = 40.1002, GNorm = 0.6157, lr_0 = 1.8983e-04
Loss = 7.6039e-04, PNorm = 40.1072, GNorm = 1.6526, lr_0 = 1.8906e-04
Loss = 7.7629e-04, PNorm = 40.1101, GNorm = 2.1848, lr_0 = 1.8830e-04
Loss = 7.7233e-04, PNorm = 40.1127, GNorm = 1.4891, lr_0 = 1.8755e-04
Loss = 7.6018e-04, PNorm = 40.1153, GNorm = 1.1787, lr_0 = 1.8679e-04
Loss = 7.8746e-04, PNorm = 40.1206, GNorm = 1.6947, lr_0 = 1.8604e-04
Loss = 7.1261e-04, PNorm = 40.1265, GNorm = 0.8096, lr_0 = 1.8529e-04
Loss = 7.5873e-04, PNorm = 40.1305, GNorm = 0.4780, lr_0 = 1.8455e-04
Loss = 8.9512e-04, PNorm = 40.1371, GNorm = 0.9541, lr_0 = 1.8380e-04
Loss = 7.5787e-04, PNorm = 40.1413, GNorm = 1.4229, lr_0 = 1.8306e-04
Loss = 9.0116e-04, PNorm = 40.1434, GNorm = 1.9180, lr_0 = 1.8233e-04
Loss = 1.0083e-03, PNorm = 40.1479, GNorm = 1.5490, lr_0 = 1.8159e-04
Loss = 8.1707e-04, PNorm = 40.1522, GNorm = 0.7596, lr_0 = 1.8086e-04
Loss = 1.0076e-03, PNorm = 40.1569, GNorm = 0.9981, lr_0 = 1.8014e-04
Loss = 7.3385e-04, PNorm = 40.1602, GNorm = 1.4237, lr_0 = 1.7941e-04
Loss = 6.9484e-04, PNorm = 40.1638, GNorm = 1.6691, lr_0 = 1.7869e-04
Loss = 8.4336e-04, PNorm = 40.1665, GNorm = 0.8417, lr_0 = 1.7797e-04
Validation rmse = 0.464374
Epoch 23
Loss = 6.1099e-04, PNorm = 40.1680, GNorm = 0.8119, lr_0 = 1.7726e-04
Loss = 8.1786e-04, PNorm = 40.1719, GNorm = 0.9249, lr_0 = 1.7654e-04
Loss = 5.8770e-04, PNorm = 40.1760, GNorm = 0.8259, lr_0 = 1.7583e-04
Loss = 5.5075e-04, PNorm = 40.1780, GNorm = 1.0342, lr_0 = 1.7512e-04
Loss = 6.7797e-04, PNorm = 40.1811, GNorm = 0.5386, lr_0 = 1.7442e-04
Loss = 6.7450e-04, PNorm = 40.1850, GNorm = 1.1433, lr_0 = 1.7372e-04
Loss = 8.6108e-04, PNorm = 40.1913, GNorm = 1.3055, lr_0 = 1.7302e-04
Loss = 6.7194e-04, PNorm = 40.1961, GNorm = 0.7382, lr_0 = 1.7232e-04
Loss = 9.7170e-04, PNorm = 40.2014, GNorm = 1.4075, lr_0 = 1.7163e-04
Loss = 8.0281e-04, PNorm = 40.2016, GNorm = 1.8723, lr_0 = 1.7094e-04
Loss = 6.2108e-04, PNorm = 40.2045, GNorm = 0.6529, lr_0 = 1.7025e-04
Loss = 7.0984e-04, PNorm = 40.2086, GNorm = 0.7449, lr_0 = 1.6957e-04
Loss = 6.7529e-04, PNorm = 40.2122, GNorm = 1.1370, lr_0 = 1.6888e-04
Loss = 6.4658e-04, PNorm = 40.2153, GNorm = 0.6693, lr_0 = 1.6821e-04
Loss = 5.8317e-04, PNorm = 40.2182, GNorm = 0.4734, lr_0 = 1.6753e-04
Loss = 1.0271e-03, PNorm = 40.2238, GNorm = 0.4558, lr_0 = 1.6685e-04
Loss = 8.2756e-04, PNorm = 40.2275, GNorm = 1.0133, lr_0 = 1.6618e-04
Loss = 6.8907e-04, PNorm = 40.2306, GNorm = 2.2595, lr_0 = 1.6552e-04
Loss = 7.7015e-04, PNorm = 40.2336, GNorm = 0.6836, lr_0 = 1.6485e-04
Loss = 1.0440e-03, PNorm = 40.2373, GNorm = 1.3245, lr_0 = 1.6419e-04
Validation rmse = 0.517217
Epoch 24
Loss = 9.3386e-04, PNorm = 40.2409, GNorm = 0.6551, lr_0 = 1.6353e-04
Loss = 6.1971e-04, PNorm = 40.2443, GNorm = 0.7405, lr_0 = 1.6287e-04
Loss = 5.3041e-04, PNorm = 40.2478, GNorm = 0.6100, lr_0 = 1.6221e-04
Loss = 7.2910e-04, PNorm = 40.2516, GNorm = 0.4512, lr_0 = 1.6156e-04
Loss = 5.9958e-04, PNorm = 40.2541, GNorm = 0.5137, lr_0 = 1.6091e-04
Loss = 1.0066e-03, PNorm = 40.2581, GNorm = 0.6252, lr_0 = 1.6026e-04
Loss = 6.9445e-04, PNorm = 40.2631, GNorm = 0.9757, lr_0 = 1.5962e-04
Loss = 8.6690e-04, PNorm = 40.2680, GNorm = 0.8238, lr_0 = 1.5898e-04
Loss = 7.2143e-04, PNorm = 40.2725, GNorm = 0.8399, lr_0 = 1.5834e-04
Loss = 7.7005e-04, PNorm = 40.2751, GNorm = 0.3761, lr_0 = 1.5770e-04
Loss = 5.8670e-04, PNorm = 40.2780, GNorm = 1.4308, lr_0 = 1.5706e-04
Loss = 7.0896e-04, PNorm = 40.2812, GNorm = 0.6067, lr_0 = 1.5643e-04
Loss = 7.3011e-04, PNorm = 40.2832, GNorm = 0.7323, lr_0 = 1.5580e-04
Loss = 7.3306e-04, PNorm = 40.2858, GNorm = 0.8691, lr_0 = 1.5518e-04
Loss = 8.0263e-04, PNorm = 40.2897, GNorm = 0.5168, lr_0 = 1.5455e-04
Loss = 7.3639e-04, PNorm = 40.2957, GNorm = 0.8845, lr_0 = 1.5393e-04
Loss = 9.6615e-04, PNorm = 40.2986, GNorm = 1.2211, lr_0 = 1.5331e-04
Loss = 5.9059e-04, PNorm = 40.3018, GNorm = 1.9936, lr_0 = 1.5269e-04
Loss = 7.1632e-04, PNorm = 40.3053, GNorm = 0.3793, lr_0 = 1.5208e-04
Loss = 5.1287e-04, PNorm = 40.3067, GNorm = 0.7629, lr_0 = 1.5147e-04
Loss = 5.8585e-04, PNorm = 40.3069, GNorm = 1.8690, lr_0 = 1.5086e-04
Validation rmse = 0.475161
Epoch 25
Loss = 7.5931e-04, PNorm = 40.3073, GNorm = 1.0931, lr_0 = 1.5025e-04
Loss = 6.7472e-04, PNorm = 40.3120, GNorm = 0.6689, lr_0 = 1.4965e-04
Loss = 6.3910e-04, PNorm = 40.3156, GNorm = 0.6312, lr_0 = 1.4905e-04
Loss = 6.4496e-04, PNorm = 40.3182, GNorm = 1.0098, lr_0 = 1.4845e-04
Loss = 5.9941e-04, PNorm = 40.3193, GNorm = 1.1515, lr_0 = 1.4785e-04
Loss = 7.4516e-04, PNorm = 40.3228, GNorm = 0.8287, lr_0 = 1.4725e-04
Loss = 5.5158e-04, PNorm = 40.3248, GNorm = 0.8964, lr_0 = 1.4666e-04
Loss = 9.0257e-04, PNorm = 40.3286, GNorm = 1.2452, lr_0 = 1.4607e-04
Loss = 7.1948e-04, PNorm = 40.3320, GNorm = 1.0575, lr_0 = 1.4548e-04
Loss = 6.6914e-04, PNorm = 40.3344, GNorm = 0.6983, lr_0 = 1.4490e-04
Loss = 5.7010e-04, PNorm = 40.3369, GNorm = 0.7862, lr_0 = 1.4432e-04
Loss = 5.7801e-04, PNorm = 40.3412, GNorm = 0.7491, lr_0 = 1.4374e-04
Loss = 9.9399e-04, PNorm = 40.3447, GNorm = 1.7361, lr_0 = 1.4316e-04
Loss = 5.8082e-04, PNorm = 40.3471, GNorm = 1.3804, lr_0 = 1.4258e-04
Loss = 6.6766e-04, PNorm = 40.3512, GNorm = 0.3977, lr_0 = 1.4201e-04
Loss = 5.1073e-04, PNorm = 40.3541, GNorm = 0.9852, lr_0 = 1.4144e-04
Loss = 7.2823e-04, PNorm = 40.3557, GNorm = 0.8320, lr_0 = 1.4087e-04
Loss = 9.0445e-04, PNorm = 40.3597, GNorm = 0.6595, lr_0 = 1.4030e-04
Loss = 6.9163e-04, PNorm = 40.3623, GNorm = 0.7446, lr_0 = 1.3974e-04
Loss = 6.3420e-04, PNorm = 40.3661, GNorm = 0.4077, lr_0 = 1.3917e-04
Validation rmse = 0.459763
Epoch 26
Loss = 7.0695e-04, PNorm = 40.3686, GNorm = 1.3840, lr_0 = 1.3861e-04
Loss = 6.4881e-04, PNorm = 40.3711, GNorm = 0.8408, lr_0 = 1.3806e-04
Loss = 6.2107e-04, PNorm = 40.3736, GNorm = 0.4451, lr_0 = 1.3750e-04
Loss = 5.8394e-04, PNorm = 40.3765, GNorm = 1.1163, lr_0 = 1.3695e-04
Loss = 8.0183e-04, PNorm = 40.3794, GNorm = 0.8011, lr_0 = 1.3640e-04
Loss = 6.0107e-04, PNorm = 40.3839, GNorm = 0.8772, lr_0 = 1.3585e-04
Loss = 6.8639e-04, PNorm = 40.3872, GNorm = 0.5911, lr_0 = 1.3530e-04
Loss = 6.2464e-04, PNorm = 40.3903, GNorm = 1.3376, lr_0 = 1.3476e-04
Loss = 7.2175e-04, PNorm = 40.3917, GNorm = 1.5694, lr_0 = 1.3422e-04
Loss = 7.0245e-04, PNorm = 40.3928, GNorm = 2.0277, lr_0 = 1.3368e-04
Loss = 5.9055e-04, PNorm = 40.3963, GNorm = 0.5836, lr_0 = 1.3314e-04
Loss = 5.4962e-04, PNorm = 40.3989, GNorm = 0.8995, lr_0 = 1.3260e-04
Loss = 7.0536e-04, PNorm = 40.4011, GNorm = 0.8179, lr_0 = 1.3207e-04
Loss = 8.6158e-04, PNorm = 40.4015, GNorm = 1.4867, lr_0 = 1.3154e-04
Loss = 6.4961e-04, PNorm = 40.4039, GNorm = 0.7151, lr_0 = 1.3101e-04
Loss = 9.3880e-04, PNorm = 40.4087, GNorm = 0.7554, lr_0 = 1.3048e-04
Loss = 6.8393e-04, PNorm = 40.4140, GNorm = 0.9249, lr_0 = 1.2996e-04
Loss = 6.8744e-04, PNorm = 40.4167, GNorm = 1.5000, lr_0 = 1.2943e-04
Loss = 7.1261e-04, PNorm = 40.4199, GNorm = 0.4534, lr_0 = 1.2891e-04
Loss = 7.7090e-04, PNorm = 40.4226, GNorm = 1.0770, lr_0 = 1.2839e-04
Validation rmse = 0.463781
Epoch 27
Loss = 1.2328e-03, PNorm = 40.4252, GNorm = 0.8800, lr_0 = 1.2788e-04
Loss = 5.6300e-04, PNorm = 40.4273, GNorm = 0.7302, lr_0 = 1.2736e-04
Loss = 7.3160e-04, PNorm = 40.4306, GNorm = 1.0095, lr_0 = 1.2685e-04
Loss = 6.1529e-04, PNorm = 40.4347, GNorm = 1.5090, lr_0 = 1.2634e-04
Loss = 6.8100e-04, PNorm = 40.4370, GNorm = 1.3296, lr_0 = 1.2583e-04
Loss = 8.1632e-04, PNorm = 40.4395, GNorm = 1.7910, lr_0 = 1.2533e-04
Loss = 5.5272e-04, PNorm = 40.4410, GNorm = 0.4784, lr_0 = 1.2482e-04
Loss = 7.5058e-04, PNorm = 40.4438, GNorm = 0.5775, lr_0 = 1.2432e-04
Loss = 5.2918e-04, PNorm = 40.4455, GNorm = 0.4550, lr_0 = 1.2382e-04
Loss = 5.8058e-04, PNorm = 40.4477, GNorm = 0.8706, lr_0 = 1.2332e-04
Loss = 5.7700e-04, PNorm = 40.4504, GNorm = 0.6313, lr_0 = 1.2282e-04
Loss = 6.6245e-04, PNorm = 40.4527, GNorm = 1.4039, lr_0 = 1.2233e-04
Loss = 5.6063e-04, PNorm = 40.4558, GNorm = 0.4498, lr_0 = 1.2184e-04
Loss = 6.0984e-04, PNorm = 40.4565, GNorm = 0.7055, lr_0 = 1.2135e-04
Loss = 9.6454e-04, PNorm = 40.4618, GNorm = 1.5832, lr_0 = 1.2086e-04
Loss = 4.8871e-04, PNorm = 40.4642, GNorm = 0.5084, lr_0 = 1.2037e-04
Loss = 5.6591e-04, PNorm = 40.4667, GNorm = 1.0293, lr_0 = 1.1989e-04
Loss = 5.0951e-04, PNorm = 40.4672, GNorm = 0.5364, lr_0 = 1.1941e-04
Loss = 7.9697e-04, PNorm = 40.4695, GNorm = 0.6157, lr_0 = 1.1893e-04
Loss = 5.9748e-04, PNorm = 40.4705, GNorm = 0.9976, lr_0 = 1.1845e-04
Loss = 7.9756e-04, PNorm = 40.4723, GNorm = 1.3115, lr_0 = 1.1797e-04
Validation rmse = 0.456423
Epoch 28
Loss = 6.3203e-04, PNorm = 40.4760, GNorm = 0.6752, lr_0 = 1.1750e-04
Loss = 6.5083e-04, PNorm = 40.4780, GNorm = 0.6837, lr_0 = 1.1702e-04
Loss = 6.5695e-04, PNorm = 40.4799, GNorm = 1.0206, lr_0 = 1.1655e-04
Loss = 7.0210e-04, PNorm = 40.4823, GNorm = 1.2429, lr_0 = 1.1608e-04
Loss = 6.7685e-04, PNorm = 40.4849, GNorm = 0.8291, lr_0 = 1.1562e-04
Loss = 6.4657e-04, PNorm = 40.4889, GNorm = 1.0661, lr_0 = 1.1515e-04
Loss = 5.6013e-04, PNorm = 40.4916, GNorm = 0.5044, lr_0 = 1.1469e-04
Loss = 5.8815e-04, PNorm = 40.4930, GNorm = 1.3296, lr_0 = 1.1423e-04
Loss = 5.7512e-04, PNorm = 40.4940, GNorm = 0.6469, lr_0 = 1.1377e-04
Loss = 7.1371e-04, PNorm = 40.4973, GNorm = 0.7081, lr_0 = 1.1331e-04
Loss = 4.4291e-04, PNorm = 40.5007, GNorm = 0.3736, lr_0 = 1.1286e-04
Loss = 8.5990e-04, PNorm = 40.5027, GNorm = 1.0525, lr_0 = 1.1240e-04
Loss = 5.8833e-04, PNorm = 40.5056, GNorm = 0.4395, lr_0 = 1.1195e-04
Loss = 6.0048e-04, PNorm = 40.5080, GNorm = 1.0308, lr_0 = 1.1150e-04
Loss = 5.6887e-04, PNorm = 40.5111, GNorm = 0.8233, lr_0 = 1.1105e-04
Loss = 8.2057e-04, PNorm = 40.5121, GNorm = 0.6182, lr_0 = 1.1060e-04
Loss = 8.1075e-04, PNorm = 40.5143, GNorm = 0.5450, lr_0 = 1.1016e-04
Loss = 7.5744e-04, PNorm = 40.5166, GNorm = 0.5537, lr_0 = 1.0972e-04
Loss = 5.5696e-04, PNorm = 40.5181, GNorm = 1.0366, lr_0 = 1.0927e-04
Loss = 5.6170e-04, PNorm = 40.5201, GNorm = 0.5295, lr_0 = 1.0883e-04
Validation rmse = 0.450690
Epoch 29
Loss = 5.5250e-04, PNorm = 40.5219, GNorm = 0.8180, lr_0 = 1.0840e-04
Loss = 7.7337e-04, PNorm = 40.5249, GNorm = 0.9228, lr_0 = 1.0796e-04
Loss = 7.6416e-04, PNorm = 40.5286, GNorm = 1.5456, lr_0 = 1.0753e-04
Loss = 6.4042e-04, PNorm = 40.5312, GNorm = 1.2250, lr_0 = 1.0709e-04
Loss = 6.4035e-04, PNorm = 40.5334, GNorm = 1.1106, lr_0 = 1.0666e-04
Loss = 5.8367e-04, PNorm = 40.5374, GNorm = 0.5735, lr_0 = 1.0623e-04
Loss = 6.3278e-04, PNorm = 40.5407, GNorm = 0.8647, lr_0 = 1.0581e-04
Loss = 5.3868e-04, PNorm = 40.5428, GNorm = 0.8911, lr_0 = 1.0538e-04
Loss = 6.1087e-04, PNorm = 40.5439, GNorm = 0.5170, lr_0 = 1.0496e-04
Loss = 7.1128e-04, PNorm = 40.5451, GNorm = 0.7697, lr_0 = 1.0453e-04
Loss = 4.5744e-04, PNorm = 40.5463, GNorm = 1.0951, lr_0 = 1.0411e-04
Loss = 6.5577e-04, PNorm = 40.5490, GNorm = 0.6070, lr_0 = 1.0369e-04
Loss = 6.2521e-04, PNorm = 40.5500, GNorm = 0.7912, lr_0 = 1.0328e-04
Loss = 6.0791e-04, PNorm = 40.5526, GNorm = 0.3848, lr_0 = 1.0286e-04
Loss = 4.5317e-04, PNorm = 40.5549, GNorm = 0.4167, lr_0 = 1.0245e-04
Loss = 6.1734e-04, PNorm = 40.5563, GNorm = 0.6870, lr_0 = 1.0204e-04
Loss = 7.0771e-04, PNorm = 40.5570, GNorm = 1.5690, lr_0 = 1.0163e-04
Loss = 4.5594e-04, PNorm = 40.5583, GNorm = 0.5541, lr_0 = 1.0122e-04
Loss = 7.2282e-04, PNorm = 40.5599, GNorm = 1.3690, lr_0 = 1.0081e-04
Loss = 8.5302e-04, PNorm = 40.5621, GNorm = 1.2283, lr_0 = 1.0040e-04
Loss = 8.2496e-04, PNorm = 40.5649, GNorm = 1.6054, lr_0 = 1.0000e-04
Validation rmse = 0.458745
Model 0 best validation rmse = 0.450690 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.436482
Ensemble test rmse = 0.436482
1-fold cross validation
Seed 0 ==> test rmse = 0.436482
Overall test rmse = 0.436482 +/- 0.000000
