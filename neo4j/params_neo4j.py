import pandas as pd
from py2neo import Graph, Node, Relationship, NodeMatcher
import model_kg_v4 as v4
import extract_params as ep


def graph_gdbparam(model_csv, algo="gdb"):
    graph = Graph("bolt://localhost:7687", user="neo4j", password="1234")
    model_df = pd.read_csv(model_csv) # csv file with all ml results
    param_df = ep.param_finaldf(model_csv, algo)
    algo_df = model_df[model_df.algorithm == algo] # dataframe with specific algorithms
    model_dicts = algo_df.to_dict('records')
    param_dct = param_df.to_dict('records') # Dict of dataframe for ml parameters
    learn_lst = []
    for i in range(len(param_dct)):
        ml_dict = model_dicts[i]
        tx = graph.begin()
        print('Creating Nodes Number ' + str(i))
        runs = Node("run_num", run=ml_dict['Run#'])
        tx.create(runs)
        algo = Node("algo", algorithm=ml_dict['algorithm'])
        tx.create(algo)
        data = Node("data_ml", data=ml_dict['dataset'])
        tx.create(data)
        target = Node("targets", target=ml_dict['target'])
        tx.create(target)
        feat_meth = Node("featmeth", feat_meth=ml_dict['feat_meth'])
        tx.create(feat_meth)
        feat_time = Node("feattime", feat_time=ml_dict['feat_time'])
        tx.create(feat_time)
        tuned = Node("tuned", tuned=ml_dict['tuned'])
        tx.create(tuned)
        feature_list = Node("featurelist", feature_lists=ml_dict['feature_list'])
        tx.create(feature_list)
        regressor = Node("regress", regressor=ml_dict['regressor'])
        tx.create(regressor)
        tunetime = Node("tunetimes", tunetime=ml_dict['tuneTime'])
        tx.create(tunetime)
        r2_avg = Node("r2avg", r2_avg=ml_dict['r2_avg'])
        tx.create(r2_avg)
        r2_std = Node("r2std", r2_std=ml_dict['r2_std'])
        tx.create(r2_std)
        mse_avg = Node("mseavg", mse_avg=ml_dict['mse_avg'])
        tx.create(mse_avg)
        mse_std = Node("msestd", mse_std=ml_dict['mse_std'])
        tx.create(mse_std)
        rmse_avg = Node("rmseavg", rmse_avg=ml_dict['rmse_avg'])
        tx.create(rmse_avg)
        rmse_std = Node("rmsestd", rmse_std=ml_dict['rmse_std'])
        tx.create(rmse_std)
        time_avg = Node("timeavg", time_avg=ml_dict['time_avg'])
        tx.create(time_avg)
        time_std = Node("timestd", time_std=ml_dict['time_std'])
        tx.create(time_std)
        final_results = Node("results", result=ml_dict['Results'])
        tx.create(final_results)
        # params
        loop_param = param_dct[i]
        learning_rate = Node("learning_rate", learn_rates=loop_param['learning_rate'])
        learn_lst.append(learning_rate)
        tx.create(learning_rate)
        max_depth = Node("max_depth", max_d=loop_param['max_depth'])
        tx.create(max_depth)
        max_features = Node("max_features", max_feat=loop_param['max_features'])
        tx.create(max_features)
        min_samples_leaf = Node("min_samples_leaf", min_leaf=loop_param['min_samples_leaf'])
        tx.create(min_samples_leaf)
        min_samples_split = Node("min_samples_split", min_split=loop_param['min_samples_split'])
        tx.create(min_samples_split)
        n_estimators = Node("n_estimators", estimators=loop_param['n_estimators'])
        tx.create(n_estimators)
        print('Creating Relationships Number ' + str(i))
        aa = Relationship(runs, "uses", algo)
        tx.merge(aa)
        ab = Relationship(runs, "uses", data)
        tx.merge(ab)
        ac = Relationship(data, "has", target)
        tx.merge(ac)
        ad = Relationship(runs, "generates", feat_meth)
        tx.merge(ad)
        ae = Relationship(feature_list, "feat_time", feat_time)
        tx.merge(ae)
        af = Relationship(feat_meth, "means", feature_list)
        tx.merge(af)
        ag = Relationship(tuned, "tuned", regressor)
        tx.merge(ag)
        ah = Relationship(algo, "params", regressor)
        tx.merge(ah)
        ai = Relationship(tuned, "tunetime", tunetime)
        tx.merge(ai)
        aj = Relationship(regressor, "gives", final_results)
        tx.merge(aj)
        ak = Relationship(final_results, "has r2_avg", r2_avg)
        tx.merge(ak)
        an = Relationship(final_results, "has Rmse_std", rmse_std)
        tx.merge(an)
        ao = Relationship(final_results, "has Rmse_avg", rmse_avg)
        tx.merge(ao)
        ap = Relationship(final_results, "has r2_std", r2_std)
        tx.merge(ap)
        at = Relationship(algo, "tune", tuned)
        tx.merge(at)
        au = Relationship(runs, "gives", final_results)
        tx.merge(au)
        av = Relationship(algo, "contributes to", final_results)
        tx.merge(av)
        az = Relationship(data, "contributes to", final_results)
        tx.merge(az)
        bb = Relationship(feat_meth, "contributes to", final_results)
        tx.merge(bb)
        bc = Relationship(regressor, "learning_rate", learning_rate)
        tx.merge(bc)
        bd = Relationship(regressor, "max_depth", max_depth)
        tx.merge(bd)
        be = Relationship(regressor, "max_features", max_features)
        tx.merge(be)
        bf = Relationship(regressor, "min_samples_leaf", min_samples_split)
        tx.merge(bf)
        bg = Relationship(regressor, "min_samples_split", min_samples_split)
        tx.merge(bg)
        bh = Relationship(regressor, "n_estimators", n_estimators)
        tx.merge(bh)
        tx.commit()

df = pd.read_csv('ml_results2.csv')
graph_gdbparam('ml_results2.csv')
v4.run_cypher_command(df, "algorithm")
v4.run_cypher_command(df, "dataset")





